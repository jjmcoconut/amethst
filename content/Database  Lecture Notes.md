### 빅 데이터

전통적인 관계형 데이터베이스 응용 프로그램은 구조화된 데이터를 기반으로 하며, 단일 기업의 데이터를 처리합니다. 현대 데이터 관리 응용 프로그램은 반드시 관계형 형태가 아닌 데이터를 처리할 필요가 있으며, 또한 단일 기업이 생성하는 것보다 훨씬 더 큰 데이터 양을 처리할 필요가 있습니다. 이 장에서는 빅 데이터라고 불리는 이러한 데이터를 관리하는 기술을 공부합니다.

#### 10.1 동기

1990년대와 2000년대 월드 와이드 웹의 성장으로 인해 관계형 데이터베이스가 관리하도록 설계된 기업 데이터보다 훨씬 많은 양의 데이터를 저장하고 질의할 필요가 생겼습니다. 초기 웹의 사용자 가시적 데이터는 대부분 정적이었지만, 웹 사이트는 방문자, 방문한 웹 페이지, 방문 시간을 기록한 대규모 데이터를 생성했습니다. 이러한 데이터는 일반적으로 텍스트 형식의 웹 서버 로그 파일에 저장되었습니다. 웹 사이트 관리자들은 웹 로그에 사용자에 대한 정보를 포함하고 있어, 이를 통해 사용자에 대해 더 많이 이해하고, 광고 및 마케팅 캠페인을 타겟팅할 수 있다는 것을 깨달았습니다. 이러한 정보는 사용자가 방문한 페이지와 사용자 프로필 데이터(예: 나이, 성별, 소득 수준 등)를 연결할 수 있습니다. 쇼핑 사이트와 같은 트랜잭션 웹 사이트는 사용자가 검색하거나 구매한 제품과 같은 다른 종류의 데이터를 가지고 있었습니다. 2000년대에는 특히 소셜 미디어 데이터와 같은 사용자 생성 데이터의 양이 급격히 증가했습니다.

이러한 데이터의 양은 곧 전통적인 데이터베이스 시스템이 처리할 수 있는 범위를 초과했으며, 저장 및 처리는 매우 높은 수준의 병렬 처리가 필요했습니다. 또한 데이터는 로그 기록과 같은 텍스트 형식이거나 8장에서 보았듯이 다른 반구조적 형태일 때가 많았습니다. 이러한 데이터는 그 크기, 생성 속도, 다양한 형식으로 인해 빅 데이터라고 불립니다.

빅 데이터는 다음과 같은 메트릭에서 전통적인 관계형 데이터베이스와 대조됩니다:
- **볼륨**: 저장하고 처리해야 하는 데이터의 양이 전통적인 데이터베이스, 특히 전통적인 병렬 관계형 데이터베이스가 처리하도록 설계된 것보다 훨씬 큽니다. 병렬 데이터베이스 시스템은 오랜 역사를 가지고 있지만, 초기 병렬 데이터베이스는 수십에서 수백 대의 기계에서 작동하도록 설계되었습니다. 반면, 일부 새로운 응용 프로그램은 수천 대의 기계를 병렬로 사용하여 데이터를 저장하고 처리해야 합니다.
- **속도**: 오늘날의 네트워크화된 세계에서는 데이터가 도착하는 속도가 과거보다 훨씬 빠릅니다. 데이터 관리 시스템은 매우 높은 속도로 데이터를 수집하고 저장할 수 있어야 합니다. 또한, 많은 응용 프로그램은 데이터 항목이 도착하는 즉시 처리하여 특정 이벤트를 빠르게 감지하고 대응해야 합니다(이러한 시스템은 스트리밍 데이터 시스템이라고 합니다). 따라서 처리 속도는 오늘날 많은 응용 프로그램에서 매우 중요합니다.
- **다양성**: 관계형 데이터의 표현, 관계형 질의 언어, 관계형 데이터베이스 시스템은 지난 수십 년 동안 매우 성공적이었으며 대부분의 조직의 데이터 표현의 핵심을 형성합니다. 그러나 모든 데이터가 관계형 데이터는 아닙니다.

8장에서 보았듯이, 오늘날에는 다양한 목적을 위해 다양한 데이터 표현이 사용됩니다. 오늘날의 많은 데이터는 관계형 형태로 효율적으로 표현될 수 있지만, 반구조적 데이터, 텍스트 데이터, 그래프 데이터와 같은 다른 형태의 데이터를 포함하는 많은 데이터 소스가 있습니다. SQL 질의 언어는 관계형 데이터에 대한 다양한 질의를 지정하는 데 적합하며, 반구조적 데이터를 처리하도록 확장되었습니다. 그러나 많은 계산은 SQL로 쉽게 표현할 수 없거나 SQL을 사용하여 효율적으로 평가할 수 없습니다.

복잡한 질의를 지정하고 효율적으로 실행하기 위한 새로운 세대의 언어와 프레임워크가 개발되었습니다.

우리는 빅 데이터를 관계형 데이터 여부와 관계없이 처리하기 위해 높은 수준의 병렬 처리가 필요한 모든 데이터 처리 요구를 지칭하는 일반적인 의미로 사용할 것입니다.

지난 10년 동안 수천 대, 경우에 따라 수만 대의 기계를 사용하여 빅 데이터를 저장하고 처리하기 위한 여러 시스템이 개발되었습니다. 클러스터의 기계를 노드라고 합니다.

#### 10.1.1 빅 데이터의 소스와 사용

1990년대 후반과 2000년대 초반 웹의 급속한 성장은 데이터 양의 엄청난 성장을 이끄는 주요 원동력이었습니다. 초기 데이터 소스는 웹 서버 소프트웨어의 로그로, 사용자와의 상호 작용을 기록했습니다. 매일 수백만 명의 사용자가 여러 링크를 클릭하면서 대형 웹 기업들은 매일 수 테라바이트의 데이터를 생성했습니다. 웹 기업들은 곧 웹 로그에 중요한 정보가 많다는 것을 깨달았습니다. 이러한 정보는 다음과 같은 다양한 용도로 사용될 수 있습니다:
- 사용자가 이전에 본 정보와 유사한 선호도를 가진 다른 사용자가 본 정보에 대한 정보를 통해 사용자에게 어떤 게시물, 뉴스, 기타 정보를 제시할지 결정합니다.
- 사용자가 본 페이지나 이전에 클릭한 광고 정보를 통해 사용자에게 어떤 광고를 보여줄지 결정하여 광고주의 이익을 최대화하고 사용자가 더 관련성 있는 광고를 보게 합니다.
- 사용자가 일반적으로 어떤 페이지로 이동하고 특정 페이지를 방문한 후 어떤 페이지를 보는지에 대한 정보를 통해 웹 사이트 구조를 결정합니다.
- 페이지 뷰를 기반으로 사용자 선호도와 트렌드를 결정하여 제조업체나 판매자가 어떤 제품을 더 많이 생산하거나 재고를 늘릴지, 어떤 제품을 덜 생산하거나 재고를 줄일지 결정합니다.
- 광고 클릭 및 전환 정보. 전환은 사용자가 광고된 제품이나 서비스를 실제로 구매할 때 발생합니다. 클릭이나 전환이 발생할 때 웹 사이트는 종종 비용을 지불받습니다. 따라서 클릭 및 전환 비율은 사이트가 어떤 광고를 표시할지 결정하는 중요한 메트릭입니다.

오늘날에는 매우 많은 양의 데이터를 생성하는 다른 소스도 많이 있습니다. 예를 들어:
- 모바일 앱의 데이터는 웹 사이트에서 사용자가 웹 사이트와의 상호 작용을 이해하는 것과 같은 방식으로 사용자가 앱과 상호 작용하는 것을 이해하는 데 도움이 됩니다.
- 소매 기업(온라인 및 오프라인)의 거래 데이터. 초기 대량 데이터 사용자는 Walmart와 같은 대형 소매 체인이었으며, 이들은 웹 이전에도 병렬 데이터베이스 시스템을 사용하여 데이터를 관리하고 분석했습니다.
- 센서 데이터. 오늘날 고급 장비에는 장비의 상태를 모니터링하기 위해 많은 센서가 있습니다. 이러한 데이터를 중앙에서 수집하면 상태를 추적하고 장비의 문제 발생 가능성을 예측하여 문제가 발생하기 전에 문제를 해결하는 데 도움이 됩니다. 이러한 센서를 점점 더 많이 사용하면서 차량, 건물, 기계 등 다른 객체에 내장된 센서 및 컴퓨팅 장치를 인터넷에 연결하는 사물 인터넷(IoT)이 증가하고 있습니다. 이러한 장치의 수는 인터넷에 연결된 인간의 수보다 많습니다.
- 통신 네트워크의 메타데이터, 데이터 네트워크의 트래픽 및 기타 모니터링 정보, 음성 네트워크의 통화 정보. 이러한 데이터는 문제가 발생하기 전에 감지하고, 문제가 발생할 때 감지하며, 용량 계획 및 기타 관련 결정을 내리는 데 중요합니다.

데이터베이스에 저장된 데이터의 양은 빅 데이터라는 용어가 사용되기 훨씬 전부터 여러 수십 년 동안 급속히 증가해 왔습니다. 그러나 웹의 급속한 성장은 주요 웹 사이트가 수억에서 수십억 명의 사용자가 생성한 데이터를 처리해야 하는 상황을 만들었습니다. 이는 대부분의 이전 응용 프로그램보다 훨씬 큰 규모였습니다.

웹과 관련이 없는 기업조차도 매우 많은 양의 데이터를 처리할 필요가 있음을 발견했습니다. 많은 기업은 다른 기업이 생성한 대량의 데이터를 구입하여 분석합니다. 예를 들어, 사용자 프로필 정보로 주석이 달린 웹 검색 기록은 많은 기업에 제공되며, 이를 통해 광고 캠페인을 계획하거나 어떤 제품을 언제 제조할지 계획하는 등 다양한 비즈니스 결정을 내릴 수 있습니다.

오늘날 기업들은 비즈니스 결정을 내리기 위해 소셜 미디어 데이터를 사용하는 것이 필수적입니다. 회사의 신제품 출시 또는 기존 제품 변경에 대한 반응은 Twitter와 같은 소셜 미디어 사이트에서 찾을 수 있습니다. Twitter와 같은 소셜 미디어 사이트의 데이터 양이 매우 많을 뿐만 아니라 데이터가 매우 빠르게 도착하며 이를 신속하게 분석하고 대응해야 합니다. 예를 들어, 회사가 광고를 내보냈는데 Twitter에서 부정적인 반응이 강하면, 회사는 문제를 신속하게 감지하고 광고를 중단하여 피해를 최소화하고자 할 것입니다. 따라서 빅 데이터는 오늘날 많은 조직의 다양한 활동을 가능하게 하는 핵심 요소가 되었습니다.

#### 10.1.2 빅 데이터 질의

SQL은 관계형 데이터베이스 질의를

 위한 가장 널리 사용되는 언어입니다. 그러나 빅 데이터 응용 프로그램에는 더 다양한 데이터 유형을 처리하고 매우 큰 데이터 볼륨/속도에 확장할 필요가 있기 때문에 더 다양한 질의 언어 옵션이 있습니다.

큰 볼륨/속도의 데이터를 처리할 수 있는 데이터 관리 시스템을 구축하려면 데이터를 병렬로 저장하고 처리해야 합니다. SQL과 다른 데이터베이스 기능(예: 트랜잭션)을 지원하면서 동시에 매우 높은 성능을 제공하는 관계형 데이터베이스를 구축하는 것은 쉬운 일이 아닙니다. 이러한 응용 프로그램에는 두 가지 범주가 있습니다:
1. 매우 높은 확장성이 필요한 트랜잭션 처리 시스템: 트랜잭션 처리 시스템은 많은 수의 짧은 실행 질의와 업데이트를 지원합니다. 관계형 데이터베이스의 모든 기능을 지원할 필요성을 완화하면 트랜잭션 처리를 지원하는 데이터베이스가 매우 많은 수의 기계로 확장하는 것이 훨씬 쉬워집니다. 반면, 매우 높은 볼륨/속도를 필요로 하는 많은 트랜잭션 처리 응용 프로그램은 전체 데이터베이스 지원 없이도 관리할 수 있습니다.
   데이터 접근의 기본 모드는 데이터를 관련 키와 함께 저장하고 그 키로 데이터를 검색하는 것입니다. 이러한 저장 시스템은 키-값 저장소라고 합니다. 앞서 설명한 사용자 프로필 예제에서는 사용자 식별자가 사용자 프로필 데이터의 키가 됩니다. 조인이 개념적으로 필요한 응용 프로그램도 있지만, 응용 프로그램 코드에서 조인을 구현하거나 뷰 실체화를 통해 조인을 구현할 수 있습니다.
   예를 들어, 소셜 네트워킹 응용 프로그램에서는 사용자가 시스템에 연결하면 모든 친구의 새 게시물을 보여줘야 합니다. 게시물 및 친구에 대한 데이터가 관계형 형식으로 유지되면 이는 조인이 필요합니다. 대신, 시스템이 키-값 저장소에 각 사용자에 대한 객체를 유지하고, 친구 정보와 게시물을 포함하는 경우, 데이터베이스에서 조인이 수행되는 대신, 응용 프로그램 코드가 사용자의 친구 집합을 찾고 각 친구의 데이터 객체를 질의하여 게시물을 찾습니다. 또 다른 대안으로는, 사용자가 게시물을 작성할 때마다 각 친구에게 메시지를 보내 친구와 관련된 데이터를 새로운 게시물의 요약으로 업데이트하는 것입니다. 사용자가 업데이트를 확인할 때, 모든 친구의 게시물 요약을 제공하는 데 필요한 모든 데이터가 한 곳에 있어 신속하게 검색할 수 있습니다.
   두 대안 간의 트레이드오프가 있습니다. 첫 번째 대안은 질의 시점에서 더 높은 비용이 들고, 두 번째 대안은 쓰기 시점에서 더 높은 저장 비용과 더 높은 비용이 듭니다. 그러나 두 접근 방식 모두 키-값 저장 시스템에서 조인 지원 없이 응용 프로그램이 작업을 수행할 수 있게 합니다.
2. 매우 높은 확장성이 필요하고 비관계형 데이터를 지원해야 하는 질의 처리 시스템: 이러한 시스템의 전형적인 예는 웹 서버 및 기타 응용 프로그램이 생성한 로그를 분석하도록 설계된 시스템입니다. 다른 예로는 웹에서 키워드 검색을 지원하는 문서 및 지식 저장 및 인덱싱 시스템이 있습니다.
   많은 응용 프로그램이 사용하는 데이터는 여러 파일에 저장됩니다. 이러한 응용 프로그램을 지원하도록 설계된 시스템은 먼저 많은 대형 파일을 저장할 수 있어야 합니다. 둘째, 이러한 파일에 저장된 데이터를 병렬로 질의할 수 있어야 합니다. 데이터가 반드시 관계형이 아니므로, 이러한 데이터를 질의하기 위해 설계된 시스템은 관계형 대수 또는 SQL 질의뿐만 아니라 임의의 프로그램 코드를 지원해야 합니다.
   빅 데이터 응용 프로그램은 종종 매우 큰 볼륨의 텍스트, 이미지, 비디오 데이터를 처리해야 합니다. 전통적으로 이러한 데이터는 파일 시스템에 저장되고 독립 실행형 응용 프로그램을 사용하여 처리되었습니다. 예를 들어, 텍스트 데이터의 키워드 검색과 그 후속 단계인 웹의 키워드 검색은 모두 텍스트 데이터를 사전 처리하고, 사전 처리 단계에서 구축된 인덱스와 같은 데이터 구조를 사용하여 질의를 처리합니다. 입력 데이터가 관계형 형태가 아니고 출력도 관계형 형태가 아닐 수 있기 때문에 이전에 보았던 SQL 구문은 이러한 작업을 수행하는 데 적합하지 않습니다.
   초기에는 이러한 데이터의 처리가 독립 실행형 프로그램을 사용하여 수행되었습니다. 이는 데이터베이스 관리 시스템이 도입되기 전 조직 데이터가 처리되던 방식과 매우 유사합니다. 그러나 데이터 크기의 매우 빠른 성장은 독립 실행형 프로그램의 한계를 명확히 했습니다. 빅 데이터의 매우 큰 규모를 감안할 때 병렬 처리는 중요합니다. 대규모 병렬 처리에서 흔히 발생하는 실패를 처리하면서 데이터를 병렬로 처리하는 프로그램을 작성하는 것은 쉽지 않습니다.

이 장에서는 오늘날 널리 사용되는 빅 데이터 질의 기법을 연구합니다. 이러한 기술의 성공의 핵심은 복잡한 데이터 처리 작업을 지정할 수 있으면서도 작업의 병렬화를 쉽게 할 수 있다는 점입니다. 이러한 기술은 프로그래머가 병렬화 수행 방법, 실패 처리 방법, 기계 간의 부하 불균형 처리 방법 등과 같은 문제를 다루지 않도록 해줍니다.

#### 10.2 빅 데이터 저장 시스템

빅 데이터 응용 프로그램은 매우 높은 확장성 요구를 가지고 있습니다. 인기 있는 응용 프로그램은 수억 명의 사용자를 보유하고 있으며, 많은 응용 프로그램은 몇 개월 또는 몇 년 안에 그 부하가 여러 배 증가합니다. 이러한 응용 프로그램의 데이터 관리 요구를 처리하려면 데이터를 수천 개의 컴퓨팅 및 저장 노드에 분산하여 저장해야 합니다.

지난 20년 동안 이러한 응용 프로그램의 데이터 관리 요구를 해결하기 위해 여러 빅 데이터 저장 시스템이 개발되고 배포되었습니다. 여기에는 다음이 포함됩니다:
- **분산 파일 시스템**: 파일을 여러 기계에 저장하면서 전통적인 파일 시스템 인터페이스를 사용하여 파일에 접근할 수 있게 합니다. 분산 파일 시스템은 대형 파일(예: 로그 파일)을 저장하는 데 사용됩니다. 또한 레코드 저장을 지원하는 시스템의 저장 계층으로도 사용됩니다.
- **다중 데이터베이스 샤딩**: 샤딩은 레코드를 여러 시스템에 분할하는 과정을 말합니다. 즉, 레코드는 시스템 간에 나누어집니다. 샤딩의 일반적인 사용 사례는 서로 다른 사용자의 레코드를 여러 데이터베이스에 분할하는 것입니다. 각 데이터베이스는 전통적인 중앙 집중식 데이터베이스로, 다른 데이터베이스에 대한 정보가 없을 수 있습니다. 클라이언트 소프트웨어는 레코드가 어떻게 분할되는지 추적하고 각 질의를 적절한 데이터베이스에 보내야 합니다.
- **키-값 저장 시스템**: 키를 기반으로 레코드를 저장하고 검색할 수 있으며 제한된 질의 기능을 제공할 수 있습니다. 그러나 완전한 데이터베이스 시스템은 아니며, 이러한 저장 시스템은 일반적으로 SQL 언어를 지원하지 않기 때문에 NoSQL 시스템이라고도 합니다.
- **병렬 및 분산 데이터베이스**: 전통적인 데이터베이스 인터페이스를 제공하지만 데이터를 여러 기계에 저장하고 여러 기계에서 병렬로 질의를 처리합니다.

병렬 및 분산 데이터베이스 저장 시스템, 분산 파일 시스템 및 키-값 저장소는 21장에서 자세히 설명합니다. 이 절에서는 이러한 빅 데이터 저장 시스템에 대한 사용자 수준 개요를 제공합니다.

#### 10.2.1 분산 파일 시스템

분산 파일 시스템은 파일을 많은 기계에 저장하면서 클라이언트에게 단일 파일 시스템 뷰를 제공합니다. 파일 시스템과 마찬가지로 파일 및 디렉터리의 시스템이 있어 클라이언트가 파일을 식별하고 접근할 수 있습니다. 클라이언트는 파일이 어디에 저장되는지 신경 쓸 필요가 없습니다. 이러한 분산 파일 시스템은 매우 많은 양의 데이터를 저장할 수 있으며, 매우 많은 수의 동시 클라이언트를 지원할 수 있습니다. 이러한 시스템은 대형 파일로 저장된 웹 페이지, 웹 서버 로그, 이미지 등의 비구조적 데이터를 저장하는 데 이상적입니다.

이와 관련된 중요한 시스템은 2000년대 초에 개발된 Google 파일 시스템(GFS)으로, Google 내에서 널리 사용되었습니다. 오픈 소스 Hadoop 파일 시스템(HDFS)은 GFS 아키텍처를 기반으로 하며 현재 매우 널리 사용됩니다.

분산 파일 시스템은 크기가 수십 메가바이트에서 수백 기가바이트 또는 그 이상의 대형 파일을 효율적으로 저장하도록 설계되었습니다.

분산 파일 시스템의 데이터는 여러 기계에 저장됩니다. 파일은 여러 블록으로 나누어집니다. 단일 파일의 블록은 여러 기계에 분할될 수 있습니다. 또한 각 파일 블록은 여러(일반적으로 세) 기계에 복제되므로 기계 고장으로 인해 파일에 접근할 수 없게 되지 않습니다.

중앙 집중식이든 분산이든 파일 시스템은 일반적으로 다음을 지원합니다:
- 디렉터리 시스템: 파일을 디렉터리와 하위 디렉터리로 계층화하여 조직할 수 있게

 합니다.
- 파일 이름을 실제 데이터가 저장된 블록의 식별자 시퀀스에 매핑합니다.
- 지정된 식별자의 블록에서 데이터를 저장하고 검색할 수 있습니다. 중앙 집중식 파일 시스템의 경우 블록 식별자는 디스크와 같은 저장 장치에서 블록을 찾는 데 도움이 됩니다. 분산 파일 시스템의 경우, 블록 식별자 외에도 파일 시스템은 블록이 저장된 위치(기계 식별자)를 제공해야 합니다. 실제로 복제 덕분에 파일 시스템은 각 블록 식별자와 함께 여러 기계 식별자를 제공합니다.

그림 10.1은 Google 파일 시스템(GFS) 아키텍처에서 파생된 Hadoop 파일 시스템(HDFS) 아키텍처를 보여줍니다. HDFS의 핵심은 NameNode라고 하는 기계에서 실행되는 서버입니다. 모든 파일 시스템 요청은 NameNode로 전송됩니다. 기존 파일을 읽고자 하는 파일 시스템 클라이언트 프로그램은 파일 이름(예: /home/avi/book/ch10)을 NameNode에 보냅니다. NameNode는 각 파일의 블록 식별자 목록을 저장합니다. 각 블록 식별자에 대해 NameNode는 해당 블록을 저장하는 기계의 식별자도 저장합니다. HDFS에서 데이터 블록을 저장하는 기계를 DataNode라고 합니다.

파일 읽기 요청의 경우, HDFS 서버는 파일의 블록 식별자 목록과 각 블록을 포함하는 기계의 식별자를 반환합니다. 그런 다음 각 블록은 블록의 복사본을 저장하는 기계 중 하나에서 검색됩니다.

파일 쓰기의 경우, HDFS 서버는 새로운 블록 식별자를 생성하고 각 블록 식별자를 여러 기계(일반적으로 세 기계)에 할당하며, 클라이언트에게 블록 식별자와 기계 할당을 반환합니다. 클라이언트는 그런 다음 블록 식별자와 블록 데이터를 할당된 기계에 보내 데이터를 저장합니다.

프로그램은 Java 및 Python과 같은 여러 언어로 제공되는 HDFS 파일 시스템 API를 사용하여 파일에 접근할 수 있습니다. API는 프로그램이 HDFS 서버에 연결하여 데이터에 접근할 수 있게 합니다.

HDFS 분산 파일 시스템은 로컬 파일 시스템에 연결하여 로컬에 저장된 것처럼 HDFS 파일에 접근할 수 있습니다. 이를 위해 NameNode 기계의 주소와 HDFS 서버가 요청을 수신하는 포트를 로컬 파일 시스템에 제공해야 합니다. 로컬 파일 시스템은 파일 경로를 기반으로 HDFS의 파일 접근을 인식하고 적절한 요청을 HDFS 서버에 보냅니다.

분산 파일 시스템 구현에 대한 자세한 내용은 21.6절에서 찾을 수 있습니다.

#### 10.2.2 샤딩

단일 데이터베이스 시스템은 일반적으로 기업의 모든 트랜잭션 처리 요구를 처리할 충분한 저장 공간과 성능을 갖추고 있습니다. 그러나 수백만 또는 수십억 명의 사용자가 있는 응용 프로그램(예: 소셜 미디어 또는 유사한 웹 규모의 응용 프로그램)이나 대형 은행과 같은 대형 조직의 사용자 대면 응용 프로그램에는 단일 데이터베이스를 사용하는 것이 충분하지 않습니다.

조직이 중앙 집중식 데이터베이스로 응용 프로그램을 구축했지만 더 많은 사용자를 처리할 필요가 있고 중앙 집중식 데이터베이스가 저장 또는 처리 속도 요구를 충족하지 못하는 경우, 일반적으로 사용되는 방법은 데이터를 여러 데이터베이스로 분할하여 각 데이터베이스에 일부 사용자를 할당하는 것입니다. 샤딩은 데이터를 여러 데이터베이스 또는 기계에 분할하는 과정을 말합니다.

분할은 일반적으로 하나 이상의 속성, 즉 분할 속성, 분할 키, 또는 샤드 키를 정의하여 수행됩니다. 사용자 또는 계정 식별자가 일반적으로 분할 키로 사용됩니다. 분할은 각 데이터베이스가 처리할 키 범위를 정의하여 수행될 수 있습니다. 예를 들어, 키 1에서 100,000까지는 첫 번째 데이터베이스에 할당되고, 키 100,001에서 200,000까지는 두 번째 데이터베이스에 할당되는 식입니다. 이러한 분할은 범위 분할이라고 합니다. 분할은 키 값을 파티션 번호로 매핑하는 해시 함수를 계산하여 수행될 수도 있습니다. 이러한 분할은 해시 분할이라고 합니다. 데이터 분할에 대한 자세한 내용은 21장에서 다룹니다.

샤딩이 응용 프로그램 코드에서 수행될 때, 응용 프로그램은 어떤 키가 어떤 데이터베이스에 저장되어 있는지 추적하고 질의를 적절한 데이터베이스로 라우팅해야 합니다. 여러 데이터베이스에서 데이터를 읽거나 업데이트하는 질의는 단일 질의를 제출하여 모든 데이터베이스에서 실행할 수 없으므로 간단히 처리할 수 없습니다. 대신, 응용 프로그램은 여러 데이터베이스에서 데이터를 읽고 최종 질의 결과를 계산해야 합니다. 여러 데이터베이스에 걸친 업데이트는 추가적인 문제를 야기합니다.

응용 프로그램 코드에서 샤딩을 수행하는 것은 응용 프로그램을 확장하는 간단한 방법을 제공하지만, 접근 방식의 한계도 명확합니다. 첫째, 응용 프로그램 코드는 데이터가 어떻게 분할되었는지 추적하고 질의를 적절하게 라우팅해야 합니다. 데이터베이스가 과부하되면 그 데이터베이스의 일부 데이터를 새 데이터베이스나 다른 기존 데이터베이스로 이동시켜야 합니다. 이를 관리하는 것은 간단한 작업이 아닙니다. 더 많은 데이터베이스가 추가됨에 따라 데이터 접근 손실로 이어질 가능성이 더 커집니다. 복제는 데이터를 접근 가능하게 유지하는 데 필요하지만, 복제를 관리하고 일관성을 유지하는 것은 추가적인 도전을 제공합니다. 키-값 저장소는 이러한 문제 중 일부를 해결합니다.

#### 10.2.3 키-값 저장 시스템

많은 웹 응용 프로그램은 매우 많은 수(수십억 개 또는 극단적인 경우 수조 개)의 상대적으로 작은 레코드(크기가 몇 킬로바이트에서 몇 메가바이트)를 저장해야 합니다. 각 레코드를 별도의 파일로 저장하는 것은 불가능합니다. 파일 시스템, 특히 분산 파일 시스템은 그렇게 많은 수의 파일을 저장하도록 설계되지 않았기 때문입니다.

이론적으로는 대규모 병렬 관계형 데이터베이스를 사용하여 이러한 데이터를 저장해야 합니다. 그러나 많은 기계에서 병렬로 실행되면서도 외래 키 제약 조건 및 트랜잭션과 같은 표준 데이터베이스 기능을 지원하는 관계형 데이터베이스 시스템을 구축하는 것은 쉽지 않습니다.

수천에서 수만 대의 기계로 확장할 수 있는 여러 저장 시스템이 개발되었지만, 일반적으로 단순한 키-값 저장 인터페이스만 제공합니다. 키-값 저장 시스템(또는 키-값 저장소)은 키와 관련된 레코드를 저장하거나 업데이트하고 지정된 키로 레코드를 검색하는 방법을 제공합니다.

병렬 키-값 저장소는 키를 여러 기계에 분할하고 업데이트 및 조회를 올바른 기계로 라우팅합니다. 또한 복제를 지원하고 복제본이 일관되게 유지되도록 합니다. 또한 필요할 때 더 많은 기계를 시스템에 추가할 수 있도록 하고 시스템의 기계 간에 부하가 자동으로 균형 잡히도록 합니다. 응용 프로그램 코드에서 샤딩을 구현하는 시스템과 달리, 병렬 키-값 저장소를 사용하는 시스템은 위의 문제를 걱정할 필요가 없습니다. 따라서 병렬 키-값 저장소는 오늘날 샤딩보다 더 널리 사용됩니다.

널리 사용되는 병렬 키-값 저장소에는 Google의 Bigtable, Apache HBase, Amazon의 Dynamo, Facebook의 Cassandra, MongoDB, Microsoft의 Azure 클라우드 저장소, Yahoo!의 Sherpa/PNUTS 등이 있습니다.

여러 키-값 데이터 저장소는 저장된 값을 비해석적인 바이트 시퀀스로 보고 그 내용을 보지 않지만, 다른 데이터 저장소는 각 레코드에 일부 구조 또는 스키마를 연결할 수 있게 합니다. 여러 키-값 저장 시스템은 저장된 데이터가 지정된 데이터 표현을 따르도록 요구하여 데이터 저장소가 저장된 값을 해석하고 저장된 값을 기반으로 간단한 질의를 실행할 수 있게 합니다. 이러한 데이터 저장소를 문서 저장소라고 합니다. MongoDB는 JSON 형식의 값을 수용하는 널리 사용되는 데이터 저장소입니다.

키-값 저장 시스템의 핵심은 put(key, value)와 get(key)라는 두 가지 기본 함수에 기반합니다. put(key, value)는 키와 함께 값을 저장하는 데 사용되며, get(key)는 지정된 키와 연관된 저장된 값을 검색하는 데 사용됩니다. Bigtable과 같은 일부 시스템은 추가적으로 키 값에 대한 범위 질의를 제공합니다. 문서 저장소는 추가적으로 저장된 값에 대한 제한된 형태의 질의를 지원합니다.

키-값 저장소의 중요한 동기는 매우 큰 양의 데이터와 질의를 처리할 수 있는 능력입니다. 키-값 저장소는 클러스터의 많은 기계에 작업을 분산하여 데이터를 처리합니다. 레코드는 클러스터의 기계 간에 분할되어 각 기계가 레코드의 하위 집합을 저장

하고 그 레코드에 대한 조회 및 업데이트를 처리합니다.

키-값 저장소는 오늘날 데이터베이스 시스템에서 표준으로 간주되는 많은 기능을 제공하지 않기 때문에 완전한 데이터베이스는 아닙니다. 키-값 저장소는 일반적으로 선언적 질의(SQL 또는 다른 선언적 질의 언어 사용)를 지원하지 않으며, 트랜잭션도 지원하지 않습니다. 트랜잭션은 다중 업데이트를 원자적으로 커밋하여 실패에도 불구하고 데이터베이스 상태가 일관되게 유지되고, 다중 트랜잭션에 의한 동시 접근으로 인한 문제가 발생하지 않도록 합니다. 키-값 저장소는 또한 일반적으로 비키 속성에 대한 선택을 기반으로 한 레코드 검색을 지원하지 않지만, 일부 문서 저장소는 이러한 검색을 지원합니다.

이러한 기능을 지원하지 않는 중요한 이유 중 일부는 매우 큰 클러스터에서 지원하는 것이 쉽지 않기 때문입니다. 따라서 대부분의 시스템은 확장성을 위해 이러한 기능을 희생합니다. 확장성을 필요로 하는 응용 프로그램은 이러한 기능을 포기하고 확장성을 얻으려 할 수 있습니다.

키-값 저장소는 NoSQL 시스템이라고도 하며, 이는 SQL을 지원하지 않음을 강조하기 위함입니다. SQL의 지원 부족은 제한이 아니라 긍정적인 것으로 간주되었습니다. 그러나 트랜잭션 지원 및 SQL 지원과 같은 데이터베이스 기능의 부족이 응용 프로그램 개발을 더 복잡하게 만든다는 것이 곧 명확해졌습니다. 따라서 많은 키-값 저장소가 SQL 언어 및 트랜잭션과 같은 기능을 지원하도록 진화했습니다.

이러한 시스템이 데이터를 저장하고 접근하기 위해 제공하는 API는 널리 사용됩니다. 앞에서 언급한 기본 get() 및 put() 함수는 간단하지만, 대부분의 시스템은 추가 기능을 지원합니다. 이러한 API의 예로, MongoDB API를 간략히 설명합니다.

그림 10.2는 JavaScript 쉘 인터페이스를 통해 MongoDB 문서 저장소에 접근하는 것을 보여줍니다. 이러한 쉘은 MongoDB가 설치되고 구성된 시스템에서 mongo 명령을 실행하여 열 수 있습니다. MongoDB는 Java 및 Python을 포함한 다양한 언어에서 등가의 API 기능을 제공합니다. 그림에 표시된 use 명령은 지정된 데이터베이스를 열고, 존재하지 않으면 생성합니다. db.createCollection() 명령은 문서를 저장하는 컬렉션을 생성하는 데 사용됩니다. MongoDB의 문서는 기본적으로 JSON 객체입니다. 그림에서는 student와 instructor 두 개의 컬렉션을 생성하고 JSON 객체를 컬렉션에 삽입합니다.

MongoDB는 삽입된 객체에 대해 식별자를 자동으로 생성하며, 이는 객체를 검색하는 데 키로 사용할 수 있습니다. 객체와 연관된 키는 id 속성을 사용하여 검색할 수 있으며, 이 속성에 대한 인덱스가 기본적으로 생성됩니다.

MongoDB는 저장된 값을 기반으로 한 질의도 지원합니다. db.student.find() 함수는 student 컬렉션의 모든 객체를 반환하고, findOne() 함수는 컬렉션에서 하나의 객체를 반환합니다. 두 함수는 원하는 속성에 대한 선택을 지정하는 JSON 객체를 인수로 받을 수 있습니다. 예제에서는 ID가 00128인 학생을 검색합니다. 마찬가지로, remove() 함수를 사용하여 이러한 선택과 일치하는 모든 객체를 삭제할 수 있습니다. drop() 함수는 전체 컬렉션을 삭제합니다.

MongoDB는 저장된 JSON 객체의 지정된 속성(예: ID 및 이름 속성)에 대한 인덱스 생성을 비롯한 다양한 기능을 지원합니다.

MongoDB의 주요 목표는 매우 큰 데이터 크기 및 질의/업데이트 부하에 대한 확장을 가능하게 하는 것입니다. MongoDB는 여러 기계가 단일 MongoDB 클러스터의 일부가 될 수 있도록 합니다. 그런 다음 데이터는 이러한 기계에 분할됩니다. 데이터의 기계 간 분할에 대한 자세한 내용은 21장에서 다루며, 질의의 병렬 처리에 대한 자세한 내용은 22장에서 다룹니다. 그러나 이 절에서는 핵심 아이디어를 간략히 설명합니다.

MongoDB(및 많은 다른 데이터베이스)에서는 분할이 분할 속성 또는 샤드 키라고 하는 지정된 속성 값을 기반으로 수행됩니다. 예를 들어, student 컬렉션이 deptname 속성을 기준으로 분할되도록 지정하면 특정 학과의 모든 객체는 한 기계에 저장되지만, 다른 학과의 객체는 다른 기계에 저장될 수 있습니다. 기계가 고장났을 때도 데이터를 접근할 수 있도록 각 분할은 여러 기계에 복제됩니다. 이 방법으로, 하나의 기계가 고장나도 해당 분할의 데이터를 다른 기계에서 가져올 수 있습니다.

MongoDB 클라이언트의 요청은 라우터로 전송되며, 라우터는 클러스터의 적절한 분할로 요청을 전달합니다.

Bigtable은 저장 시스템이 저장된 값의 개별 부분에 접근할 수 있는 형식을 따르도록 요구하는 또 다른 키-값 저장소입니다. Bigtable에서 데이터 값(레코드)은 여러 속성을 가질 수 있으며, 속성 이름 세트는 사전 결정되지 않으며 다른 레코드 간에 다를 수 있습니다. 따라서 속성 값의 키는 개념적으로 (레코드 식별자, 속성 이름)으로 구성됩니다. 각 속성 값은 Bigtable에 대해 단순한 문자열입니다. 레코드의 모든 속성을 검색하려면 범위 질의, 정확히 말하면 레코드 식별자만 포함하는 접두사 일치 질의가 사용됩니다. get() 함수는 값과 함께 속성 이름을 반환합니다. 특정 레코드의 모든 속성을 효율적으로 검색하기 위해 저장 시스템은 키별로 정렬된 상태로 항목을 저장하여 특정 레코드의 모든 속성 값이 함께 클러스터링되도록 합니다.

사실, 레코드 식별자는 계층적으로 구조화될 수 있지만, Bigtable 자체에서 레코드 식별자는 단순한 문자열입니다. 예를 들어, 웹 크롤에서 검색된 페이지를 저장하는 응용 프로그램은 다음과 같은 URL을 다음과 같은 레코드 식별자로 매핑할 수 있습니다:
```
www.cs.yale.edu/people/silberschatz.html
```
```
edu.yale.cs.www/people/silberschatz.html
```
이 표현을 사용하면, cs.yale.edu의 모든 URL은 접두사 edu.yale.cs가 있는 모든 키를 검색하는 질의로 검색될 수 있으며, 이는 정렬된 키 순서에서 연속된 키 값 범위에 저장됩니다. 마찬가지로 yale.edu의 모든 URL은 접두사 edu.yale을 가지며 연속된 키 값 범위에 저장됩니다.

Bigtable은 JSON을 네이티브로 지원하지 않지만, JSON 데이터를 Bigtable의 데이터 모델에 매핑할 수 있습니다. 예를 들어, 다음 JSON 데이터를 고려해 봅시다:
```json
{ "ID": "22222",
  "name": { "firstname": "Albert", "lastname": "Einstein" },
  "deptname": "Physics",
  "children": [
    {"firstname": "Hans", "lastname": "Einstein" },
    {"firstname": "Eduard", "lastname": "Einstein" }
  ]
}
```
위의 데이터는 "22222" 식별자를 가진 Bigtable 레코드로 표현될 수 있으며, 여러 속성 이름(예: "name.firstname", "deptname", "children[1].firstname" 또는 "children[2].lastname")을 가질 수 있습니다.

또한, Bigtable의 단일 인스턴스는 단순히 응용 프로그램 이름과 테이블 이름을 레코드 식별자에 접두사로 추가하여 여러 응용 프로그램의 데이터를 저장할 수 있습니다.

많은 데이터 저장 시스템은 데이터 항목의 여러 버전을 저장할 수 있습니다. 버전은 종종 타임스탬프로 식별되지만, 새 버전의 데이터 항목이 생성될 때마다 증가하는 정수 값으로 식별될 수도 있습니다. 조회는 필요한 데이터 항목의 버전을 지정하거나 가장 높은 버전 번호를 가진 버전을 선택할 수 있습니다. 예를 들어, Bigtable에서 키는 실제로 (레코드 식별자, 속성 이름, 타임스탬프)로 구성됩니다. Bigtable은 Google에서 서비스로 접근할 수 있습니다. Bigtable의 오픈 소스 버전인 HBase는 널리 사용됩니다.

#### 10.2.4 병렬 및 분산 데이터베이스

병렬 데이터베이스는 여러 기계에서 실행되며 데이터를 여러 기계에 저장하고 대규모 질의를 여러 기계를 사용하여 처리하도록 설계된 데이터베이스입니다. 병렬 데이터베이스는 1980년대에 처음 개발되었으며, 현대 빅 데이터 시스템보다 앞서 개발되었습니다. 프로그래머 관점에서 병렬 데이터베이스는 단일 기계에서 실행되는 데이터베이스처럼 사용할 수 있습니다.

초기 병렬 데이터베이스는 트랜잭션 처리를 위해 설계되었으며, 클러스터 내에서 몇 개의 기계만 지원했습니다. 반면, 대규모 분석 질의를 처리하도록

 설계된 데이터베이스는 수십에서 수백 대의 기계를 지원하도록 설계되었습니다. 데이터는 클러스터 내 여러 기계에 복제되어 데이터가 손실되지 않고, 클러스터 내의 기계가 고장나도 계속 접근할 수 있도록 합니다. 수십에서 수백 대의 기계를 가진 시스템에서 질의를 처리하는 동안 고장이 발생하면, 고장이 발생한 노드에서 질의를 다시 시작하고, 다른 노드에 있는 데이터 복제본을 사용합니다.

수천 대의 기계를 가진 클러스터에서 이러한 데이터베이스 시스템을 실행하면, 질의를 실행하는 동안 고장이 발생할 확률이 크게 증가합니다. 질의가 실행되는 동안 고장이 발생하면 질의를 다시 시작하는 것은 더 이상 옵션이 아닙니다. 실행 중에 또 다른 고장이 발생할 확률이 높기 때문입니다. 맵리듀스 시스템에서는 이러한 문제를 해결하기 위해 고장이 발생한 기계에서만 다시 계산하는 기술이 개발되었습니다. 이러한 기술은 상당한 오버헤드를 초래합니다. 수천에서 수만 대의 노드를 사용하는 계산은 일부 예외적으로 큰 응용 프로그램에만 필요하기 때문에 오늘날 대부분의 병렬 관계형 데이터베이스 시스템은 수십에서 수백 대의 기계에서 실행되는 응용 프로그램을 대상으로 하며 고장이 발생하면 질의를 다시 시작합니다.

이러한 병렬 및 분산 데이터베이스에서의 질의 처리는 22장에서, 이러한 데이터베이스에서의 트랜잭션 처리는 23장에서 자세히 다룹니다.

#### 10.2.5 복제와 일관성

복제는 데이터의 가용성을 보장하기 위한 핵심 요소로, 일부 데이터 항목을 저장하는 기계가 고장나도 데이터 항목에 접근할 수 있도록 합니다. 데이터 항목에 대한 업데이트는 해당 데이터 항목의 모든 복제본에 적용되어야 합니다. 모든 복제본을 포함하는 기계가 모두 활성 상태이고 상호 연결되어 있으면, 모든 복제본에 업데이트를 적용하는 것은 간단합니다.

그러나 기계가 고장날 수 있기 때문에 두 가지 주요 문제가 있습니다. 첫째, 둘 이상의 기계에서 데이터를 업데이트하는 트랜잭션의 원자적 실행을 어떻게 보장할 것인가입니다. 트랜잭션 실행이 원자적이라는 것은 실패에도 불구하고 트랜잭션이 업데이트한 모든 데이터 항목이 성공적으로 업데이트되거나 모든 데이터 항목이 원래 값으로 되돌아가야 한다는 것을 의미합니다. 둘째, 일부 복제본이 있는 기계가 고장난 경우 데이터 항목에 대한 업데이트를 어떻게 수행할 것인가입니다. 여기서 중요한 요구 사항은 일관성으로, 모든 활성 복제본이 동일한 값을 가져야 하며, 각 읽기 작업이 데이터 항목의 최신 버전을 봐야 합니다. 이러한 문제에 대한 여러 가지 가능한 솔루션이 있으며, 각 솔루션은 다른 수준의 실패 회복성을 제공합니다. 두 가지 문제에 대한 솔루션은 23장에서 다룹니다.

두 번째 문제에 대한 솔루션은 일반적으로 복제본의 과반수가 읽기 및 업데이트에 사용할 수 있어야 한다는 것을 요구합니다. 3개의 복제본이 있는 경우, 이는 1개 이상의 복제본이 실패하지 않아야 한다는 것을 의미하지만, 5개의 복제본이 있는 경우 두 대의 기계가 실패해도 과반수의 복제본이 여전히 사용할 수 있습니다. 이러한 가정 하에서는 쓰기가 차단되지 않으며, 읽기는 데이터 항목의 최신 값을 봅니다.

여러 기계의 고장 확률은 상대적으로 낮지만, 네트워크 링크 고장은 추가 문제를 야기할 수 있습니다. 특히, 네트워크 파티션은 네트워크의 두 활성 기계가 서로 통신할 수 없는 경우 발생합니다.

네트워크 파티션이 발생하는 상황에서 가용성(데이터를 읽고 쓸 수 있는 능력)을 보장하면서 일관성을 보장하는 프로토콜은 존재하지 않는다는 것이 입증되었습니다. 따라서 분산 시스템은 타협을 해야 합니다. 높은 가용성을 원하면, 일관성을 희생해야 합니다. 예를 들어, 데이터를 읽을 때 이전 값을 볼 수 있거나, 복제본이 서로 다른 값을 가지도록 허용해야 합니다. 후자의 경우, 복제본을 통합하여 공통 값을 만드는 것은 응용 프로그램이 처리해야 하는 작업입니다. 일부 응용 프로그램 또는 응용 프로그램의 일부는 가용성을 우선시하여 일관성을 희생할 수 있습니다. 그러나 다른 응용 프로그램 또는 응용 프로그램의 일부는 실패 시 시스템의 잠재적 비가용성을 감수하더라도 일관성을 우선시할 수 있습니다. 이러한 문제는 23장에서 더 자세히 논의됩니다.

### 10.3 MapReduce 패러다임

MapReduce 패러다임은 많은 입력 레코드 각각에 대해 `map()` 함수로 식별된 처리를 수행한 후, `reduce()` 함수로 식별된 형태의 집계를 수행하는 병렬 처리의 일반적인 상황을 모델링합니다. `map()` 함수는 그룹화 키를 지정할 수도 있으며, 이 경우 `reduce()` 함수에서 지정된 집계는 `map()` 출력의 그룹화 키에 따라 각 그룹 내에서 수행됩니다. 이 섹션에서는 MapReduce 패러다임과 `map()` 및 `reduce()` 함수에 대해 자세히 살펴봅니다.

MapReduce 패러다임은 함수형 프로그래밍 및 병렬 처리 커뮤니티에서 몇십 년 전부터 존재해 왔습니다(예: Lisp 언어에서 `map` 및 `reduce` 함수 지원).

#### 10.3.1 왜 MapReduce인가?

MapReduce 패러다임 사용의 동기를 부여하는 예로, 많은 파일을 입력으로 받아 각 단어가 모든 파일에서 몇 번 등장하는지 세는 단어 개수 응용 프로그램을 고려해 보겠습니다. 여기서 입력은 디렉토리에 저장된 잠재적으로 많은 파일의 형태일 수 있습니다.

단일 파일의 경우, 파일의 단어를 읽고 지금까지 발견된 모든 단어와 그 개수를 추적하는 메모리 내 데이터 구조를 유지하는 프로그램을 작성하는 것은 간단합니다. 문제는 순차적인 성격의 위 알고리즘을 각 파일에 수십에서 수백 메가바이트의 데이터가 포함된 수만 개의 파일이 있는 환경으로 확장하는 방법입니다. 이렇게 대량의 데이터를 순차적으로 처리하는 것은 불가능합니다.

하나의 솔루션은 많은 머신에서 병렬로 실행되는 프로그램으로 코딩하여 각 머신이 파일의 일부를 처리하게 하는 것입니다. 그런 다음 각 머신에서 로컬로 계산된 개수를 결합하여 최종 개수를 얻어야 합니다. 이 경우 프로그래머는 서로 다른 머신에서 작업을 시작하고 조정하며 최종 답을 계산하는 데 필요한 모든 "배관"을 책임져야 합니다. 또한, 프로그램이 완료되도록 보장하기 위해 머신 고장에도 대처해야 합니다. 수천 대의 머신이 참여하고 프로그램이 오랜 시간 동안 실행되는 경우 고장은 상당히 빈번하게 발생합니다.

위 요구 사항을 구현하는 "배관" 코드는 매우 복잡합니다. 이를 한 번만 작성하고 모든 응용 프로그램에 재사용하는 것이 타당합니다.

MapReduce 시스템은 응용 프로그램에 필요한 핵심 로직을 지정할 수 있는 방법을 제공하며, 앞서 언급한 배관의 세부 사항은 MapReduce 시스템이 처리합니다. 프로그래머는 `map()` 및 `reduce()` 함수만 제공하면 되며, 옵션으로 데이터 읽기 및 쓰기 함수를 추가할 수 있습니다. 프로그래머가 제공한 `map()` 및 `reduce()` 함수는 MapReduce 시스템에 의해 호출되어 데이터를 병렬로 처리합니다. 프로그래머는 배관이나 그 복잡성을 인식할 필요가 없으며, 실제로 프로그램이 여러 머신에서 병렬로 실행된다는 사실을 대부분 무시할 수 있습니다.

MapReduce 접근 방식은 다양한 응용 프로그램에 대해 대량의 데이터를 처리하는 데 사용할 수 있습니다. 앞서 언급한 단어 개수 프로그램은 텍스트 및 문서 처리 응용 프로그램 클래스의 장난감 예제입니다. 예를 들어, 키워드를 입력하면 해당 키워드를 포함하는 문서를 반환하는 검색 엔진을 생각해 보세요. MapReduce는 예를 들어 문서를 처리하고 텍스트 인덱스를 생성하는 데 사용할 수 있으며, 이는 지정된 키워드를 포함하는 문서를 효율적으로 찾는 데 사용됩니다.

#### 10.3.2 예제로 본 MapReduce 1: 단어 개수

우리의 단어 개수 응용 프로그램은 다음과 같은 함수를 사용하여 MapReduce 프레임워크에서 구현할 수 있습니다. 이 의사 코드는 특정 프로그래밍 언어에 속하지 않으며 개념을 소개하는 데 목적이 있습니다. 특정 언어로 MapReduce 코드를 작성하는 방법은 나중에 설명합니다.

1. MapReduce 패러다임에서는 프로그래머가 제공한 `map()` 함수가 각 입력 레코드에 대해 호출되며, 0개 이상의 출력 데이터 항목을 방출하여 `reduce()` 함수로 전달됩니다. 첫 번째 질문은 레코드가 무엇인가 하는 것입니다. MapReduce 시스템은 기본적으로 각 입력 파일의 각 줄을 레코드로 간주합니다. 이러한 기본값은 단어 개수 응용 프로그램에 잘 맞지만, 프로그래머는 입력 파일을 레코드로 나누는 자체 함수를 지정할 수 있습니다.

단어 개수 응용 프로그램의 경우, `map()` 함수는 각 레코드(줄)를 개별 단어로 나누고 각 단어의 출현 횟수를 포함하는 쌍(단어, 개수)을 출력하는 여러 레코드를 생성할 수 있습니다. 실제로 단순화된 구현에서는 `map()` 함수가 더 적은 작업을 수행하고, 발견된 각 단어를 개수 1로 출력합니다. 이러한 개수는 나중에 `reduce()`에 의해 더해집니다. 단어 개수 프로그램에 대한 `map()` 함수의 의사 코드는 그림 10.3에 나와 있습니다. 이 함수는 레코드(줄)를 개별 단어로 나눕니다. 각 단어가 발견되면 `map()` 함수는 레코드(단어, 1)를 방출합니다. 따라서 파일에 "One a penny, two a penny, hot cross buns."라는 문장만 포함된 경우, `map()` 함수가 출력하는 레코드는 다음과 같습니다.

```
("one", 1), ("a", 1), ("penny", 1), ("two", 1), ("a", 1), ("penny", 1), ("hot", 1), ("cross", 1), ("buns", 1)
```

일반적으로 `map()` 함수는 각 입력 레코드에 대해 (키, 값) 쌍의 집합을 출력합니다. `map()` 출력 레코드의 첫 번째 속성(키)은 `reduce` 단계에서 사용되므로 `reduce` 키라고 합니다.

2. MapReduce 시스템은 `map()` 함수가 방출한 모든 (키, 값) 쌍을 정렬(또는 최소한 그룹화)하여 특정 키와 일치하는 모든 레코드를 함께 모읍니다. 키가 일치하는 모든 레코드를 그룹화하고, 관련된 값의 목록을 만듭니다. 그런 다음 (키, 목록) 쌍이 `reduce()` 함수로 전달됩니다.

우리의 단어 개수 예제에서는 각 키가 단어이고, 관련 목록은 다른 파일의 다른 줄에서 생성된 개수의 목록입니다. 예제 데이터로 이 단계의 결과는 다음과 같습니다:

```
("a", [1, 1]), ("buns", [1]), ("cross", [1]), ("hot", [1]), ("one", [1]), ("penny", [1, 1]), ("two", [1])
```

우리의 예제에서 `reduce()` 함수는 단어 개수 목록을 결합하여 개수를 더하고, (단어, 총 개수) 쌍을 출력합니다. 예제 입력의 경우, `reduce()` 함수가 출력하는 레코드는 다음과 같습니다:

```
("one", 1), ("a", 2), ("penny", 2), ("two", 1), ("hot", 1), ("cross", 1), ("buns", 1)
```

단어 개수 프로그램에 대한 `reduce()` 함수의 의사 코드는 그림 10.3에 나와 있습니다. `map()` 함수가 생성한 개수는 모두 1이므로, `reduce()` 함수는 목록의 값 수를 세기만 하면 되지만, 나중에 볼 최적화를 위해 값을 더하는 것이 더 유리합니다.

여기서 중요한 문제는 많은 파일에서 동일한 단어가 여러 번 등장할 수 있다는 것입니다. `map()` 함수의 출력을 재구성하여 특정 키의 모든 값을 함께 가져와야 합니다. 여러 머신을 사용하는 병렬 시스템에서는 이 작업을 위해 다른 머신 간에 `reduce` 키에 대한 데이터를 교환해야 하므로, 특정 `reduce` 키에 대한 모든 값이 단일 머신에 있어야 합니다. 이 작업은 셔플 단계에서 수행되며, 셔플 단계는 머신 간 데이터 교환을 수행하고 (키, 값) 쌍을 정렬하여 특정 키의 모든 값을 함께 가져옵니다. 예제에서 단어가 실제로 알파벳순으로 정렬된 것을 관찰할 수 있습니다. `map()` 출력 레코드를 정렬하는 것은 시스템이 단어의 모든 출현을 함께 수집하는 한 가지 방법입니다. 각 단어의 목록은 정렬된 레코드에서 생성됩니다.

기본적으로 `reduce()` 함수의 출력은 하나 이상의 파일로 전송되지만, MapReduce 시스템은 프로그래머가 출력에 대해 수행할 작업을 제어할 수 있도록 합니다.

#### 10.3.3 예제로 본 MapReduce 2: 로그 처리

MapReduce 패러다임 사용의 또 다른 예로, 전통적인 데이터베이스 쿼리 처리를 더 가까이

서 살펴보면, 웹사이트 접근을 기록한 로그 파일을 가지고 있다고 가정해 보겠습니다. 이 로그 파일은 그림 10.4에 나와 있는 것처럼 구성되어 있습니다. 파일 접근 개수 응용 프로그램의 목표는 2013년 1월 1일부터 2013년 1월 31일까지 slide-dir 디렉터리에 있는 각 파일이 몇 번 접근되었는지를 찾는 것입니다. 이 응용 프로그램은 웹 로그 파일의 데이터를 사용하여 분석가가 묻는 다양한 종류의 질문 중 하나를 예시합니다.

우리의 로그 파일 처리 응용 프로그램에서는 입력 파일의 각 줄을 레코드로 간주할 수 있습니다. `map()` 함수는 먼저 입력 레코드를 개별 필드, 즉 날짜, 시간, 파일 이름으로 분할합니다. 날짜가 필요한 날짜 범위에 있으면, `map()` 함수는 해당 레코드에서 파일 이름이 한 번 등장했다는 것을 나타내는 레코드(파일 이름, 1)를 방출합니다. 이 예제의 `map()` 함수에 대한 의사 코드는 그림 10.5에 나와 있습니다.

셔플 단계는 특정 `reduce` 키(이 경우 파일 이름)에 대한 모든 값을 목록으로 모읍니다. 그림 10.6에 나와 있는 프로그래머가 제공한 `reduce()` 함수는 그런 다음 각 `reduce` 키 값에 대해 호출됩니다. `reduce()`의 첫 번째 인수는 `reduce` 키 자체이고, 두 번째 인수는 해당 `reduce` 키에 대해 `map()` 함수가 방출한 레코드의 값 목록입니다. 이 예제에서는 특정 키에 대한 값을 더하여 파일의 총 접근 횟수를 구합니다. 그런 다음 `reduce()` 함수가 이 숫자를 출력합니다.

`map()` 함수가 생성한 값을 사용하면, 방출된 모든 레코드의 값은 "1"이므로 목록의 요소 수를 세기만 하면 됩니다. 그러나 MapReduce 시스템은 값이 재분배되기 전에 각 입력 파일의 값에 대한 부분적인 합산을 수행하는 등의 최적화를 지원합니다. 그런 경우, `reduce()` 함수가 받는 값은 반드시 1이 아니므로, 값을 더해야 합니다.

그림 10.7은 `map()` 및 `reduce()` 함수의 흐름을 개략적으로 보여줍니다. 그림에서 `mki`는 `map` 키, `mvi`는 `map` 입력 값, `rki`는 `reduce` 키, `rvi`는 `reduce` 입력 값을 나타냅니다. `reduce` 출력은 표시되지 않습니다.

#### 10.3.4 MapReduce 작업의 병렬 처리

지금까지 `map()` 및 `reduce()` 함수에 대한 설명에서는 병렬 처리 문제를 무시했습니다. MapReduce 코드를 병렬 처리에 대해 고려하지 않고도 이해할 수 있습니다. 그러나 MapReduce 패러다임을 사용하는 우리의 목표는 병렬 처리를 가능하게 하는 것입니다. 따라서 MapReduce 시스템은 여러 머신에서 `map()` 함수를 병렬로 실행하며, 각 `map` 작업은 데이터의 일부를 처리합니다. 예를 들어 일부 파일 또는 매우 큰 입력 파일의 경우 파일의 일부를 처리합니다. 마찬가지로 `reduce()` 함수도 여러 머신에서 병렬로 실행되며, 각 `reduce` 작업은 `reduce` 키의 하위 집합을 처리합니다(특정 `reduce()` 함수 호출은 여전히 단일 `reduce` 키에 대해 수행됨).

그림 10.8은 `map` 및 `reduce` 작업의 병렬 실행을 그림으로 보여줍니다. 그림에서 입력 파일 파티션은 Part i로 표시되며, 파일 또는 파일의 일부일 수 있습니다. Map i로 표시된 노드는 `map` 작업이고, Reduce i로 표시된 노드는 `reduce` 작업입니다. 마스터 노드는 `map()` 및 `reduce()` 코드의 사본을 `map` 및 `reduce` 작업에 보냅니다. `map` 작업은 코드를 실행하고 출력 데이터를 로컬 파일에 씁니다. 이 데이터는 `reduce` 키 값에 따라 정렬되고 파티션됩니다. 각 `Map` 노드에서 각 `reduce` 작업에 대해 별도의 파일이 생성됩니다. 이러한 파일은 네트워크를 통해 `reduce` 작업에 의해 가져옵니다. 각 `reduce` 작업이 가져온 파일(여러 `map` 작업에서 가져옴)은 병합되고 정렬되어 특정 `reduce` 키의 모든 값이 정렬된 파일에 함께 있게 됩니다. 그런 다음 `reduce` 키와 값이 `reduce()` 함수에 전달됩니다.

MapReduce 시스템은 또한 여러 머신에 걸쳐 파일 입력과 출력을 병렬화해야 합니다. 그렇지 않으면 데이터를 저장하는 단일 머신이 병목 현상이 될 것입니다. 파일 입력과 출력을 병렬화하려면 Hadoop 파일 시스템(HDFS)과 같은 분산 파일 시스템을 사용할 수 있습니다. 10.2절에서 보았듯이, 분산 파일 시스템은 여러 머신이 파일 저장을 협력할 수 있도록 합니다. 파일 시스템 데이터는 일반적으로 세 대의 머신에 복제(복사)되어 몇몇 머신이 고장 나더라도 데이터를 사용할 수 있습니다.

오늘날 HDFS와 같은 분산 파일 시스템 외에도 MapReduce 시스템은 HBase, MongoDB, Cassandra 및 Amazon Dynamo와 같은 다양한 빅데이터 저장 시스템에서 입력을 지원합니다. 출력도 마찬가지로 이러한 저장 시스템 중 어느 곳으로든 보낼 수 있습니다.

#### 10.3.5 Hadoop에서의 MapReduce

Hadoop 프로젝트는 Java 언어로 MapReduce의 널리 사용되는 오픈 소스 구현을 제공합니다. 여기서는 Hadoop이 제공하는 Java API를 사용하여 주요 기능을 요약합니다. Hadoop은 Python 및 C++와 같은 여러 다른 언어로도 MapReduce API를 제공합니다.

우리의 MapReduce 의사 코드와 달리, Hadoop과 같은 실제 구현에서는 `map()` 함수의 입력 키 및 값, 출력 키 및 값에 대한 타입을 지정해야 합니다. 마찬가지로, `reduce()` 함수의 입력 및 출력 키와 값의 타입도 지정해야 합니다. Hadoop은 프로그래머가 Hadoop Mapper 및 Reducer 클래스를 확장하는 클래스의 멤버 함수로 `map()` 및 `reduce()` 함수를 구현하도록 요구합니다. Hadoop은 프로그래머가 파일을 레코드로 분할하는 함수를 제공하거나, 파일을 레코드로 분할하는 기본 제공 함수를 사용하는 파일 유형 중 하나로 파일을 지정할 수 있도록 합니다. 예를 들어, TextInputFormat은 파일을 줄로 분할하여 각 줄을 별도의 레코드로 처리하도록 지정합니다. 오늘날 압축 파일 형식이 널리 사용되며, Avro, ORC 및 Parquet이 Hadoop 세계에서 가장 널리 사용되는 압축 파일 형식입니다(압축 파일 형식에 대해서는 13.6절에서 더 자세히 설명합니다). 시스템은 압축 해제를 수행하며, 쿼리를 작성하는 프로그래머는 지원되는 유형 중 하나만 지정하면, 쿼리를 구현하는 코드에서 압축 해제된 표현을 사용할 수 있습니다.

Hadoop에서는 입력 파일이 단일 머신의 파일 시스템에서 올 수 있지만, 대형 데이터 세트의 경우 단일 머신의 파일 시스템이 성능 병목이 됩니다. Hadoop MapReduce는 HDFS와 같은 분산 파일 시스템에 입력 및 출력 파일을 저장할 수 있도록 하여 여러 머신이 병렬로 데이터를 읽고 쓸 수 있습니다.

`reduce()` 함수 외에도, Hadoop은 프로그래머가 `map()` 함수가 실행되는 노드에서 `reduce()` 작업의 일부를 수행할 수 있는 `combine()` 함수를 정의할 수 있도록 합니다. 우리의 단어 개수 예제에서 `combine()` 함수는 앞서 본 `reduce()` 함수와 동일합니다. 그런 다음 `reduce()` 함수는 특정 단어에 대한 부분 개수 목록을 받게 됩니다. 단어 개수의 `reduce()` 함수는 값을 합산하므로 `combine()` 함수와 함께 사용해도 제대로 작동합니다. `combine()` 함수를 사용하면 네트워크를 통해 전송해야 하는 데이터 양이 줄어듭니다. `map` 작업을 실행하는 각 노드는 여러 항목 대신 단일 항목을 네트워크를 통해 전송하게 됩니다.

Hadoop에서 단일 MapReduce 단계는 `map` 및 `reduce` 함수를 실행합니다. 프로그램은 여러 MapReduce 단계를 가질 수 있으며, 각 단계마다 자체 `map` 및 `reduce` 함수가 있습니다. Hadoop API는 프로그램이 여러 MapReduce 단계를 실행할 수 있도록 합니다. 각 단계의 `reduce()` 출력은 (분산된) 파일 시스템에 쓰여지고 다음 단계에서 다시 읽습니다. Hadoop은 또한 프로그래머가 작업에 대해 병렬로 실행할 `map` 및 `reduce` 작업의 수를 제어할 수 있도록 합니다.

이 섹션의 나머지 부분은 Java에 대한 기본 지식을 전제로 합니다(Java에 익숙하지 않은 경우 이 섹션의 나머지 부분을 건너뛰어도 계속 읽는 데 문제가 없습니다).

그림 10.9는 앞서 본 단어 개수 응용 프로그램의 Hadoop Java 구현을 보여줍니다. 간결함을 위해 Java import 문을 생략했습니다. 이 코드는 Mapper 인터페이스를 구현하는 클래스와 Reducer 인터페이스를 구현하는 또 다른 클래스를 정의합니다. Mapper 및 Reducer 클래스는 입력 키, 입력 값, 출력 키 및 출력 값의 타입을 지정하는 네 가지 타입 인

수를 사용하는 제네릭 클래스입니다.

그림 10.9의 Map 클래스의 타입 정의는 `map` 키가 LongWritable 타입(기본적으로 긴 정수)이고, 값이 문서(또는 문서의 일부)인 Text 타입임을 지정합니다. `map`의 출력은 키가 Text 타입이며, 값이 정수 값인 IntWritable 타입입니다.

단어 개수 예제의 `map()` 코드는 StringTokenizer를 사용하여 입력 텍스트 값을 단어로 분할한 다음 각 단어에 대해 context.write(word, one)를 호출하여 키와 값 쌍을 출력합니다. 여기서 one은 값이 1인 IntWritable 객체입니다.

특정 키(우리 예제에서는 단어)가 있는 모든 `map()` 호출의 값은 MapReduce 시스템 인프라에 의해 목록으로 수집됩니다. 이를 위해 여러 `map` 작업에서 여러 `reduce` 작업으로 데이터 교환이 필요합니다. 분산 설정에서는 데이터가 네트워크를 통해 전송되어야 합니다. 특정 키에 대한 모든 값이 함께 올 수 있도록 하기 위해 MapReduce 시스템은 일반적으로 `map` 함수가 출력한 키를 정렬하여 특정 키의 모든 값이 정렬된 순서로 함께 오도록 합니다. 각 키에 대한 값 목록이 `reduce()` 함수에 제공됩니다.

`reduce()` 입력 키의 타입은 `map` 출력 키의 타입과 동일합니다. 예제에서 `reduce()` 입력 값은 Java `Iterable<IntWritable> `객체로, `map` 출력 값(IntWritable 타입)의 목록을 포함합니다. `reduce()`의 출력 키는 단어(Text 타입)이고, 출력 값은 단어 개수(IntWritable 타입)입니다.

예제에서 `reduce()` 함수는 입력으로 받은 값을 합산하여 총 개수를 구합니다. `reduce()`는 context.write() 함수를 사용하여 단어와 총 개수를 씁니다.

간단한 예제에서는 모든 값이 1이므로 `reduce()`는 받은 값의 수만 세면 됩니다. 그러나 일반적으로 Hadoop은 `map` 작업의 출력에 대해 `combine()` 함수를 실행하는 Combiner 클래스를 선언할 수 있도록 합니다. 이 함수는 단일 키에 대한 여러 `map()` 출력 값을 단일 값으로 대체합니다. 예제에서 `combine()` 함수는 각 단어의 발생 횟수를 세고 단일 값을 출력할 수 있으며, 이는 `map` 작업의 로컬 단어 개수입니다. 이러한 출력은 `reduce()` 함수로 전달되며, 로컬 개수를 합산하여 전체 개수를 구합니다. Combiner의 작업은 네트워크를 통한 트래픽을 줄이는 것입니다.

MapReduce 작업은 `map` 및 `reduce` 단계를 실행합니다. 프로그램은 여러 MapReduce 단계를 가질 수 있으며, 각 단계는 `map` 및 `reduce` 함수에 대한 자체 설정을 가집니다. main() 함수는 각 MapReduce 작업에 대한 매개변수를 설정한 다음 이를 실행합니다.

그림 10.9의 예제 코드는 단일 MapReduce 작업을 실행합니다. 작업의 매개변수는 다음과 같습니다:

- 작업의 `map` 및 `reduce` 함수를 포함하는 클래스, setMapperClass 및 setReducerClass 메서드로 설정됨.
- 작업의 출력 키 및 값의 타입, 각각 setOutputKeyClass 및 setOutputValueClass 메서드로 설정됨.
- 작업의 입력 형식, TextInputFormat으로 설정된 job.setInputFormatClass 메서드로 설정됨. Hadoop의 기본 입력 형식은 TextInputFormat이며, 파일의 바이트 오프셋이 값인 `map` 키와 파일의 한 줄이 값인 `map` 값을 생성합니다. 파일은 4기가바이트보다 클 수 있으므로, 오프셋은 LongWritable 타입입니다. 프로그래머는 자체 입력 형식 클래스를 제공하여 입력 파일을 처리하고 파일을 레코드로 나눌 수 있습니다.
- 작업의 출력 형식, job.setOutputFormatClass 메서드로 설정된 TextOutputFormat.
- 입력 파일이 저장된 디렉터리와 출력 파일이 생성될 디렉터리, addInputPath 및 addOutputPath 메서드로 설정됨.

Hadoop은 병렬로 실행할 `map` 및 `reduce` 작업의 수와 각 `map` 및 `reduce` 작업에 할당할 메모리 양 등 MapReduce 작업에 대한 더 많은 매개변수를 지원합니다.

#### 10.3.6 MapReduce에서 SQL

MapReduce 응용 프로그램의 많은 부분은 대량의 비관계형 데이터를 병렬 처리하는 것으로, SQL로 쉽게 표현할 수 없는 계산을 사용합니다. 예를 들어, 단어 개수 프로그램은 SQL로 쉽게 표현할 수 없습니다. MapReduce를 사용한 많은 실제 사용 사례는 SQL로 표현할 수 없습니다. 예를 들어, 웹 검색 엔진이 키워드 쿼리에 효율적으로 응답할 수 있도록 하는 "역 인덱스"의 계산 및 Google의 PageRank 계산 등이 있습니다. PageRank는 웹 사이트의 중요도를 나타내는 중요한 척도로, 웹 검색 쿼리에 대한 응답을 정렬하는 데 사용됩니다.

그러나 MapReduce 패러다임을 사용하여 다양한 종류의 데이터 처리를 수행하는 많은 응용 프로그램이 있으며, 그 논리는 SQL을 사용하여 쉽게 표현할 수 있습니다. 데이터가 데이터베이스에 있는 경우, 이러한 쿼리를 SQL로 작성하고 병렬 데이터베이스 시스템에서 쿼리를 실행하는 것이 타당합니다(병렬 데이터베이스 시스템은 22장에서 자세히 다룹니다). SQL을 사용하는 것이 MapReduce 패러다임을 코딩하는 것보다 훨씬 쉽습니다. 그러나 많은 응용 프로그램의 데이터는 파일 시스템에 있으며, 데이터베이스에 로드하는 데 많은 시간과 공간이 소요됩니다.

관계형 연산은 `map` 및 `reduce` 단계를 사용하여 구현할 수 있으며, 다음 예제에서 설명합니다:

- 관계형 선택 연산은 `reduce()` 함수 없이 단일 `map()` 함수로 구현할 수 있습니다(또는 입력을 변경하지 않고 출력하는 `reduce()` 함수가 포함될 수 있음).
- 관계형 그룹화 및 집계 함수 γ는 단일 MapReduce 단계로 구현할 수 있습니다: `map()`은 그룹화 속성 값을 `reduce` 키로 하는 레코드를 출력합니다. `reduce()` 함수는 특정 그룹화 키에 대한 모든 속성 값을 수신하고, 입력 목록의 값에 대해 필요한 집계를 계산합니다.
- 조인 연산은 단일 MapReduce 단계로 구현할 수 있습니다. r.A = s.A 조인 연산을 고려해 봅시다. r 레코드의 경우 (r.A, r) 쌍을 출력하고, s 레코드의 경우 (s.A, s) 쌍을 출력합니다. 출력에는 r 또는 s 관계에서 나온 것임을 나타내는 태그도 포함됩니다. `reduce()` 함수는 조인 속성 값에 대해 호출되며, 해당 조인 속성 값이 있는 모든 r 및 s 레코드 목록을 포함합니다. 함수는 r 및 s 튜플을 분리한 다음, 조인 속성 값이 동일한 모든 r 및 s 튜플의 교차 곱을 출력합니다.

자세한 내용은 독자에게 연습 문제로 남겨둡니다(연습 문제 10.4). 여러 연산이 포함된 복잡한 작업은 여러 단계의 `map` 및 `reduce` 작업을 사용하여 표현할 수 있습니다.

관계형 쿼리를 MapReduce 패러다임으로 표현하는 것은 가능하지만, 인간이 그렇게 하는 것은 매우 번거로울 수 있습니다. SQL로 쿼리를 작성하는 것이 훨씬 간결하고 이해하기 쉽지만, 전통적인 데이터베이스는 파일에서 데이터 접근을 허용하지 않았으며, 이러한 쿼리의 병렬 처리를 지원하지 않았습니다.

SQL 언어의 변형으로 작성된 쿼리를 파일 시스템에 저장된 데이터에 병렬로 실행할 수 있는 새로운 세대의 시스템이 개발되었습니다. 이러한 시스템에는 Facebook에서 처음 개발한 Apache Hive, Microsoft에서 개발한 SCOPE, Yahoo!에서 처음 개발한 Apache Pig가 포함되며, 모두 관계형 대수에 기반한 선언적 언어인 Pig Latin을 사용합니다. 이러한 시스템은 데이터를 파일 시스템에서 직접 읽을 수 있지만, 입력 데이터를 레코드 형식으로 변환하는 함수를 프로그래머가 정의할 수 있도록 합니다.

이러한 시스템은 주어진 쿼리를 실행하기 위해 일련의 `map` 및 `reduce` 작업을 포함하는 프로그램을 생성합니다. 프로그램은 컴파일되어 Hadoop과 같은 MapReduce 프레임워크에서 실행됩니다. 이러한 시스템은 매우 인기를 끌었으며, 오늘날 MapReduce 패러다임을 직접 사용하여 작성된 쿼리보다 훨씬 많은 쿼리가 이러한 시스템을 사용하여 작성되었습니다.

오늘날 Hive 구현은 SQL 코드를 병렬 환경에서 실행할 수 있는 대수 연산 트리로 컴파일하는 옵션을 제공합니다. Apache Tez 및 Spark는 다음 섹션 10.4에서 살펴볼 병렬 환경에서 대수 연산 트리(DAG)를 실행하는 두 가지 널리 사용되는 플랫폼입니다.

### 10.4 MapReduce를 넘어서: 대수 연산

관계형 대수는 관계형 쿼리 처리를 위한 기초를 형성하여 쿼리를 연산 트리로 모델링할 수 있도록 합니다. 이 아이

디어는 복잡한 데이터 유형이 포함된 데이터 세트에 작업할 수 있는 대수 연산자를 지원함으로써 확장됩니다. 이러한 연산자는 복잡한 데이터 유형이 포함된 레코드로 구성된 데이터 세트를 입력으로 받아, 유사한 복잡한 데이터 유형이 포함된 레코드를 가진 데이터 세트를 반환합니다.

#### 10.4.1 대수 연산의 동기

10.3.6절에서 본 것처럼 관계형 연산은 일련의 `map` 및 `reduce` 단계로 표현할 수 있습니다. 그러나 이러한 방식으로 작업을 표현하는 것은 매우 번거로울 수 있습니다. 예를 들어, 프로그래머가 두 입력의 조인을 계산해야 하는 경우, `map` 및 `reduce` 함수를 통해 간접적으로 표현하는 대신 단일 대수 연산으로 표현할 수 있어야 합니다. 조인과 같은 함수에 접근할 수 있으면 프로그래머의 작업이 크게 단순화됩니다.

조인 연산은 여러 기술을 사용하여 병렬로 실행할 수 있으며, 이는 22.3절에서 자세히 다룹니다. 실제로 이러한 기술을 사용하면 `map` 및 `reduce` 함수를 사용하여 조인을 구현하는 것보다 훨씬 더 효율적일 수 있습니다. 따라서 프로그래머가 직접 MapReduce 코드를 작성하지 않는 Hive와 같은 시스템에서도 조인과 같은 연산을 직접 지원하는 것이 유익할 수 있습니다.

후속 세대의 병렬 데이터 처리 시스템은 조인(외부 조인 및 세미 조인의 변형 포함)과 같은 다른 관계형 연산뿐만 아니라 데이터 분석을 지원하는 다양한 연산을 추가로 지원했습니다. 예를 들어, 많은 머신 러닝 모델은 레코드 세트를 입력으로 받아 레코드의 다른 속성을 기반으로 모델이 예측한 값을 포함하는 추가 속성을 가진 레코드 세트를 출력하는 연산자로 모델링될 수 있습니다. 머신 러닝 알고리즘 자체는 학습된 모델을 출력하는 연산자로 모델링될 수 있습니다. 데이터 처리는 종종 여러 단계로 이루어지며, 이는 연산자의 순서(파이프라인) 또는 트리로 모델링될 수 있습니다.

이러한 연산을 통합하는 프레임워크는 하나 이상의 데이터 세트를 입력으로 받고, 하나 이상의 데이터 세트를 출력으로 하는 대수 연산으로 처리하는 것입니다.

관계형 대수(2.6절)에서 각 연산은 하나 이상의 관계를 입력으로 받고, 관계를 출력합니다. 이러한 후속 세대의 병렬 쿼리 처리 시스템도 동일한 아이디어를 기반으로 하지만 몇 가지 차이점이 있습니다. 주요 차이점은 입력 데이터가 관계 모델에서와 같이 원자 데이터 유형을 포함한 열로만 구성되지 않고 임의의 유형일 수 있다는 것입니다. SQL을 지원하기 위해 확장된 관계형 대수는 간단한 산술, 문자열 및 부울 표현으로 제한될 수 있습니다. 반면, 새로운 세대의 대수 연산자는 프로그래밍 언어의 전체 기능을 필요로 하는 복잡한 표현을 지원해야 합니다.

복잡한 데이터에 대한 대수 연산을 지원하는 프레임워크가 여러 가지 있으며, 오늘날 가장 널리 사용되는 것은 Apache Tez와 Apache Spark입니다.

Apache Tez는 시스템 구현자에게 적합한 저수준 API를 제공합니다. 예를 들어, Hive on Tez는 SQL 쿼리를 Tez에서 실행되는 대수 연산으로 컴파일합니다. Tez 프로그래머는 노드의 트리(또는 일반적으로 방향성 비순환 그래프, DAG)를 만들고, 각 노드에서 실행할 코드를 제공합니다. 입력 노드는 데이터 소스에서 데이터를 읽고 다른 노드로 전달합니다. 데이터는 여러 머신에 걸쳐 분할될 수 있으며, 각 노드의 코드는 각 머신에서 실행될 수 있습니다. Tez는 애플리케이션 프로그래머가 직접 사용하도록 설계되지 않았기 때문에 더 자세히 설명하지 않습니다.

그러나 Apache Spark는 애플리케이션 프로그래머에게 적합한 고수준 API를 제공합니다. 다음에서 Spark에 대해 더 자세히 설명합니다.

#### 10.4.2 Spark의 대수 연산

Apache Spark는 다양한 대수 연산을 지원하는 널리 사용되는 병렬 데이터 처리 시스템입니다. 데이터는 다양한 저장 시스템에서 입력되거나 출력될 수 있습니다. 관계형 데이터베이스가 데이터 표현의 기본 추상화로 관계를 사용하는 것처럼, Spark는 탄력적 분산 데이터 세트(RDD)라는 표현을 사용합니다. RDD는 여러 머신에 걸쳐 저장될 수 있는 레코드 모음입니다. "분산"이라는 용어는 레코드가 다른 머신에 저장된다는 것을 의미하며, "탄력적"이라는 용어는 고장에 대한 탄력성을 의미합니다. 즉, 하나의 머신이 고장 나더라도 다른 머신에서 레코드를 검색할 수 있습니다.

Spark의 연산자는 하나 이상의 RDD를 입력으로 받고, 출력은 RDD입니다. RDD에 저장된 레코드의 유형은 미리 정의되지 않으며 애플리케이션이 원하는 모든 것이 될 수 있습니다. Spark는 나중에 설명할 관계형 데이터 표현인 DataSet도 지원합니다.

Spark는 Java, Scala 및 Python용 API를 제공합니다. Spark에 대한 설명은 Java API를 기반으로 합니다.

그림 10.10은 Apache Spark를 사용하여 Java로 작성된 단어 개수 응용 프로그램을 보여줍니다. 이 프로그램은 RDD 데이터 표현을 사용합니다. JavaRDD의 Java 타입은 JavaRDD로, RDD는 각 줄에 대한 레코드를 생성합니다. 입력은 파일 또는 여러 파일이 있는 디렉터리가 될 수 있습니다. 여러 노드에서 실행되는 Spark 시스템은 실제로 RDD를 여러 머신에 분할하여 저장하지만, 프로그램은 대부분의 경우 단일 머신의 데이터 구조로 간주할 수 있습니다. 그림 10.10의 예제 코드에서 결과는 `lines`라는 RDD입니다.

다음 단계에서는 각 줄을 공백을 기준으로 나누어 단어 배열로 분할합니다. 이 함수는 줄을 공백을 기준으로 나누고 단어 배열을 반환합니다. 더 완전한 함수는 마침표, 세미콜론 등 다른 구두점 문자로 입력을 분할합니다. split 함수는 map() 함수 호출을 통해 입력 RDD의 각 줄에 대해 호출됩니다. 예제에서는 대신 flatMap()이라는 변형을 사용합니다. flatMap()은 map()과 유사하게 사용자 정의 함수를 각 입력 레코드에 호출합니다. 함수는 반복자를 반환해야 합니다. Java 반복자는 next() 함수를 지원하여 여러 번 호출하여 여러 결과를 가져올 수 있습니다. flatMap() 함수는 사용자 정의 함수를 호출하여 반복자를 가져오고, 반복자의 next() 함수를 여러 번 호출하여 여러 값을 가져온 다음, 모든 입력 레코드의 값을 합친 RDD를 반환합니다.

그림 10.10의 코드는 Java 8에서 도입된 "람다 표현식" 구문을 사용합니다. 이 구문은 함수를 compact하게 정의할 수 있으며, 이름조차 필요 없습니다. Java 코드에서 s -> Arrays.asList(s.split(" ")).iterator() 구문은 매개변수 s를 받고 이전에 설명한 split 함수를 적용하여 단어 배열을 생성하고, Arrays.asList를 사용하여 배열을 목록으로 변환한 다음, iterator() 메서드를 목록에 적용하여 반복자를 생성합니다. flatMap() 함수는 이 반복자에서 작동합니다.

이 단계를 거쳐 단일 단어를 포함하는 각 레코드가 있는 `words`라는 RDD가 생성됩니다.

다음 단계에서는 `words`의 각 단어에 대해 (단어, 1) 형식의 쌍을 포함하는 JavaPairRDD `ones`를 생성합니다. 단어가 입력 파일에 여러 번 나타나면 `words`와 `ones`에는 그만큼 많은 레코드가 있습니다.

마지막으로 대수 연산 `reduceByKey()`는 그룹화 및 집계 단계를 구현합니다. 샘플 코드에서는 람다 함수 (i1, i2) -> i1 + i2를 `reduceByKey()` 함수에 전달하여 집계에 덧셈을 사용한다고 지정합니다. `reduceByKey()` 함수는 JavaPairRDD에서 작동하며, 첫 번째 속성으로 그룹화하고 두 번째 속성 값을 제공된 람다 함수를 사용하여 집계합니다. `ones` RDD에 적용되면, 첫 번째 속성인 단어로 그룹화되고, 두 번째 속성 값(모두 1인 `ones` RDD)으로 합산됩니다. 결과는 JavaPairRDD `counts`에 저장됩니다.

일반적으로 이진 함수는 수집된 값의 순서에 관계없이 동일한 결과를 주는 한 집계에 사용할 수 있습니다.

마지막으로 `counts` RDD는 `saveAsTextFile()`로 파일 시스템에 저장됩니다. 단일 파일을 생성하는 대신 RDD 자체가 머신에 분할되어 있으면 여러 파일을 생성합니다.

병렬 처리 방법을 이해하려면 다음을 이해하는 것이 중요합니다:
- RDD는 분할되어 여러 머신에 저장될 수 있으며,
- 각 연산은 머신에 있는 RDD 분할에서 여러 머신에서 병렬로 실행될 수 있습니다. 연산은 먼저 입력을 재분할하여 관련

된 레코드를 같은 머신으로 가져온 다음 병렬로 연산을 실행할 수 있습니다. 예를 들어, `reduceByKey()`는 입력 RDD를 재분할하여 그룹에 속하는 모든 레코드를 단일 머신으로 가져오고, 다른 그룹의 레코드는 다른 머신에 있을 수 있습니다.

Spark의 또 다른 중요한 측면은 함수 호출 시 연산이 즉시 평가되지 않는다는 것입니다. 대신 그림에 나와 있는 코드는 실제로 연산 트리를 만듭니다. 코드에서는 텍스트 파일을 읽는 `textFile()`이 리프 연산이며, `flatMap()`은 `textFile()` 연산을 자식으로 갖고, `mapToPairs()`는 `flatMap()`을 자식으로 가집니다. 연산자는 관계형 용어로 뷰를 정의하는 것으로 간주될 수 있으며, 정의될 때 즉시 실행되는 것이 아니라 나중에 실행됩니다.

실제 평가가 필요한 경우에만 전체 연산 트리가 평가됩니다. 예를 들어, `saveAsTextFile()`은 트리를 평가하도록 강제합니다. 다른 함수에는 트리를 평가하고 모든 레코드를 단일 머신으로 가져와 예를 들어 출력하는 `collect()`가 있습니다.

이러한 트리의 지연 평가의 중요한 이점은 실제 평가 전에 쿼리 최적화기가 트리를 동일한 결과를 계산하지만 더 빨리 실행될 수 있는 다른 트리로 다시 작성할 수 있다는 것입니다. 쿼리 최적화 기술은 16장에서 자세히 다루며, 이러한 트리를 최적화하는 데 적용될 수 있습니다.

앞의 예는 연산 트리를 생성했지만, 일반적으로 연산 결과가 여러 다른 연산에 소비되면 연산은 방향성 비순환 그래프(DAG) 구조를 형성할 수 있습니다. 이는 연산의 부모가 여러 개 있을 수 있으며, 트리에서는 최대 한 부모만 가질 수 있습니다.

RDD는 텍스트 데이터와 같은 특정 데이터 유형을 나타내는 데 적합하지만, 빅데이터 응용 프로그램의 많은 부분은 여러 속성을 가진 구조화된 데이터를 처리해야 합니다. Spark는 구조화된 데이터를 지원하기 위해 DataSet 타입을 도입했습니다. DataSet 타입은 여러 속성을 가진 레코드를 압축 방식으로 저장하도록 설계된 Parquet, ORC 및 Avro 파일 형식과 잘 작동합니다. Spark는 관계를 데이터베이스에서 읽을 수 있는 JDBC 커넥터도 지원합니다.

다음 코드는 Spark에서 Parquet 형식으로 된 데이터를 읽고 처리하는 방법을 보여줍니다. 여기서 spark는 이전에 열린 Spark 세션입니다.

```java
Dataset<Row> instructor = spark.read().parquet("...");
Dataset<Row> department = spark.read().parquet("...");
instructor.filter(instructor.col("salary").gt(100000))
  .join(department, instructor.col("dept_name").equalTo(department.col("dept_name")))
  .groupBy(department.col("building"))
  .agg(count(instructor.col("ID")));
```

위의 `DataSet<Row>` 타입은 각 컬럼 값을 이름으로 접근할 수 있는 Row 타입을 사용합니다. 코드는 Parquet 파일에서 강사 및 학과 관계를 읽습니다(파일 이름은 코드에서 생략되었습니다). Parquet 파일은 값 외에도 컬럼 이름과 같은 메타데이터를 저장하여 Spark가 관계의 스키마를 생성할 수 있도록 합니다. Spark 코드는 강사 관계에 대한 필터(선택) 연산을 적용하여 급여가 100000보다 큰 강사만 유지한 다음, 학과 관계와 `dept_name` 속성으로 조인하고, `building` 속성(학과 관계의 속성)으로 그룹화합니다. 각 그룹에 대해 `ID` 값의 수를 계산합니다.

새로운 대수 연산을 정의하고 쿼리에서 사용하는 기능은 많은 응용 프로그램에서 매우 유용한 것으로 밝혀져 Spark의 광범위한 채택으로 이어졌습니다. Spark 시스템은 Hive SQL 쿼리를 Spark 연산 트리로 컴파일한 다음 이를 실행하는 기능도 지원합니다.

Spark는 DataSet 타입과 함께 Row 외에도 다른 클래스를 사용할 수 있도록 합니다. Spark는 각 속성 `Attrk`에 대해 `getAttrk()` 및 `setAttrk()` 메서드가 정의되어 속성 값을 저장 및 검색할 수 있도록 해야 합니다. Instructor 클래스를 생성하고 해당 속성을 가진 Parquet 파일이 있는 경우, 다음과 같이 Parquet 파일에서 데이터를 읽을 수 있습니다:

```java
Dataset<Instructor> instructor = spark.read().parquet("...").as(Encoders.bean(Instructor.class));
```

이 경우 Parquet은 입력 파일의 속성 이름을 제공하여 해당 값을 Instructor 클래스의 속성에 매핑합니다. Row와 달리 컴파일 시간에 타입을 알 수 있어 더 간결하게 표현할 수 있으며, Instructor 클래스의 메서드를 사용하여 속성에 접근할 수 있습니다. 예를 들어, `getSalary()`를 사용할 수 있으며, 이는 런타임에 속성 이름을 기본 레코드의 위치에 매핑하는 비용을 피할 수 있습니다. 이러한 구문을 사용하는 방법에 대한 자세한 내용은 [spark.apache.org](http://spark.apache.org)에서 제공하는 Spark 문서를 참조하십시오.

Spark에 대한 설명은 데이터베이스 연산에 중점을 두었지만, 언급했듯이 Spark는 머신 러닝 관련 연산 등 다양한 대수 연산을 지원하며, 이는 DataSet 타입에서 호출할 수 있습니다.

### 10.5 스트리밍 데이터

데이터 쿼리는 데이터베이스에서 정보를 추출하고자 하는 분석가의 필요에 따라 비정기적으로 실행될 수 있습니다. 또한, 전날 발생한 거래의 요약을 얻기 위해 매일 아침 쿼리를 실행하는 것과 같이 주기적으로 실행될 수도 있습니다.

그러나 데이터가 연속적으로 도착하는 많은 응용 프로그램에서는 쿼리를 지속적으로 실행해야 합니다. 스트리밍 데이터란 연속적으로 도착하는 데이터를 말합니다. 많은 응용 프로그램 도메인에서는 실시간으로(즉, 도착할 때) 데이터를 처리해야 합니다. 지연이 발생하더라도 보장이 있어야 합니다.

#### 10.5.1 스트리밍 데이터의 응용

여기 몇 가지 스트리밍 데이터의 예와 이를 사용하는 응용 프로그램의 실시간 요구 사항을 제시합니다.

- **주식 시장:** 주식 시장에서는 각 거래가 튜플로 나타나며, 거래가 스트림으로 처리 시스템에 전송됩니다. 주식 시장 거래자는 거래 스트림을 분석하여 패턴을 찾아 이를 기반으로 매수 또는 매도 결정을 내립니다. 실시간 요구 사항은 과거에는 초 단위였으나 오늘날에는 수십 마이크로초 단위로 줄어들고 있습니다. 주식 시장 규제 기관도 동일한 스트림을 사용하지만, 불법 활동을 나타내는 거래 패턴을 찾기 위해 사용합니다.
- **전자 상거래:** 전자 상거래 사이트에서는 각 구매가 튜플로 나타나며, 모든 구매의 순서가 스트림을 형성합니다. 심지어 고객의 검색도 사이트에 가치가 있으며, 이를 스트림으로 처리할 수 있습니다. 스트림은 광고 캠페인의 영향을 실시간으로 모니터링하거나 특정 제품의 판매 급증을 감지하는 데 사용될 수 있습니다. 또한, 사용자의 활동 패턴을 감지하여 부정 행위를 차단할 수도 있습니다.
- **센서:** 차량, 건물 및 공장과 같은 시스템에 센서가 널리 사용됩니다. 이러한 센서는 주기적으로 읽기를 보내며, 이는 스트림을 형성합니다. 스트림에서 읽기를 통해 시스템의 상태를 모니터링하고, 비정상적인 읽기가 있으면 알람을 울리고 문제를 최소한의 지연으로 해결합니다. 많은 경우 중앙 클라우드 시설에서 모니터링이 이루어지며, 병렬 처리가 필수적입니다.
- **네트워크 데이터:** 큰 컴퓨터 네트워크를 관리하는 조직은 네트워크 활동을 모니터링하여 네트워크 문제 및 악성 소프트웨어 공격을 감지해야 합니다. 모니터링되는 데이터는 각 모니터링 지점에서 관찰된 데이터를 포함하는 스트림으로 나타낼 수 있습니다. 스트림의 생성 속도는 매우 높으며, 이를 처리하기 위해 특수 하드웨어가 필요할 수 있습니다.
- **소셜 미디어:** Facebook 및 Twitter와 같은 소셜 미디어는 사용자로부터 연속적인 메시지 스트림을 받습니다. 각 메시지는 적절히 라우팅되어야 하며, 예를 들어 친구나 팔로워에게 보내질 수 있습니다. 소셜 미디어 스트림은 소프트웨어에서도 소비될 수 있으며, 예를 들어 회사에 대한 부정적인 감정을 나타내는 트윗을 모니터링하고 경고를 올리거나 광고 캠페인의 영향을 분석할 수 있습니다.

다양한 도메인에서 스트리밍 데이터를 처리하고 쿼리해야 하는 많은 예가 있습니다.

#### 10.5.2 스트리밍 데이터 쿼리

데이터베이스에 저장된 데이터는 가끔 "정지 데이터"라고 하며, 스트리밍 데이터와 대조됩니다. 스트리밍 데이터는 무한정으로 도착할 수 있으므로, 스트림의 모든 튜플을 본 후에만 결과를 출력할

 수 있는 쿼리는 결과를 출력할 수 없습니다. 예를 들어, 스트림의 튜플 수를 묻는 쿼리는 최종 결과를 제공할 수 없습니다.

스트림의 무한한 특성을 처리하는 한 가지 방법은 특정 시간 범위 또는 튜플 수를 포함하는 창(window)을 정의하는 것입니다. 들어오는 튜플의 타임스탬프에 대한 정보를 알고 있으면 특정 창의 모든 튜플이 보였는지 추론할 수 있습니다. 이를 기반으로 일부 스트림 쿼리 언어는 스트림에서 창을 정의하고, 쿼리가 스트림 대신 하나 또는 여러 창의 튜플을 참조할 수 있도록 합니다.

또 다른 옵션은 스트림의 특정 지점에서 정확한 결과를 출력한 다음 더 많은 튜플이 도착하면 결과를 업데이트하는 것입니다. 예를 들어, 카운트 쿼리는 특정 시점에 본 튜플 수를 출력하고, 더 많은 튜플이 도착하면 새로운 개수에 기반하여 결과를 업데이트할 수 있습니다.

스트리밍 데이터를 쿼리하기 위한 몇 가지 접근 방식이 개발되었습니다.

1. **연속 쿼리:** 이 접근 방식에서는 들어오는 데이터 스트림을 관계에 대한 삽입으로 간주하고, 관계에 대한 쿼리를 SQL 또는 관계 대수 연산을 사용하여 작성할 수 있습니다. 이러한 쿼리는 연속 쿼리로 등록될 수 있습니다. 연속 쿼리는 지속적으로 실행되는 쿼리입니다. 초기 데이터에 대한 쿼리의 결과는 시스템이 시작될 때 출력됩니다. 각 들어오는 튜플은 연속 쿼리의 결과를 삽입, 업데이트 또는 삭제할 수 있습니다. 연속 쿼리의 출력은 기본 데이터베이스가 들어오는 스트림으로 업데이트됨에 따라 쿼리 결과의 업데이트 스트림입니다.
   - 이 접근 방식의 주요 문제는 입력 속도가 높은 경우 쿼리 결과에 대한 많은 업데이트로 소비자가 과부하될 수 있다는 점입니다. 특히, 집계 값을 출력하는 응용 프로그램의 경우 사용자는 모든 중간 결과 대신 일정 기간 동안의 최종 집계를 보고 싶어할 수 있습니다.
2. **스트림 쿼리 언어:** 두 번째 접근 방식은 SQL 또는 관계 대수를 확장하여 스트림을 저장된 관계와 다르게 취급하는 쿼리 언어를 정의하는 것입니다. 대부분의 스트림 쿼리 언어는 창 연산을 사용하여 스트림에 적용하고 창의 내용을 관계로 변환합니다. 예를 들어, 스트림에서 시간별로 튜플 집합을 생성할 수 있으며, 각 집합은 관계입니다. 관계 연산은 이러한 튜플 집합에 대해 실행할 수 있습니다. 여기에는 집계, 선택, 저장된 관계 데이터 또는 다른 스트림의 창과 조인 등이 포함됩니다.
   - 스트림 쿼리 언어의 개요는 섹션 10.5.2.1에서 제공됩니다. 이러한 언어는 스트림 데이터와 저장된 관계를 언어 수준에서 분리하고, 관계 연산을 수행하기 전에 창 연산이 적용되도록 요구합니다. 이를 통해 스트림의 일부만 보고 결과를 출력할 수 있습니다. 예를 들어, 스트림이 튜플의 타임스탬프가 증가하는 것을 보장하는 경우, 시간에 기반한 창이 완료될 때까지 더 높은 타임스탬프를 가진 튜플을 본 후에 창의 집계 결과를 출력할 수 있습니다.
   - 일부 스트림은 타임스탬프가 증가하는 것을 보장하지 않지만, 주기적으로 메타데이터 튜플(구두점)을 포함하여 모든 이후 튜플이 특정 값보다 큰 타임스탬프를 가짐을 나타냅니다. 이러한 구두점은 주기적으로 발생하며, 창 연산자가 집계 결과를 출력할 때 사용될 수 있습니다.
3. **스트림에 대한 대수 연산자:** 세 번째 접근 방식은 사용자가 각 들어오는 튜플에 대해 실행되는 연산자(사용자 정의 함수)를 작성할 수 있도록 하는 것입니다. 튜플은 입력에서 연산자로 라우팅되며, 연산자의 출력은 다른 연산자, 시스템 출력 또는 데이터베이스에 저장될 수 있습니다. 연산자는 튜플을 처리하는 동안 내부 상태를 유지하여 들어오는 데이터를 집계할 수 있습니다. 또한 장기간 사용을 위해 데이터를 데이터베이스에 영구적으로 저장할 수 있습니다.
   - 이 접근 방식은 최근 몇 년 동안 널리 채택되었으며, 나중에 더 자세히 설명합니다.
4. **패턴 매칭:** 네 번째 옵션은 패턴 매칭 언어를 정의하고 사용자가 여러 규칙을 작성할 수 있도록 하는 것입니다. 각 규칙에는 패턴과 작업이 있습니다. 시스템이 특정 패턴과 일치하는 튜플 하위 시퀀스를 찾으면 패턴에 해당하는 작업이 실행됩니다. 이러한 시스템은 복잡 이벤트 처리(CEP) 시스템이라고 하며, Oracle Event Processing, Microsoft StreamInsight 및 Apache Flink 프로젝트의 FlinkCEP가 인기가 있습니다.

스트림 쿼리 언어 및 대수 연산에 대해서는 이 섹션에서 더 자세히 설명합니다.

많은 스트림 처리 시스템은 데이터를 메모리에 유지하며, 지속성 보장을 제공하지 않습니다. 그들의 목표는 최소 지연으로 결과를 생성하여 스트리밍 데이터 분석에 기반한 빠른 응답을 가능하게 하는 것입니다. 반면, 들어오는 데이터는 나중에 처리하기 위해 데이터베이스에 저장될 수도 있습니다. 두 가지 패턴의 쿼리를 모두 지원하기 위해 많은 응용 프로그램은 스트림 처리 시스템에 입력 데이터의 복사본을 제공하고, 다른 복사본은 데이터베이스에 제공하여 저장 및 나중에 처리할 수 있는 람다 아키텍처를 사용합니다. 이러한 아키텍처는 지속성 관련 문제를 걱정하지 않고 스트림 처리 시스템을 빠르게 개발할 수 있도록 합니다. 그러나 스트림 시스템과 데이터베이스 시스템이 분리되어 있어 다음과 같은 문제가 발생합니다:

- 쿼리를 스트림 시스템과 데이터베이스 시스템에서 각각 다른 언어로 두 번 작성해야 할 수 있습니다.
- 스트리밍 쿼리는 저장된 데이터에 효율적으로 접근할 수 없을 수 있습니다.

스트리밍 쿼리와 지속적 저장을 지원하고 스트림과 저장된 데이터를 아우르는 쿼리를 지원하는 시스템은 이러한 문제를 피할 수 있습니다.

#### 10.5.2.1 SQL에 대한 스트림 확장

SQL 창 연산은 5.5.2절에서 설명했지만, 스트림 쿼리 언어는 SQL 창 함수에서 지원하지 않는 추가 창 유형을 지원합니다. 예를 들어, 시간별로 튜플을 포함하는 창은 SQL 창 함수로 지정할 수 없습니다. 그러나 시간별 창에 대한 집계는 더 간접적으로 SQL에서 지정할 수 있습니다. 먼저 타임스탬프의 시간 구성 요소만 포함하는 추가 속성을 계산한 다음, 시간 속성으로 그룹화합니다. 스트리밍 쿼리 언어의 창 함수는 이러한 집계를 쉽게 지정할 수 있습니다. 일반적으로 지원되는 창 함수에는 다음이 포함됩니다:

- **텀블링 창:** 시간별 창은 텀블링 창의 예입니다. 창은 겹치지 않지만 서로 인접해 있습니다. 창은 창 크기로 지정됩니다(예: 시간, 분 또는 초 수).
- **홉핑 창:** 20분마다 계산되는 시간별 창은 홉핑 창의 예입니다. 창 너비는 고정되어 있지만 인접한 창이 겹칠 수 있습니다.
- **슬라이딩 창:** 슬라이딩 창은 각 들어오는 튜플 주변에 지정된 크기(시간 또는 튜플 수)의 창입니다. SQL 표준에서 지원됩니다.
- **세션 창:** 세션 창은 사용자가 세션의 일부로 여러 작업을 수행하는 것을 모델링합니다. 창은 사용자와 타임아웃 간격으로 식별되며, 각 작업은 이전 작업으로부터 타임아웃 간격 내에 발생하는 작업 시퀀스를 포함합니다. 예를 들어, 타임아웃이 5분이고 사용자가 오전 10시에 작업을 수행하고, 오전 10시 4분에 두 번째 작업을 수행하고, 오전 11시에 세 번째 작업을 수행하면, 첫 두 작업은 하나의 세션의 일부이고, 세 번째 작업은 다른 세션의 일부입니다. 최대 기간도 지정할 수 있으며, 이 기간이 만료되면 일부 작업이 타임아웃 간격 내에 수행되더라도 세션 창이 닫힙니다.

창을 지정하는 정확한 구문은 구현에 따라 다릅니다. order(orderid, datetime, itemid, amount) 관계가 있다고 가정해 봅시다. Azure Stream Analytics에서는 다음과 같이 텀블링 창을 사용하여 각 시간에 대해 각 항목의 총 주문 금액을 지정할 수 있습니다:

```sql
select item, System.Timestamp as window_end, sum(amount)
from order timestamp by datetime
group by itemid, tumblingwindow(hour, 1)
```

각 출력 튜플에는 창의 끝 타임스탬프와 같은 값의 타

임스탬프가 있습니다. 타임스탬프는 위의 쿼리에서 `System.Timestamp` 키워드를 사용하여 접근할 수 있습니다.

스트림을 지원하는 SQL 확장은 스트림과 관계를 구분합니다. 스트림은 암시적 타임스탬프를 가지며 무한정으로 도착할 수 있는 튜플을 받을 수 있습니다. 예를 들어, 주문과 관련된 고객, 공급업체 및 항목은 스트림이 아닌 관계로 처리됩니다. 창 연산 결과는 스트림이 아닌 관계로 처리됩니다.

스트림과 관계의 조인은 허용되며, 결과는 스트림입니다. 조인 결과 튜플의 타임스탬프는 입력 스트림 튜플의 타임스탬프와 같습니다. 두 스트림 간의 조인은 하나의 스트림에서 일찍 발생한 튜플이 나중에 다른 스트림에서 발생한 튜플과 일치할 수 있기 때문에 저장 문제를 초래할 수 있습니다. 이를 방지하기 위해 스트리밍 SQL 시스템은 일치하는 튜플의 시간 차이를 제한하는 조건이 있는 경우에만 스트림 간 조인을 허용합니다. 예를 들어, 두 튜플의 타임스탬프가 최대 1시간 차이가 나는 조건이 이에 해당합니다.

#### 10.5.3 스트림에 대한 대수 연산

스트리밍 데이터에 대한 SQL 쿼리는 매우 유용하지만, SQL 쿼리가 적합하지 않은 많은 응용 프로그램이 있습니다. 스트림 처리에 대한 대수 연산 접근 방식에서는 대수 연산을 구현하기 위한 사용자 정의 코드를 제공할 수 있습니다. 또한, 선택 및 창 집계와 같은 여러 미리 정의된 대수 연산도 제공됩니다.

계산을 수행하려면 들어오는 튜플을 소비하는 연산자로 라우팅하고, 연산자의 출력을 소비자에게 라우팅해야 합니다. 구현의 주요 작업은 시스템 입력, 연산자 및 출력 간의 튜플을 내결함성 있게 라우팅하는 것입니다. Apache Storm 및 Kafka는 이러한 데이터 라우팅을 지원하는 널리 사용되는 구현입니다.

튜플의 논리적 라우팅은 연산자를 노드로 하는 방향성 비순환 그래프(DAG)를 생성하여 수행됩니다. 노드 간의 엣지는 튜플의 흐름을 정의합니다. 각 연산자의 출력 튜플은 연산자의 모든 아웃 엣지에 따라 소비 연산자로 전송됩니다. 각 연산자는 모든 인 엣지에서 튜플을 수신합니다. 그림 10.11a는 DAG 구조를 통해 스트림 튜플의 논리적 라우팅을 나타냅니다. 그림에서 연산 노드는 "Op" 노드로 표시됩니다. 스트림 처리 시스템의 진입점은 데이터 소스 노드이며, 이러한 노드는 스트림 소스에서 튜플을 소비하고 스트림 처리 시스템에 삽입합니다. 스트림 처리 시스템의 출구점은 데이터 싱크 노드이며, 시스템을 떠나는 튜플은 데이터 스토어 또는 파일 시스템에 저장되거나 다른 방식으로 출력될 수 있습니다.

스트림 처리 시스템을 구현하는 한 가지 방법은 시스템 구성 파일의 일부로 그래프를 지정하는 것입니다. 시스템이 튜플을 처리하기 시작할 때 구성 파일을 읽고 이를 사용하여 튜플을 라우팅합니다. Apache Storm 스트림 처리 시스템은 그래프를 정의하는 구성 파일을 사용하는 시스템의 예입니다. Storm 시스템에서 데이터 소스 노드는 spout라고 하며, 연산자 노드는 bolt라고 합니다. 엣지는 이러한 노드를 연결합니다.

이러한 라우팅 그래프를 생성하는 또 다른 방법은 발행-구독 시스템을 사용하는 것입니다. 발행-구독 시스템은 문서 또는 기타 형태의 데이터를 주제와 함께 발행할 수 있도록 합니다. 구독자는 해당 주제를 지정하여 구독합니다. 특정 주제에 문서가 발행되면 해당 주제를 구독한 모든 구독자에게 문서의 복사본이 전송됩니다. 발행-구독 시스템은 pub-sub 시스템이라고도 합니다.

발행-구독 시스템이 스트림 처리 시스템에서 튜플 라우팅에 사용될 때, 튜플은 문서로 간주되며 각 튜플은 주제로 태그가 지정됩니다. 시스템의 진입점은 주제와 함께 튜플을 "발행"합니다. 연산자는 하나 이상의 주제를 구독하며, 시스템은 특정 주제와 일치하는 모든 튜플을 해당 주제를 구독한 모든 소비자에게 라우팅합니다. 연산자는 출력 결과를 다시 발행-구독 시스템에 발행하여 주제와 연결할 수 있습니다.

발행-구독 접근 방식의 주요 이점은 연산자를 시스템에 쉽게 추가하거나 제거할 수 있다는 것입니다. 그림 10.11b는 발행-구독 표현을 사용한 튜플 라우팅을 나타냅니다. 각 데이터 소스는 고유한 주제 이름이 할당되며, 각 연산자의 출력에도 고유한 주제 이름이 할당됩니다. 각 연산자는 입력 주제를 구독하고, 출력 주제에 발행합니다. 데이터 소스는 해당 주제에 발행하고, 데이터 싱크는 해당 출력 주제를 구독합니다.

Apache Kafka 시스템은 발행-구독 모델을 사용하여 스트림의 튜플 라우팅을 관리합니다. Kafka 시스템에서 특정 주제에 대해 발행된 튜플은 보존 기간 동안 유지됩니다. 보존 기간 동안 해당 주제에 구독자가 없더라도 유지됩니다. 구독자는 일반적으로 가능한 빨리 튜플을 처리하지만, 처리 지연이나 일시적인 중단이 발생하면 보존 시간이 만료될 때까지 튜플을 처리할 수 있습니다.

라우팅 및 병렬 시스템에서 발행-구독 구현에 대한 자세한 내용은 22.8절에서 제공합니다.

다음으로 대수 연산을 어떻게 구현할지 설명하겠습니다. 앞서 파일 및 기타 데이터 소스를 입력으로 사용하는 대수 연산을 어떻게 계산하는지 살펴보았습니다.

Apache Spark는 스트림 데이터 소스를 입력으로 사용할 수 있도록 합니다. 주요 문제는 일부 연산이 전체 스트림을 소비할 때까지 결과를 전혀 출력하지 않을 수 있다는 것입니다. 이는 잠재적으로 무한한 시간이 걸릴 수 있습니다. 이를 방지하기 위해 Spark는 스트림을 시간 창으로 분할하여 창의 데이터를 대수 연산의 입력 데이터로 처리합니다. 창의 데이터가 소비되면, 연산자는 마치 데이터 소스가 파일 또는 관계인 것처럼 출력을 생성합니다.

그러나 위 접근 방식에는 연산을 실행하기 전에 스트림을 분할해야 하는 문제가 있습니다. 다른 시스템인 Apache Storm 및 Apache Flink는 스트림을 입력으로 사용하고 다른 스트림을 출력하는 스트림 연산을 지원합니다. 이는 map 또는 관계 선택 연산과 같은 연산에는 간단합니다. 각 출력 튜플은 입력 튜플의 타임스탬프를 상속받습니다. 반면, 관계 집계 연산 및 reduce 연산은 전체 스트림을 소비하기 전에는 출력을 생성할 수 없습니다. 이를 지원하기 위해 Flink는 스트림을 창으로 분할하는 창 연산을 지원합니다. 각 창 내에서 집계가 수행되며 창이 완료되면 출력됩니다. 출력은 창의 끝을 기반으로 타임스탬프를 가지는 스트림으로 처리됩니다.

### 10.6 그래프 데이터베이스

그래프는 데이터베이스가 처리해야 하는 중요한 데이터 유형입니다. 예를 들어, 여러 라우터와 이를 연결하는 링크가 있는 컴퓨터 네트워크는 노드를 라우터로, 링크를 엣지로 모델링하여 그래프로 표현할 수 있습니다. 도로 네트워크는 또 다른 일반적인 그래프 유형으로, 도로 교차로를 노드로, 교차로 간의 도로 링크를 엣지로 모델링합니다. 웹 페이지와 하이퍼링크는 또 다른 그래프 예시입니다. 웹 페이지는 노드로, 하이퍼링크는 엣지로 모델링할 수 있습니다.

사실, 기업의 E-R 모델을 고려하면, 모든 엔티티를 그래프의 노드로, 모든 이진 관계를 그래프의 엣지로 모델링할 수 있습니다. 3항 및 고차 관계는 모델링하기 어렵지만, 6.9.4절에서 보았듯이, 이러한 관계는 원한다면 이진 관계 집합으로 모델링할 수 있습니다.

그래프는 다음 두 관계를 사용하여 관계형 모델로 표현할 수 있습니다:

1. node(ID, label, node_data)
2. edge(fromID, toID, label, edge_data)

여기서 node_data 및 edge_data는 각각 노드 및 엣지와 관련된 모든 데이터를 포함합니다.

단지 두 개의 관계를 사용하여 그래프를 모델링하는 것은 복잡한 데이터베이스 스키마에 너무 단순합니다. 예를 들어, 애플리케이션은 각기 다른 속성을 가진 여러 유형의 노드를 모델링해야 하며, 여러 유형의 엣지를 모델링해야 합니다. 각각의 속성을 가진 노드를 저장하는 여러 관계와 각각의 속성을 가진 엣지를 저장하는 여러 관계를 가질 수 있습니다.



그래프 데이터를 관계형 데이터베이스에 쉽게 저장할 수 있지만, 널리 사용되는 Neo4j와 같은 그래프 데이터베이스는 몇 가지 추가 기능을 제공합니다:

- 관계를 노드 또는 엣지로 식별하고 이러한 관계를 정의하는 특별한 구문을 제공합니다.
- 경로 쿼리를 쉽게 표현할 수 있는 쿼리 언어를 지원합니다. 이러한 쿼리는 SQL에서 표현하기 어렵습니다.
- 이러한 쿼리를 매우 빠르게 실행할 수 있는 효율적인 구현을 제공합니다. SQL에서 표현된 쿼리보다 훨씬 빠르게 실행할 수 있습니다.
- 그래프 시각화와 같은 다른 기능을 지원합니다.

그래프 쿼리의 예로, Neo4j에서 지원하는 Cypher 쿼리 언어를 고려해 보겠습니다. 입력 그래프에는 학생을 나타내는 노드(학생 관계에 저장)와 강사를 나타내는 노드(강사 관계에 저장), 학생에서 강사로 가는 advisor 엣지 유형이 있다고 가정합니다. Neo4j에서 이러한 노드 및 엣지 유형을 생성하는 방법에 대한 세부 사항은 생략하고, 이러한 유형에 적절한 스키마가 있다고 가정합니다. 그런 다음 다음과 같은 쿼리를 작성할 수 있습니다:

```cypher
match (i:instructor)<-[:advisor]-(s:student)
where i.dept
return i.ID as ID, i.name as name, collect(s.name) as advisees
```

쿼리의 match 절은 advisor 엣지를 통해 강사와 학생을 연결합니다. advisor 엣지는 학생에서 강사로 향하므로, 역방향으로 경로를 탐색합니다. 쿼리는 instructor, advisor 및 student 관계의 조인을 수행합니다. 그런 다음 강사의 ID와 이름으로 그룹화하고, 강사가 지도한 모든 학생을 advisees 집합으로 수집합니다. 자세한 내용은 생략하며, 자세한 내용은 [neo4j.com/developer](http://neo4j.com/developer)에서 온라인 튜토리얼을 참조하십시오.

Neo4j는 엣지의 재귀적 탐색도 지원합니다. 예를 들어, 과정의 직접 및 간접적인 선행 과정을 찾으려면 course를 노드로 모델링하고, prereq(course_id, prereq_id) 관계를 엣지로 모델링할 수 있습니다. 그런 다음 다음과 같은 쿼리를 작성할 수 있습니다:

```cypher
match (c1:course)-[:prereq *1..]->(c2:course)
return c1.course_id, c2.course_id
```

여기서 `*1..` 표기는 하나 이상의 prereq 엣지가 있는 경로를 고려한다는 것을 나타내며, 최소 1개의 엣지가 필요합니다(최소 0인 경우, 과정을 자신의 선행 과정으로 나타냅니다).

Neo4j는 중앙 집중식 시스템이며 병렬 처리를 지원하지 않습니다(2018년 기준). 그러나 매우 큰 그래프를 처리해야 하는 많은 응용 프로그램이 있으며, 이러한 응용 프로그램에서는 병렬 처리가 중요합니다.

PageRank 계산(8.3.2.2절에서 보았듯이)은 매우 큰 그래프에 대한 복잡한 계산의 좋은 예입니다. 이 그래프에는 각 웹 페이지에 대한 노드와 한 페이지에서 다른 페이지로 가는 하이퍼링크에 대한 엣지가 포함됩니다. 웹 그래프에는 오늘날 수백억 개의 노드와 수조 개의 엣지가 있습니다. 소셜 네트워크는 수십억 개의 노드와 엣지를 포함하는 또 다른 예로, 이러한 그래프에 대한 계산에는 연결성을 찾기 위한 최단 경로 또는 엣지에 기반한 사람의 영향력을 계산하는 작업이 포함됩니다.

병렬 그래프 처리를 위한 두 가지 인기 있는 접근 방식이 있습니다:

1. **Map-reduce 및 대수 프레임워크:** 그래프를 관계로 표현할 수 있으며, 많은 병렬 그래프 알고리즘의 개별 단계는 조인으로 표현할 수 있습니다. 그래프는 여러 머신에 걸쳐 분할된 병렬 저장 시스템에 저장할 수 있습니다. 그런 다음 map-reduce 프로그램, Spark와 같은 대수 프레임워크 또는 병렬 관계형 데이터베이스 구현을 사용하여 그래프 알고리즘의 각 단계를 병렬로 처리할 수 있습니다.
   - 이러한 접근 방식은 많은 응용 프로그램에 적합합니다. 그러나 긴 경로를 반복적으로 탐색하는 계산을 수행할 때, 이러한 접근 방식은 매우 비효율적입니다. 이는 각 반복에서 전체 그래프를 읽어야 하기 때문입니다.
2. **일괄 동기화 처리 프레임워크:** 일괄 동기화 처리(BSP) 프레임워크는 그래프 알고리즘을 반복적으로 작동하는 정점과 관련된 계산으로 구성합니다. 앞의 접근 방식과 달리, 여기서는 그래프가 일반적으로 메모리에 저장되며, 그래프를 각 반복에서 읽을 필요가 없습니다.
   - 그래프의 각 정점(노드)은 관련된 데이터를 가지고 있습니다. MapReduce 프레임워크에서 프로그래머가 `map()` 및 `reduce()` 함수를 제공하는 것처럼, BSP 프레임워크에서는 프로그래머가 그래프의 각 노드에서 실행되는 메서드를 제공합니다. 메서드는 그래프의 인접 노드로 메시지를 보내고, 인접 노드에서 메시지를 받을 수 있습니다. 각 반복(슈퍼스텝)에서는 각 노드와 관련된 메서드가 실행됩니다. 메서드는 들어오는 메시지를 소비하고, 노드와 관련된 데이터를 업데이트하며, 선택적으로 인접 노드로 메시지를 보낼 수 있습니다. 한 반복에서 보낸 메시지는 다음 반복에서 수신됩니다. 각 정점에서 실행되는 메서드는 더 이상 수행할 계산이 없다고 판단하면 중지할 수 있습니다. 모든 정점이 중지하기로 결정하고 메시지가 전송되지 않으면 계산이 중지될 수 있습니다.
   - 계산 결과는 각 노드에 있는 상태에 포함됩니다. 상태는 수집되어 계산 결과로 출력될 수 있습니다.
   - 일괄 동기화 처리 아이디어는 오래된 개념이지만, Google이 개발한 Pregel 시스템에 의해 인기를 끌었습니다. Pregel 시스템은 프레임워크의 내결함성 구현을 제공했습니다. Apache Giraph 시스템은 Pregel 시스템의 오픈 소스 버전입니다.
   - Apache Spark의 GraphX 구성 요소는 대규모 그래프에 대한 그래프 계산을 지원합니다. GraphX는 Pregel을 기반으로 한 API뿐만 아니라 그래프를 입력으로 받고 그래프를 출력하는 여러 연산도 제공합니다. GraphX에서 지원하는 연산에는 그래프의 정점 및 엣지에 적용되는 맵 함수, RDD와의 조인, 및 메시지를 생성하여 인접 노드로 보내고, 메시지를 집계하는 사용자 정의 함수를 사용하여 집계하는 연산이 포함됩니다. 이러한 모든 연산은 대규모 그래프를 처리하기 위해 병렬로 실행될 수 있습니다.

이와 같은 환경에서 그래프 알고리즘을 작성하는 방법에 대한 자세한 내용은 챕터 끝에 있는 추가 읽기 섹션의 참조 문헌을 참조하십시오.