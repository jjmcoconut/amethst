### 12.2 I/O 하드웨어

컴퓨터는 다양한 종류의 장치를 운영합니다. 대부분의 장치는 저장 장치(디스크, 테이프), 전송 장치(네트워크 연결, 블루투스), 인간-인터페이스 장치(화면, 키보드, 마우스, 오디오 입력 및 출력) 등의 일반적인 범주에 속합니다. 항공기 조종과 관련된 장치와 같이 보다 전문화된 장치들도 있습니다. 이러한 항공기에서는 사람이 조이스틱과 발 페달을 통해 비행 컴퓨터에 입력을 제공하며, 컴퓨터는 방향타와 플랩을 움직이고 엔진으로 연료를 보내는 명령을 출력합니다. 비록 I/O 장치의 종류는 매우 다양하지만, 장치가 어떻게 연결되고 소프트웨어가 하드웨어를 제어할 수 있는지 이해하는 데 필요한 개념은 몇 가지뿐입니다.

장치는 케이블을 통해 또는 무선으로 신호를 보내 컴퓨터 시스템과 통신합니다. 장치는 연결 지점, 즉 포트를 통해 기계와 통신합니다. 예를 들어, 시리얼 포트가 그 예입니다. (OSI 모델의 물리 계층을 줄인 용어인 PHY는 포트에 대해 언급할 때도 사용되지만, 데이터 센터 명명법에서 더 일반적입니다.) 장치가 공통의 전선 세트를 공유하면 그 연결을 버스라고 합니다. 대부분의 컴퓨터에서 사용되는 PCI 버스와 같은 버스는 전선 세트와 전선에서 보낼 수 있는 메시지 세트를 지정하는 엄격하게 정의된 프로토콜로 구성됩니다. 전자공학적으로 메시지는 정의된 타이밍에 전선에 적용되는 전압 패턴에 의해 전달됩니다. 장치 A가 장치 B에 연결되는 케이블을 갖고, 장치 B는 장치 C에 연결되는 케이블을 갖고, 장치 C는 컴퓨터의 포트에 연결되는 경우, 이 배열을 데이지 체인이라고 합니다. 데이지 체인은 일반적으로 버스로 작동합니다.

버스는 컴퓨터 아키텍처에서 널리 사용되며, 신호 방식, 속도, 처리량 및 연결 방식이 다양합니다. 일반적인 PC 버스 구조는 그림 12.1에 나타나 있습니다. 이 그림에서 PCIe 버스(일반적인 PC 시스템 버스)는 프로세서-메모리 서브시스템을 빠른 장치에 연결하며, 확장 버스는 키보드, 시리얼 및 USB 포트와 같은 상대적으로 느린 장치에 연결합니다. 그림의 왼쪽 하단 부분에서는 네 개의 디스크가 SAS 컨트롤러에 연결된 시리얼 부착 SCSI(SAS) 버스에 연결되어 있습니다. PCIe는 하나 이상의 "레인"을 통해 데이터를 전송하는 유연한 버스입니다. 레인은 데이터를 수신하는 한 쌍과 전송하는 한 쌍으로 구성됩니다. 따라서 각 레인은 네 개의 전선으로 구성되며, 각 레인은 양방향으로 데이터를 동시에 전송하는 풀 듀플렉스 바이트 스트림으로 사용됩니다. 물리적으로 PCIe 링크는 1, 2, 4, 8, 12, 16 또는 32개의 레인을 가질 수 있으며, "x" 접두사로 표시됩니다. 예를 들어, 8개의 레인을 사용하는 PCIe 카드나 커넥터는 x8로 표시됩니다. 또한, PCIe는 여러 "세대"를 거쳤으며, 앞으로도 계속 발전할 예정입니다. 예를 들어, "PCIe gen3 x8" 카드는 PCIe의 세대 3과 호환되며 8개의 레인을 사용한다는 의미입니다. 이러한 장치는 최대 8GB/s의 처리량을 갖습니다. PCIe에 대한 자세한 내용은 [pcisig.com](https://pcisig.com)에서 확인할 수 있습니다.

컨트롤러는 포트, 버스 또는 장치를 작동시킬 수 있는 전자 장치의 모음입니다. 시리얼 포트 컨트롤러는 간단한 장치 컨트롤러입니다. 이는 컴퓨터의 단일 칩(또는 칩의 일부)으로, 시리얼 포트의 전선에 신호를 제어합니다. 반면, 파이버 채널(FC) 버스 컨트롤러는 단순하지 않습니다. FC 프로토콜은 복잡하며, PC가 아닌 데이터 센터에서 사용되므로 FC 버스 컨트롤러는 종종 컴퓨터의 버스에 연결되는 별도의 회로 기판, 즉 호스트 버스 어댑터(HBA)로 구현됩니다. 이 컨트롤러는 일반적으로 프로세서, 마이크로코드 및 FC 프로토콜 메시지를 처리할 수 있는 일부 전용 메모리를 포함합니다. 일부 장치는 자체 내장된 컨트롤러를 갖추고 있습니다. 디스크 드라이브를 보면 한쪽에 부착된 회로 기판을 볼 수 있습니다. 이 보드는 디스크 컨트롤러로, SAS 및 SATA와 같은 연결 유형의 프로토콜을 구현합니다. 이 보드는 불량 섹터 매핑, 프리페칭, 버퍼링 및 캐싱과 같은 많은 작업을 수행하는 마이크로코드와 프로세서를 포함하고 있습니다.

### 12.2.1 메모리 맵드 I/O

프로세서는 어떻게 컨트롤러에 명령과 데이터를 전달하여 I/O 전송을 수행할까요? 짧은 대답은 컨트롤러가 데이터와 제어 신호를 위한 하나 이상의 레지스터를 가지고 있다는 것입니다. 프로세서는 이 레지스터의 비트 패턴을 읽고 쓰는 방식으로 컨트롤러와 통신합니다. 이 통신이 발생할 수 있는 한 가지 방법은 특수한 I/O 명령을 사용하는 것입니다. 이 명령은 I/O 포트 주소로 바이트 또는 워드를 전송하도록 지정합니다. I/O 명령은 버스 라인을 트리거하여 적절한 장치를 선택하고 장치 레지스터로 비트를 이동시킵니다. 또는 장치는 메모리 맵드 I/O를 지원할 수 있습니다. 이 경우 장치 제어 레지스터는 프로세서의 주소 공간에 매핑됩니다. CPU는 물리 메모리의 매핑된 위치에 있는 장치 제어 레지스터를 읽고 쓰기 위해 표준 데이터 전송 명령을 사용하여 I/O 요청을 실행합니다.

과거에는 PC에서 일부 장치는 I/O 명령을 사용하여 제어하고 다른 장치는 메모리 맵드 I/O를 사용하여 제어했습니다. 그림 12.2는 PC의 일반적인 I/O 포트 주소를 보여줍니다. 그래픽 컨트롤러는 기본 제어 작업을 위한 I/O 포트를 가지고 있지만, 화면 내용을 저장하기 위해 큰 메모리 맵드 영역을 가지고 있습니다. 스레드는 메모리 맵드 영역에 데이터를 써서 화면에 출력합니다. 컨트롤러는 이 메모리의 내용을 기반으로 화면 이미지를 생성합니다. 이 기술은 사용하기 간단합니다. 또한 그래픽 메모리에 수백만 바이트를 쓰는 것이 수백만 개의 I/O 명령을 발행하는 것보다 빠릅니다. 따라서 시간이 지남에 따라 시스템은 메모리 맵드 I/O로 이동했습니다. 오늘날 대부분의 I/O는 메모리 맵드 I/O를 사용하는 장치 컨트롤러에 의해 수행됩니다.

I/O 장치 제어는 일반적으로 상태, 제어, 데이터 입력, 데이터 출력 레지스터라고 불리는 네 개의 레지스터로 구성됩니다.
- 데이터 입력 레지스터는 호스트가 입력을 얻기 위해 읽습니다.
- 데이터 출력 레지스터는 호스트가 출력을 보내기 위해 씁니다.
- 상태 레지스터에는 호스트가 읽을 수 있는 비트가 포함됩니다. 이 비트는 현재 명령이 완료되었는지, 데이터 입력 레지스터에서 읽을 수 있는 바이트가 있는지, 장치 오류가 발생했는지 등의 상태를 나타냅니다.
- 제어 레지스터는 호스트가 명령을 시작하거나 장치 모드를 변경하기 위해 쓸 수 있습니다. 예를 들어, 시리얼 포트의 제어 레지스터의 특정 비트는 풀 듀플렉스와 반 듀플렉스 통신을 선택하고, 다른 비트는 패리티 검사를 활성화하며, 세 번째 비트는 단어 길이를 7 또는 8비트로 설정하고, 다른 비트는 시리얼 포트가 지원하는 속도 중 하나를 선택합니다.

데이터 레지스터는 일반적으로 1에서 4바이트 크기입니다. 일부 컨트롤러는 데이터 레지스터 크기를 초과하여 여러 바이트의 입력 또는 출력 데이터를 보유할 수 있는 FIFO 칩을 가지고 있습니다. FIFO 칩은 장치 또는 호스트가 이러한 데이터를 수신할 수 있을 때까지 데이터의 작은 버스트를 보유할 수 있습니다.

### 12.2.2 폴링

호스트와 컨트롤러 간의 상호 작용을 위한 완전한 프로토콜은 복잡할 수 있지만, 기본적인 핸드셰이킹

 개념은 간단합니다. 우리는 예를 통해 핸드셰이킹을 설명합니다. 컨트롤러와 호스트 간의 생산자-소비자 관계를 조정하기 위해 두 비트를 사용한다고 가정해 봅시다. 컨트롤러는 상태 레지스터의 busy 비트를 통해 상태를 표시합니다. (비트를 설정한다는 것은 비트에 1을 쓰는 것이고, 비트를 지운다는 것은 비트에 0을 쓰는 것입니다.) 컨트롤러는 작업 중일 때 busy 비트를 설정하고, 다음 명령을 받을 준비가 되면 busy 비트를 지웁니다. 호스트는 명령 레지스터의 command-ready 비트를 통해 원하는 바를 신호합니다. 호스트는 컨트롤러가 실행할 수 있는 명령이 있을 때 command-ready 비트를 설정합니다. 이 예제에서는 호스트가 포트를 통해 출력을 쓰고, 핸드셰이킹을 통해 컨트롤러와 조정합니다.

1. 호스트는 busy 비트가 지워질 때까지 반복해서 읽습니다.
2. 호스트는 명령 레지스터에 쓰기 비트를 설정하고 데이터 출력 레지스터에 바이트를 씁니다.
3. 호스트는 command-ready 비트를 설정합니다.
4. 컨트롤러가 command-ready 비트가 설정된 것을 인지하면 busy 비트를 설정합니다.
5. 컨트롤러는 명령 레지스터를 읽어 쓰기 명령을 확인합니다. 컨트롤러는 데이터 출력 레지스터에서 바이트를 읽고 장치로 I/O를 수행합니다.
6. 컨트롤러는 command-ready 비트를 지우고, 장치 I/O가 성공했음을 나타내기 위해 상태 레지스터의 오류 비트를 지우고, 작업이 완료되었음을 나타내기 위해 busy 비트를 지웁니다.

이 루프는 각 바이트마다 반복됩니다.

1단계에서 호스트는 busy-waiting 또는 폴링 중입니다: 호스트는 busy 비트가 지워질 때까지 상태 레지스터를 반복해서 읽는 루프에 있습니다. 컨트롤러와 장치가 빠르면 이 방법이 합리적입니다. 하지만 기다림이 길어질 가능성이 있다면, 호스트는 다른 작업으로 전환해야 합니다. 그렇다면 호스트는 컨트롤러가 유휴 상태가 되었는지 어떻게 알 수 있을까요? 일부 장치의 경우 호스트는 데이터를 잃지 않기 위해 장치를 신속하게 서비스해야 합니다. 예를 들어, 시리얼 포트 또는 키보드에서 데이터가 스트리밍될 때, 컨트롤러의 작은 버퍼가 오버플로우하여 호스트가 바이트를 읽기 전에 데이터를 잃게 됩니다.

많은 컴퓨터 아키텍처에서 장치를 폴링하는 데 세 가지 CPU 명령 사이클이 충분합니다: 장치 레지스터를 읽고, 논리적으로 AND하여 상태 비트를 추출하며, 0이 아니면 분기합니다. 기본 폴링 작업은 분명히 효율적입니다. 하지만 폴링이 반복적으로 시도되어도 장치가 서비스 준비가 거의 되지 않고, 다른 유용한 CPU 처리가 남아 있을 때는 폴링이 비효율적입니다. 이러한 경우, 장치가 서비스 준비가 되면 CPU에 알리도록 하드웨어 컨트롤러를 구성하는 것이 CPU가 반복적으로 I/O 완료를 위해 폴링하는 것보다 더 효율적일 수 있습니다. 장치가 CPU에 알리는 하드웨어 메커니즘을 인터럽트라고 합니다.

### 12.2.3 인터럽트

기본 인터럽트 메커니즘은 다음과 같이 작동합니다. CPU 하드웨어에는 인터럽트 요청 라인이라고 불리는 선이 있으며, CPU는 모든 명령을 실행한 후 이 신호를 감지합니다. CPU가 컨트롤러가 인터럽트 요청 라인에 신호를 보낸 것을 감지하면, CPU는 상태를 저장하고 메모리의 고정된 주소에 있는 인터럽트 처리 루틴으로 점프합니다. 인터럽트 처리기는 인터럽트의 원인을 결정하고, 필요한 처리를 수행하며, 상태를 복원하고, 인터럽트 이전의 실행 상태로 CPU를 복귀시키는 인터럽트 복귀 명령을 실행합니다. 장치 컨트롤러가 인터럽트 요청 라인에 신호를 보내 인터럽트를 발생시킨다고 하고, CPU가 인터럽트를 감지하여 인터럽트 처리기로 전달한 후, 처리기가 장치를 서비스하여 인터럽트를 제거한다고 말합니다. 그림 12.3은 인터럽트 구동 I/O 사이클을 요약한 것입니다.

우리는 이 장에서 인터럽트 관리를 강조합니다. 현대의 단일 사용자 시스템조차도 초당 수백 개의 인터럽트를 관리하며, 서버는 초당 수십만 개의 인터럽트를 관리합니다. 예를 들어, 그림 12.4는 macOS에서의 latency 명령 출력을 보여주며, 조용한 데스크탑 컴퓨터가 10초 동안 거의 23,000개의 인터럽트를 수행했음을 나타냅니다.

기본 인터럽트 메커니즘은 컨트롤러가 서비스 준비가 되었을 때 CPU가 비동기 이벤트에 응답할 수 있도록 합니다. 그러나 현대 운영 체제에서는 더 정교한 인터럽트 처리 기능이 필요합니다.

1. 중요한 처리 중에 인터럽트 처리를 연기할 수 있는 능력이 필요합니다.
2. 모든 장치를 폴링하지 않고 장치에 적절한 인터럽트 처리기로 효율적으로 디스패치할 수 있는 방법이 필요합니다.
3. 높은 우선순위와 낮은 우선순위 인터럽트를 구별하고, 여러 동시 인터럽트가 발생할 때 적절한 긴급도로 응답할 수 있도록 다중 레벨 인터럽트가 필요합니다.
4. 페이지 폴트와 같은 활동을 위해 운영 체제의 주의를 직접 끌어야 할 필요가 있습니다. 이 작업은 "트랩"이라는 방식으로 수행됩니다.

현대 컴퓨터 하드웨어에서는 이러한 기능이 CPU와 인터럽트 컨트롤러 하드웨어에 의해 제공됩니다.

대부분의 CPU는 두 개의 인터럽트 요청 라인을 가지고 있습니다. 하나는 복구 불가능한 메모리 오류와 같은 이벤트를 위한 비마스크 인터럽트입니다. 두 번째 인터럽트 라인은 마스크 가능하여, CPU가 중요한 명령 시퀀스를 실행하기 전에 인터럽트를 꺼서 인터럽트되지 않도록 할 수 있습니다. 마스크 가능한 인터럽트는 장치 컨트롤러가 서비스를 요청하는 데 사용됩니다.

인터럽트 메커니즘은 특정 인터럽트 처리 루틴을 선택하는 주소를 수신합니다. 대부분의 아키텍처에서 이 주소는 인터럽트 벡터라는 테이블의 오프셋입니다. 이 벡터에는 특수화된 인터럽트 처리기의 메모리 주소가 포함되어 있습니다. 벡터화된 인터럽트 메커니즘의 목적은 단일 인터럽트 처리기가 서비스를 필요로 하는 모든 가능한 인터럽트 소스를 검색해야 하는 필요성을 줄이는 것입니다. 그러나 실제로 컴퓨터에는 인터럽트 벡터의 주소 요소보다 더 많은 장치(및 따라서 인터럽트 처리기)가 있습니다. 이 문제를 해결하는 일반적인 방법은 각 인터럽트 벡터 요소가 인터럽트 처리기 목록의 시작 부분을 가리키는 인터럽트 체이닝을 사용하는 것입니다. 인터럽트가 발생하면 해당 목록의 처리기가 하나씩 호출되어 요청을 서비스할 수 있는 처리가 있을 때까지 호출됩니다. 이 구조는 방대한 인터럽트 테이블의 오버헤드와 단일 인터럽트 처리기로 디스패치하는 비효율성 사이의 타협입니다.

그림 12.5는 Intel 펜티엄 프로세서의 인터럽트 벡터 설계를 보여줍니다. 0에서 31까지의 이벤트는 마스크되지 않으며, 다양한 오류 조건(시스템 충돌을 일으킴), 페이지 폴트(즉각적인 조치 필요), 디버깅 요청(정상 작동을 중지하고 디버거 애플리케이션으로 점프) 등을 신호로 보냅니다. 32에서 255까지의 이벤트는 장치 생성 인터럽트와 같은 목적으로 사용됩니다.

인터럽트 메커니즘은 또한 인터럽트 우선순위 수준 시스템을 구현합니다. 이 수준은 CPU가 모든 인터럽트를 마스킹하지 않고 저우선순위 인터럽트 처리를 연기할 수 있도록 하며, 높은 우선순위 인터럽트가 저우선순위 인터럽트의 실행을 선점할 수 있도록 합니다.

현대 운영 체제는 여러 방식으로 인터럽트 메커니즘과 상호 작용합니다. 부팅 시 운영 체제는 하드웨어 버스를 탐색하여 존재하는 장치를 확인하고 해당 인터럽트 처리기를 인터럽트 벡터에 설치합니다. I/O 중에 다양한 장치 컨트롤러는 서비스 준비가 되었을 때 인터럽트를 발생시킵니다. 이러한 인터럽트는 출력이 완료되었거나, 입력 데이터가 사용 가능하거나, 오류가 감지되었음을 나타

냅니다. 인터럽트 메커니즘은 또한 0으로 나누기, 보호된 메모리 주소에 접근 또는 특권 명령을 사용자 모드에서 실행하려는 시도와 같은 다양한 예외를 처리하는 데 사용됩니다. 인터럽트를 유발하는 이벤트는 운영 체제가 긴급하고 자족적인 루틴을 실행하도록 유도하는 공통 속성을 가지고 있습니다.

인터럽트 처리는 많은 경우 시간과 리소스가 제한되어 있기 때문에 구현하기 복잡하므로 시스템은 종종 첫 번째 수준 인터럽트 처리기(FLIH)와 두 번째 수준 인터럽트 처리기(SLIH)로 인터럽트 관리를 분할합니다. FLIH는 컨텍스트 스위치, 상태 저장 및 처리 작업 큐잉을 수행하고, 별도로 예약된 SLIH는 요청된 작업을 처리합니다.

운영 체제는 다른 용도로도 인터럽트를 잘 사용합니다. 예를 들어, 많은 운영 체제는 가상 메모리 페이징에 인터럽트 메커니즘을 사용합니다. 페이지 폴트는 인터럽트를 발생시키는 예외입니다. 인터럽트는 현재 프로세스를 중단하고 커널의 페이지 폴트 처리기로 점프합니다. 이 처리기는 프로세스의 상태를 저장하고, 프로세스를 대기 큐로 이동하며, 페이지 캐시 관리를 수행하고, 페이지를 가져오기 위한 I/O 작업을 예약하고, 다른 프로세스를 재개하도록 예약한 다음 인터럽트에서 복귀합니다.

또 다른 예는 시스템 호출의 구현에서 찾을 수 있습니다. 보통 프로그램은 라이브러리 호출을 사용하여 시스템 호출을 발행합니다. 라이브러리 루틴은 애플리케이션이 제공한 인수를 검사하고, 커널로 인수를 전달하기 위한 데이터 구조를 구성한 다음, 소프트웨어 인터럽트 또는 트랩이라고 불리는 특수 명령을 실행합니다. 이 명령은 요청된 커널 서비스를 식별하는 피연산자를 가집니다. 프로세스가 트랩 명령을 실행하면 인터럽트 하드웨어는 사용자 코드의 상태를 저장하고 커널 모드로 전환하며 요청된 서비스를 구현하는 커널 루틴 또는 스레드로 디스패치합니다. 트랩은 장치 인터럽트에 비해 상대적으로 낮은 인터럽트 우선순위를 가집니다. 애플리케이션을 대신하여 시스템 호출을 실행하는 것은 장치 컨트롤러를 서비스하는 것보다 긴급하지 않습니다.

인터럽트는 커널 내에서 제어 흐름을 관리하는 데에도 사용될 수 있습니다. 예를 들어, 디스크 읽기를 완료하기 위한 처리 작업을 고려해 봅시다. 한 단계는 데이터를 커널 공간에서 사용자 버퍼로 복사하는 것입니다. 이 복사는 시간이 많이 소요되지만 긴급하지 않습니다. 다른 단계는 해당 디스크 드라이브의 다음 대기 중인 I/O를 시작하는 것입니다. 이 단계는 우선순위가 높습니다. 디스크를 효율적으로 사용하려면 이전 I/O가 완료되자마자 다음 I/O를 시작해야 합니다. 결과적으로 인터럽트 처리기 쌍이 디스크 읽기를 완료하는 커널 코드를 구현합니다. 고우선순위 처리기는 I/O 상태를 기록하고, 장치 인터럽트를 지우며, 다음 대기 중인 I/O를 시작하고, 작업을 완료하기 위해 저우선순위 인터럽트를 발생시킵니다. 나중에 CPU가 고우선순위 작업으로 바쁘지 않을 때 저우선순위 인터럽트가 디스패치됩니다. 해당 처리기는 커널 버퍼에서 애플리케이션 공간으로 데이터를 복사하여 사용자 수준의 I/O를 완료하고, 애플리케이션을 준비 큐에 배치하도록 스케줄러를 호출합니다.

스레드 커널 아키텍처는 여러 인터럽트 우선순위를 구현하고 인터럽트 처리가 백그라운드 처리보다 우선하도록 강제하는 데 적합합니다. 우리는 이 점을 Solaris 커널로 설명합니다. Solaris에서는 인터럽트 처리기가 커널 스레드로 실행됩니다. 이러한 스레드에는 높은 스케줄링 우선순위 범위가 예약되어 있습니다. 이러한 우선순위는 인터럽트 처리기가 애플리케이션 코드와 커널 관리 작업보다 우선권을 가지게 하며, 인터럽트 처리기 간의 우선순위 관계를 구현합니다. 우선순위는 Solaris 스레드 스케줄러가 저우선순위 인터럽트 처리기보다 고우선순위 인터럽트 처리기를 선점하도록 하고, 스레드 구현은 멀티프로세서 하드웨어가 여러 인터럽트 처리기를 동시에 실행할 수 있도록 합니다. 우리는 20장에서 Linux의 인터럽트 아키텍처, 21장에서 Windows 10, 부록 C에서 UNIX를 설명합니다.

요약하자면, 인터럽트는 비동기 이벤트를 처리하고 커널의 슈퍼바이저 모드 루틴으로 트랩하기 위해 현대 운영 체제에서 널리 사용됩니다. 가장 긴급한 작업이 먼저 수행될 수 있도록 하기 위해 현대 컴퓨터는 인터럽트 우선순위 시스템을 사용합니다. 장치 컨트롤러, 하드웨어 결함 및 시스템 호출은 모두 커널 루틴을 트리거하기 위해 인터럽트를 발생시킵니다. 인터럽트는 시간에 민감한 처리를 위해 많이 사용되므로, 효율적인 인터럽트 처리가 좋은 시스템 성능을 위해 필요합니다. 인터럽트 구동 I/O는 이제 폴링보다 훨씬 더 일반적이며, 폴링은 고처리량 I/O에 사용됩니다. 때로는 두 가지가 함께 사용되기도 합니다. 일부 장치 드라이버는 I/O 속도가 낮을 때 인터럽트를 사용하고, 속도가 증가하여 폴링이 더 빠르고 효율적이게 되면 폴링으로 전환합니다.

### 12.2.4 직접 메모리 접근

디스크 드라이브와 같이 대량 전송을 수행하는 장치의 경우, 비싼 범용 프로세서를 사용하여 상태 비트를 감시하고 컨트롤러 레지스터에 데이터를 한 번에 한 바이트씩 공급하는 것은 낭비입니다. 이를 프로그램된 I/O(Programmed I/O, PIO)라고 합니다. 컴퓨터는 이러한 작업을 직접 메모리 접근(DMA) 컨트롤러라는 특수 목적의 프로세서에 오프로드하여 주 CPU에 부담을 주지 않습니다. DMA 전송을 시작하기 위해 호스트는 DMA 명령 블록을 메모리에 씁니다. 이 블록에는 전송 소스에 대한 포인터, 전송 목적지에 대한 포인터 및 전송할 바이트 수가 포함됩니다. 명령 블록은 복잡할 수 있으며, 연속적이지 않은 소스 및 목적지 주소 목록을 포함할 수 있습니다. 이 스캐터-개더 방법은 단일 DMA 명령을 통해 여러 전송을 실행할 수 있게 합니다. CPU는 이 명령 블록의 주소를 DMA 컨트롤러에 쓰고 다른 작업을 계속합니다. DMA 컨트롤러는 메모리 버스를 직접 작동하여, 메인 CPU의 도움 없이 전송을 수행할 주소를 버스에 배치합니다. 간단한 DMA 컨트롤러는 모든 현대 컴퓨터, 스마트폰에서 메인프레임에 이르기까지 표준 구성 요소입니다.

목표 주소가 커널 주소 공간에 있는 것이 가장 직관적입니다. 사용자 공간에 있다면, 예를 들어 사용자가 전송 중에 해당 공간의 내용을 수정하여 일부 데이터를 잃을 수 있습니다. 그러나 DMA 전송된 데이터를 스레드가 접근할 수 있도록 사용자 공간으로 가져오려면, 이번에는 커널 메모리에서 사용자 메모리로 두 번째 복사 작업이 필요합니다. 이중 버퍼링은 비효율적입니다. 시간이 지남에 따라 운영 체제는 메모리 맵핑(12.2.1절 참조)을 사용하여 장치와 사용자 주소 공간 간의 I/O 전송을 직접 수행하게 되었습니다.

DMA 컨트롤러와 장치 컨트롤러 간의 핸드셰이킹은 DMA 요청 및 DMA 승인이라는 두 개의 전선을 통해 수행됩니다. 장치 컨트롤러는 전송할 데이터 단어가 준비되었을 때 DMA 요청 전선에 신호를 보냅니다. 이 신호는 DMA 컨트롤러가 메모리 버스를 점유하게 하여 원하는 주소를 메모리 주소 전선에 배치하고 DMA 승인 전선에 신호를 배치하게 합니다. 장치 컨트롤러가 DMA 승인 신호를 받으면, 데이터 단어를 메모리로 전송하고 DMA 요청 신호를 제거합니다.

전체 전송이 완료되면 DMA 컨트롤러는 CPU에 인터럽트를 발생시킵니다. 이 과정은 그림 12.6에 나타나 있습니다. DMA 컨트롤러가 메모리 버스를 점유할 때, CPU는 메인 메모리에 접근하지 못하지만 캐시에 있는 데이터 항목에는 여전히 접근할 수 있습니다. 이러한 사이클 스틸링은 CPU 연산을 느리게 할 수 있지만, 데이터 전송 작업을 DMA 컨트

롤러에 오프로드하면 전체 시스템 성능이 향상됩니다. 일부 컴퓨터 아키텍처는 DMA에 물리 메모리 주소를 사용하지만, 다른 아키텍처는 가상 메모리 주소를 사용하여 물리 주소로 변환되는 직접 가상 메모리 접근(DVMA)을 수행합니다. DVMA는 CPU의 개입이나 메인 메모리 사용 없이 두 메모리 맵드 장치 간의 전송을 수행할 수 있습니다.

보호 모드 커널에서는 운영 체제가 일반적으로 프로세스가 장치 명령을 직접 발행하지 못하도록 합니다. 이 규율은 데이터 접근 제어 위반을 방지하고 장치 컨트롤러의 잘못된 사용으로 인한 시스템 충돌을 방지합니다. 대신 운영 체제는 충분히 권한이 있는 프로세스가 기본 하드웨어 작업에 접근할 수 있는 기능을 내보냅니다. 메모리 보호가 없는 커널에서는 프로세스가 장치 컨트롤러에 직접 접근할 수 있습니다. 이 직접 접근은 커널 통신, 컨텍스트 스위치 및 커널 소프트웨어 계층을 피할 수 있기 때문에 높은 성능을 달성하는 데 사용할 수 있습니다. 그러나 이는 시스템 보안과 안정성을 방해합니다. 일반적인 범용 운영 체제는 시스템이 잘못되었거나 악의적인 애플리케이션을 방지하기 위해 메모리와 장치를 보호합니다.


## 13.1 파일 컨셉

컴퓨터는 다양한 저장 매체, 예를 들어 NVM 장치, HDD, 자기 테이프, 광 디스크 등에 정보를 저장할 수 있습니다. 컴퓨터 시스템이 편리하게 사용되도록 운영 체제는 저장된 정보에 대해 통일된 논리적 관점을 제공합니다. 운영 체제는 저장 장치의 물리적 속성에서 추상화하여 논리적 저장 단위인 파일을 정의합니다. 운영 체제는 파일을 물리적 장치에 매핑합니다. 이러한 저장 장치는 일반적으로 비휘발성이므로 시스템 재부팅 사이에 내용이 유지됩니다.

파일은 2차 저장 장치에 기록된 관련 정보의 이름 있는 집합입니다. 사용자 관점에서 파일은 논리적 2차 저장 장치의 가장 작은 할당 단위입니다. 즉, 데이터는 파일 내에 있어야만 2차 저장 장치에 쓸 수 있습니다. 일반적으로 파일은 프로그램(소스 및 오브젝트 형식 모두)과 데이터를 나타냅니다. 데이터 파일은 숫자, 알파벳, 알파숫자, 이진 형식일 수 있습니다. 파일은 텍스트 파일처럼 자유 형식일 수도 있고, 엄격하게 형식화될 수도 있습니다. 일반적으로 파일은 비트, 바이트, 줄, 레코드의 시퀀스이며, 그 의미는 파일의 작성자와 사용자가 정의합니다. 따라서 파일의 개념은 매우 일반적입니다.

파일은 사용자가 데이터를 저장하고 검색하는 방법이기 때문에, 그리고 매우 범용적이므로 그 사용 범위가 원래 한계를 넘어 확장되었습니다. 예를 들어, UNIX, Linux 및 일부 다른 운영 체제는 시스템 정보(예: 프로세스 세부 정보)에 접근하기 위해 파일 시스템 인터페이스를 사용하는 proc 파일 시스템을 제공합니다.

파일의 정보는 작성자가 정의합니다. 파일에는 소스나 실행 가능한 프로그램, 숫자나 텍스트 데이터, 사진, 음악, 비디오 등 다양한 유형의 정보가 저장될 수 있습니다. 파일은 특정한 구조를 가지며, 이는 파일 유형에 따라 달라집니다. 텍스트 파일은 줄(및 경우에 따라 페이지)로 구성된 문자 시퀀스입니다. 소스 파일은 함수 시퀀스로, 각 함수는 선언문 뒤에 실행 가능한 문장이 따릅니다. 실행 파일은 로더가 메모리에 로드하여 실행할 수 있는 코드 섹션의 시리즈입니다.

### 13.1.1 파일 속성

파일은 인간 사용자의 편의를 위해 이름이 붙여지며, 이름으로 참조됩니다. 이름은 일반적으로 example.c와 같은 문자열입니다. 일부 시스템은 이름에서 대문자와 소문자를 구별하는 반면, 다른 시스템은 그렇지 않습니다. 파일이 이름 지어지면, 이는 파일을 생성한 프로세스, 사용자, 심지어 시스템과도 독립적이 됩니다. 예를 들어, 한 사용자가 example.c 파일을 생성하면 다른 사용자는 이름을 지정하여 해당 파일을 편집할 수 있습니다. 파일 소유자는 파일을 USB 드라이브에 쓰거나 이메일 첨부 파일로 보내거나 네트워크를 통해 복사할 수 있으며, 대상 시스템에서도 여전히 example.c로 불릴 수 있습니다. 공유 및 동기화 방법이 없는 한, 두 번째 복사본은 이제 첫 번째 복사본과 독립적으로 변경될 수 있습니다.

파일의 속성은 운영 체제마다 다르지만 일반적으로 다음을 포함합니다:
- 이름: 사람이 읽을 수 있는 형태로 유지되는 유일한 정보입니다.
- 식별자: 보통 숫자인 이 고유 태그는 파일 시스템 내에서 파일을 식별합니다. 이는 파일의 사람이 읽을 수 없는 이름입니다.
- 유형: 다른 유형의 파일을 지원하는 시스템에 필요한 정보입니다.
- 위치: 이 정보는 장치 및 해당 장치의 파일 위치에 대한 포인터입니다.
- 크기: 파일의 현재 크기(바이트, 워드 또는 블록 단위)와 최대 허용 크기가 포함됩니다.
- 보호: 접근 제어 정보는 누가 읽기, 쓰기, 실행 등을 할 수 있는지 결정합니다.
- 타임스탬프 및 사용자 식별: 이 정보는 생성, 마지막 수정 및 마지막 사용에 대해 유지될 수 있습니다. 이러한 데이터는 보호, 보안 및 사용 모니터링에 유용할 수 있습니다.

일부 최신 파일 시스템은 파일의 문자 인코딩 및 파일 체크섬과 같은 보안 기능을 포함한 확장 파일 속성을 지원합니다. 그림 13.1은 macOS의 파일 정보 창을 보여주며, 파일의 속성을 표시합니다.

모든 파일에 대한 정보는 디렉토리 구조에 유지되며, 이는 파일 자체와 동일한 장치에 위치합니다. 일반적으로 디렉토리 항목은 파일의 이름과 고유 식별자로 구성됩니다. 식별자는 다른 파일 속성을 찾습니다. 각 파일에 대해 이 정보를 기록하는 데 1킬로바이트 이상이 필요할 수 있습니다. 많은 파일이 있는 시스템에서는 디렉토리 자체의 크기가 메가바이트 또는 기가바이트가 될 수 있습니다. 디렉토리가 파일의 변동성을 맞추기 위해 파일처럼 장치에 저장되어야 하며, 필요에 따라 조각으로 메모리에 불러옵니다.

### 13.1.2 파일 작업

파일은 추상 데이터 유형입니다. 파일을 적절히 정의하려면 파일에서 수행할 수 있는 작업을 고려해야 합니다. 운영 체제는 파일을 생성, 쓰기, 읽기, 재배치, 삭제 및 잘라내기 위한 시스템 호출을 제공할 수 있습니다. 이러한 기본 파일 작업을 수행하기 위해 운영 체제가 수행해야 하는 작업을 살펴보겠습니다. 그러면 파일 이름 바꾸기와 같은 유사한 작업을 어떻게 구현할 수 있는지 쉽게 알 수 있습니다.

- 파일 생성: 파일을 생성하려면 두 가지 단계가 필요합니다. 첫째, 파일 시스템에서 파일에 대한 공간을 찾아야 합니다. 14장에서 파일에 대한 공간을 할당하는 방법에 대해 논의합니다. 둘째, 새로운 파일에 대한 항목을 디렉토리에 만들어야 합니다.
- 파일 열기: 모든 파일 작업이 파일 이름을 지정하여 운영 체제가 이름을 평가하고 접근 권한을 확인하게 하는 대신, 생성 및 삭제를 제외한 모든 작업에는 먼저 파일을 열어야 합니다. 열기 호출이 성공하면 다른 호출에서 인수로 사용되는 파일 핸들이 반환됩니다.
- 파일 쓰기: 파일에 쓰려면 열린 파일 핸들과 파일에 쓸 정보를 지정하는 시스템 호출을 해야 합니다. 시스템은 순차적인 경우 다음 쓰기가 발생할 파일 위치에 쓰기 포인터를 유지해야 합니다. 쓰기 발생 시 쓰기 포인터를 업데이트해야 합니다.
- 파일 읽기: 파일에서 읽으려면 파일 핸들과 파일의 다음 블록을 넣을 위치(메모리 내)를 지정하는 시스템 호출을 사용합니다. 시스템은 순차적인 경우 다음 읽기가 발생할 파일 위치에 대한 읽기 포인터를 유지해야 합니다. 읽기가 발생한 후 읽기 포인터가 업데이트됩니다. 프로세스는 일반적으로 파일에서 읽거나 쓰기 때문에 현재 작업 위치는 프로세스별 현재 파일 위치 포인터로 유지될 수 있습니다. 읽기와 쓰기 작업 모두 이 포인터를 사용하여 공간을 절약하고 시스템 복잡성을 줄입니다.
- 파일 내 위치 재배치: 열린 파일의 현재 파일 위치 포인터를 주어진 값으로 재배치합니다. 파일 내 재배치는 실제 I/O를 수반할 필요는 없습니다. 이 파일 작업은 파일 탐색이라고도 합니다.
- 파일 삭제: 파일을 삭제하려면 지정된 파일을 디렉토리에서 찾아야 합니다. 관련 디렉토리 항목을 찾으면 모든 파일 공간을 해제하여 다른 파일이 재사용할 수 있도록 하고 디렉토리 항목을 삭제하거나 무료로 표시합니다. 일부 시스템에서는 동일한 파일에 대해 여러 이름(디렉토리 항목)을 허용하는 하드 링크를 허용합니다. 이 경우 마지막 링크가 삭제될 때까지 실제 파일 내용은 삭제되지 않습니다.
- 파일 잘라내기: 사용자는 파일의 내용을 지우고 싶을 수 있지만 속성은 유지하고 싶을 수 있습니다. 사용자가 파일을 삭제한 후 다시 생성하도록 강요하는 대신 이 기능을 사용하면 파일 길이를 제외한 모든 속성이 변경되지 않은 상태로 유지됩니다. 그런 다음 파일 길이를 0으로 재설정하고 파일 공간을 해제할 수 있습니다.

이 7가지 기본 작업은 필요한 파일 작업의 최소 집합을 구성합니다. 다른 일반적인 작업으로는 기존 파일 끝에 새로운 정보를 추가하거나 기존 파일의 이름을 바꾸는 것이 있습니다. 이러한 기본 작업을 결합하여 다른 파일 작업을 수행할 수 있습니다. 예를 들어, 새 파일을 생성하고 기존 파일에서 읽고 새 파일에 쓰는 방식으로 파일 복사본을 만들 수 있습니다. 또한 사용자가 파일의 다양한 속성을 가져오고 설정할 수 있는 작업을 수행하기를 원합니다. 예를 들어, 사용자가 파일의 상태(예: 파일 길이)를 결정하고 파일 소유자와 같은 파일 속성을 설정할 수 있는 작업이 필요할 수 있습니다.

앞서 언급했듯이 대부분의 파일 작업은 지정된 파일과 연결된 항목을 찾기 위해 디렉토리를 검색해야 합니다. 이러한 지속적인 검색을 피하기 위해 많은 시스템에서는 파일이 처음 사용되기 전에 open() 시스템 호출

을 해야 합니다. 운영 체제는 모든 열린 파일에 대한 정보를 포함하는 테이블(열린 파일 테이블)을 유지합니다. 파일 작업이 요청되면 파일은 이 테이블의 인덱스를 통해 지정되므로 검색이 필요 없습니다. 파일이 더 이상 적극적으로 사용되지 않으면 프로세스가 파일을 닫고 운영 체제는 열린 파일 테이블에서 항목을 제거하여 잠금을 해제할 수 있습니다. create() 및 delete()는 열린 파일이 아닌 닫힌 파일과 함께 작동하는 시스템 호출입니다.

일부 시스템은 파일에 대한 첫 번째 참조가 있을 때 암시적으로 파일을 엽니다. 파일은 파일을 연 작업이나 프로그램이 종료될 때 자동으로 닫힙니다. 그러나 대부분의 시스템에서는 프로그래머가 open() 시스템 호출로 파일을 명시적으로 열어야만 해당 파일을 사용할 수 있습니다. open() 작업은 파일 이름을 가져와 디렉토리를 검색하고 디렉토리 항목을 열린 파일 테이블로 복사합니다. open() 호출은 또한 접근 모드 정보(생성, 읽기 전용, 읽기-쓰기, 추가 전용 등)를 수락할 수 있습니다. 이 모드는 파일의 권한과 대조됩니다. 요청된 모드가 허용되면 파일이 프로세스를 위해 열립니다. open() 시스템 호출은 일반적으로 열린 파일 테이블 항목에 대한 포인터를 반환합니다. 이 포인터는 모든 I/O 작업에서 사용되며, 추가 검색을 피하고 시스템 호출 인터페이스를 단순화합니다.

여러 프로세스가 파일을 동시에 열 수 있는 환경에서 open() 및 close() 작업의 구현은 더 복잡합니다. 이는 여러 다른 응용 프로그램이 동시에 동일한 파일을 여는 시스템에서 발생할 수 있습니다. 일반적으로 운영 체제는 두 수준의 내부 테이블을 사용합니다: 프로세스별 테이블과 시스템 전역 테이블. 프로세스별 테이블은 프로세스가 열어둔 모든 파일을 추적합니다. 이 테이블에는 파일 사용에 대한 정보가 저장됩니다. 예를 들어 각 파일에 대한 현재 파일 포인터가 여기에 있습니다. 파일에 대한 접근 권한과 회계 정보도 포함될 수 있습니다.

프로세스별 테이블의 각 항목은 시스템 전역 열린 파일 테이블을 가리킵니다. 시스템 전역 테이블에는 디스크의 파일 위치, 접근 날짜, 파일 크기와 같은 프로세스 독립적인 정보가 포함됩니다. 파일이 하나의 프로세스에 의해 열리면 시스템 전역 테이블에 파일에 대한 항목이 포함됩니다. 다른 프로세스가 open() 호출을 실행하면 프로세스의 열린 파일 테이블에 적절한 시스템 전역 테이블 항목을 가리키는 새 항목이 단순히 추가됩니다. 일반적으로 열린 파일 테이블에는 각 파일에 대해 파일을 연 프로세스 수를 나타내는 열린 수가 포함됩니다. 각 close()는 이 열린 수를 감소시키고 열린 수가 0에 도달하면 파일이 더 이상 사용되지 않으며 파일의 항목이 열린 파일 테이블에서 제거됩니다. 요약하자면, 열린 파일과 관련된 여러 정보 조각이 있습니다.

- 파일 포인터: read() 및 write() 시스템 호출의 일부로 파일 오프셋을 포함하지 않는 시스템에서는 시스템이 마지막 읽기-쓰기 위치를 현재 파일 위치 포인터로 추적해야 합니다. 이 포인터는 파일을 운영하는 각 프로세스에 고유하며 디스크의 파일 속성과 별도로 유지해야 합니다.
- 파일 열린 수: 파일이 닫힐 때 운영 체제는 열린 파일 테이블 항목을 재사용해야 하며, 그렇지 않으면 테이블의 공간이 부족할 수 있습니다. 여러 프로세스가 파일을 열 수 있으며 시스템은 마지막 파일이 닫힐 때까지 열린 파일 테이블 항목을 제거하지 않아야 합니다. 파일 열린 수는 열기 및 닫기 수를 추적하여 마지막 닫기 시 0에 도달합니다. 그러면 시스템은 항목을 제거할 수 있습니다.
- 파일 위치: 대부분의 파일 작업은 시스템이 파일 내에서 데이터를 읽거나 쓰도록 요구합니다. 파일을 찾는 데 필요한 정보(파일이 위치한 대용량 저장 장치, 네트워크를 통한 파일 서버 또는 RAM 드라이브에 위치한 경우)는 각 작업을 위해 디렉토리 구조에서 읽을 필요가 없도록 메모리에 유지됩니다.
- 접근 권한: 각 프로세스는 접근 모드로 파일을 엽니다. 이 정보는 프로세스별 테이블에 저장되어 운영 체제가 이후의 I/O 요청을 허용하거나 거부할 수 있습니다.

일부 운영 체제는 열린 파일(또는 파일의 섹션)을 잠그는 기능을 제공합니다. 파일 잠금은 하나의 프로세스가 파일을 잠그고 다른 프로세스가 접근하지 못하도록 합니다. 파일 잠금은 여러 프로세스가 공유하는 파일에 유용합니다. 예를 들어 시스템 로그 파일은 시스템의 여러 프로세스가 접근하고 수정할 수 있습니다.

파일 잠금은 7.1.2절에서 다룬 읽기-쓰기 잠금과 유사한 기능을 제공합니다. 공유 잠금은 여러 프로세스가 동시에 잠금을 획득할 수 있다는 점에서 읽기 잠금과 유사합니다. 독점 잠금은 작성 잠금과 유사하게 동작하며 한 번에 하나의 프로세스만 이러한 잠금을 획득할 수 있습니다. 모든 운영 체제가 두 가지 유형의 잠금을 제공하는 것은 아닙니다. 일부 시스템은 독점 파일 잠금만 제공합니다.

또한, 운영 체제는 강제적 또는 권고적 파일 잠금 메커니즘을 제공합니다. 강제 잠금을 사용하면 프로세스가 독점 잠금을 획득하면 운영 체제가 다른 프로세스가 잠긴 파일에 접근하지 못하도록 합니다. 예를 들어, 프로세스가 파일 system.log에 대한 독점 잠금을 획득했다고 가정합니다. 다른 프로세스(예: 텍스트 편집기)에서 system.log를 열려고 시도하면 운영 체제는 독점 잠금이 해제될 때까지 접근을 차단합니다. 반대로, 잠금이 권고적인 경우 운영 체제는 텍스트 편집기가 system.log에 접근하는 것을 막지 않습니다. 대신 텍스트 편집기는 파일에 접근하기 전에 수동으로 잠금을 획득하도록 작성되어야 합니다. 즉, 잠금 체계가 강제적이면 운영 체제가 잠금 무결성을 보장합니다. 권고적 잠금의 경우, 소프트웨어 개발자가 적절하게 잠금을 획득하고 해제하도록 보장해야 합니다. 일반적으로 Windows 운영 체제는 강제 잠금을 사용하고 UNIX 시스템은 권고 잠금을 사용합니다.

파일 잠금을 사용할 때는 일반적인 프로세스 동기화와 같은 주의가 필요합니다. 예를 들어, 강제 잠금을 사용하는 시스템에서 개발하는 프로그래머는 파일에 접근하는 동안에만 독점 파일 잠금을 유지해야 합니다. 그렇지 않으면 다른 프로세스가 파일에 접근하지 못하게 됩니다. 또한 파일 잠금을 획득하려는 두 개 이상의 프로세스가 교착 상태에 빠지지 않도록 조치가 필요합니다.

### 13.1.3 파일 유형

파일 시스템, 더 나아가 전체 운영 체제를 설계할 때, 운영 체제가 파일 유형을 인식하고 지원해야 할지를 항상 고려합니다. 운영 체제가 파일 유형을 인식하면 해당 파일을 합리적인 방식으로 처리할 수 있습니다. 예를 들어, 사용자가 프로그램의 바이너리 오브젝트 형식을 출력하려고 시도할 때 흔히 실수가 발생합니다. 이 시도는 일반적으로 엉뚱한 결과를 낳지만, 운영 체제가 해당 파일이 바이너리 오브젝트 프로그램임을 알고 있다면 성공할 수 있습니다.

파일 유형을 구현하는 일반적인 기술은 파일 이름의 일부로 유형을 포함시키는 것입니다. 이름을 두 부분으로 나누어, 이름과 확장자로 구분하며, 보통 점으로 구분합니다(그림 13.3). 이렇게 하면 사용자와 운영 체제는 이름만 보고도 파일 유형을 알 수 있습니다. 대부분의 운영 체제는 사용자가 파일 이름을 문자 시퀀스로 지정하고 점으로 구분한 후 추가 문자로 구성된 확장자로 끝내도록 허용합니다. 예를 들어, resume.docx, server.c, ReaderThread.cpp 등이 있습니다.

시스템은 확장자를 사용하여 파일 유형과 해당 파일에서 수행할 수 있는 작업 유형을 나타냅니다. 예를 들어, .com, .exe, 또는 .sh 확장자를 가진 파일만 실행할 수 있습니다. .com 및 .exe 파일은 두 가지 형태의 바이너리 실행 파일인 반면, .sh 파일은 ASCII 형식으로 운영 체제에 명령을 전달하는 쉘 스크립트입니다. 애플리케이션 프로그램도 관심 있는 파일 유형을 나타내기 위해 확장자를 사용합니다. 예를 들어, Java 컴파일러는 소스 파일이 .java 확장자를 가지길 기대하며, Microsoft Word 워드 프로세서는 파일이 .doc 또는 .docx 확장자로 끝나기를 기대합니다. 이러한 확장자는 항상 필요한 것은 아니므로, 사용자는 파일 이름을 확장자 없이 지정할 수 있으며(타이핑을 줄이기 위해), 애플리케이션은 주어진 이름과 예상되는 확장자를 가진 파일을 찾습니다. 이러한 확장자가 운영 체제에 의해 지원되지 않기 때문에, 해당 확장자는 해당 애플리케이션에 대한 "힌트"로 간주될 수 있습니다.

macOS 운영 체제를 고려해보세요. 이 시스템에서는 각 파일이 .app(애플리케이션)과 같은 유형을 가지며, 각 파일에는 해당 파일을 만든 프로그램의 이름을 포함하는 생성자 속성이 있습니다. 이 속성은 create() 호출 동안 운영 체제에 의해 설정되므로, 시스템에서 사용이 강제되고 지원됩니다. 예를 들어, 워드 프로세서가 생성한 파일에는 워드 프로세서의 이름이 생성자로 설정됩니다. 사용자가 파일을 열 때, 해당 파일을 나타내는 아이콘을 더블 클릭하면 워드 프로세서가 자동으로 실행되고 파일이 로드되어 편집할 준비가 됩니다.

UNIX 시스템은 일부 바이너리 파일의 시작 부분에 저장된 매직 넘버를 사용하여 파일의 데이터 유형을 나타냅니다(예: 이미지 파일의 형식). 마찬가지로, 텍스트 파일의 시작 부분에 텍스트 매직 넘버를 사용하여 파일 유형(스크립트가 작성된 쉘 언어)을 나타냅니다. 모든 파일에 매직 넘버가 있는 것은 아니므로 시스템 기능은 이 정보에만 의존할 수 없습니다. UNIX는 생성 프로그램의 이름도 기록하지 않습니다. UNIX는 파일 이름 확장자 힌트를 허용하지만, 이러한 확장자는 운영 체제에 의해 강제되지도 않고 의존되지도 않습니다. 주로 사용자가 파일의 내용을 판단하는 데 도움이 되도록 합니다. 확장자는 애플리케이션이 사용할 수도 있고 무시할 수도 있으며, 이는 애플리케이션 프로그래머에게 달려 있습니다.

### 13.1.4 파일 구조

파일 유형은 파일의 내부 구조를 나타내는 데도 사용될 수 있습니다. 소스 및 오브젝트 파일은 이를 읽는 프로그램의 기대에 맞는 구조를 가집니다. 더 나아가, 특정 파일은 운영 체제에서 이해하는 필수 구조를 가져야 합니다. 예를 들어, 운영 체제는 실행 파일이 메모리 어디에 로드할지와 첫 번째 명령의 위치를 결정할 수 있도록 특정 구조를 가져야 합니다. 일부 운영 체제는 이러한 아이디어를 확장하여 시스템에서 지원하는 파일 구조 집합과 해당 구조로 파일을 조작하기 위한 특수 작업 집합을 제공합니다.

이 점은 운영 체제가 여러 파일 구조를 지원하는 것의 단점 중 하나로 이어집니다: 운영 체제가 크고 복잡해진다는 것입니다. 운영 체제가 다섯 가지 다른 파일 구조를 정의한다면, 이러한 파일 구조를 지원하는 코드를 포함해야 합니다. 또한, 모든 파일을 운영 체제가 지원하는 파일 유형 중 하나로 정의해야 할 수도 있습니다. 새로운 애플리케이션이 운영 체제가 지원하지 않는 방식으로 정보를 구조화해야 하는 경우, 심각한 문제가 발생할 수 있습니다.

예를 들어, 시스템이 텍스트 파일(캐리지 리턴과 라인 피드로 구분된 ASCII 문자로 구성)과 실행 가능한 바이너리 파일의 두 가지 유형을 지원한다고 가정해 봅시다. 이제 우리가 암호화된 파일을 정의하여 무단으로 읽히는 것을 방지하고자 할 때, 두 파일 유형 모두 적절하지 않을 수 있습니다. 암호화된 파일은 ASCII 텍스트 라인이 아니며, (겉보기에는) 무작위 비트입니다. 바이너리 파일처럼 보이지만 실행 가능하지는 않습니다. 결과적으로, 우리는 운영 체제의 파일 유형 메커니즘을 우회하거나 오용해야 하거나 암호화 방식을 포기해야 할 수 있습니다.

일부 운영 체제는 최소한의 파일 구조만 부과(및 지원)합니다. 이 접근 방식은 UNIX, Windows 등에서 채택되었습니다. UNIX는 각 파일을 8비트 바이트의 시퀀스로 간주하며, 운영 체제에 의해 이러한 비트의 해석은 이루어지지 않습니다. 이 방식은 최대의 유연성을 제공하지만, 지원은 거의 없습니다. 각 애플리케이션 프로그램은 입력 파일을 적절한 구조로 해석하는 자체 코드를 포함해야 합니다. 그러나 모든 운영 체제는 실행 파일 구조를 최소한 하나는 지원해야 하므로 시스템이 프로그램을 로드하고 실행할 수 있습니다.

### 13.1.5 내부 파일 구조

내부적으로 파일 내의 오프셋을 찾는 것은 운영 체제에 복잡할 수 있습니다. 디스크 시스템은 일반적으로 섹터 크기에 의해 결정되는 명확한 블록 크기를 가집니다. 모든 디스크 I/O는 한 블록(물리적 레코드) 단위로 수행되며, 모든 블록은 동일한 크기입니다. 물리적 레코드 크기가 원하는 논리적 레코드 길이와 정확히 일치할 가능성은 낮습니다. 논리적 레코드는 길이가 다를 수도 있습니다. 여러 논리적 레코드를 물리적 블록에 패킹하는 것이 이 문제에 대한 일반적인 해결책입니다.

예를 들어, UNIX 운영 체제는 모든 파일을 단순히 바이트 스트림으로 정의합니다. 각 바이트는 파일의 시작(또는 끝)으로부터의 오프셋에 의해 개별적으로 주소 지정됩니다. 이 경우 논리적 레코드 크기는 1바이트입니다. 파일 시스템은 자동으로 바이트를 물리적 디스크 블록(예: 블록당 512바이트)으로 패킹하고 풀어냅니다.

논리적 레코드 크기, 물리적 블록 크기 및 패킹 기술은 각 물리적 블록에 몇 개의 논리적 레코드가 포함되는지를 결정합니다. 패킹은 사용자의 애플리케이션 프로그램 또는 운영 체제에 의해 수행될 수 있습니다. 어느 경우든 파일은 블록의 시퀀스로 간주될 수 있습니다. 모든 기본 I/O 기능은 블록 단위로 작동합니다. 논리적 레코드를 물리적 블록으로 변환하는 것은 비교적 간단한 소프트웨어 문제입니다.

디스크 공간은 항상 블록 단위로 할당되기 때문에, 각 파일의 마지막 블록의 일부는 일반적으로 낭비됩니다. 예를 들어, 각 블록이 512바이트라면, 1,949바이트의 파일은 네 블록(2,048바이트)로 할당되며, 마지막 99바이트는 낭비됩니다. 모든 것을 바이트 단위 대신 블록 단위로 유지하기 위해 발생하는 낭비는 내부 단편화입니다. 모든 파일 시스템은 내부 단편화 문제를 겪으며, 블록 크기가 클수록 내부 단편화도 커집니다.

### 13.3 디렉터리 구조

디렉터리는 파일 이름을 파일 제어 블록으로 변환하는 심볼 테이블로 볼 수 있습니다. 이러한 관점에서 디렉터리는 여러 가지 방식으로 조직될 수 있습니다. 디렉터리 조직은 항목을 삽입하고 삭제하며 특정 이름의 항목을 검색하고 디렉터리의 모든 항목을 나열할 수 있도록 해야 합니다. 이 절에서는 디렉터리 시스템의 논리적 구조를 정의하는 여러 방식을 살펴봅니다.

특정 디렉터리 구조를 고려할 때, 디렉터리에서 수행해야 할 작업을 염두에 두어야 합니다:
- **파일 검색**: 특정 파일의 항목을 찾기 위해 디렉터리 구조를 검색할 수 있어야 합니다. 파일에는 상징적 이름이 있으며, 유사한 이름은 파일 간의 관계를 나타낼 수 있으므로 특정 패턴과 일치하는 모든 파일을 찾을 수 있어야 할 수 있습니다.
- **파일 생성**: 새 파일을 생성하고 디렉터리에 추가해야 합니다.
- **파일 삭제**: 파일이 더 이상 필요 없을 때 디렉터리에서 제거할 수 있어야 합니다. 삭제는 디렉터리 구조에 구멍을 남기며 파일 시스템은 디렉터리 구조를 조각 모음(defragment)하는 방법을 가질 수 있습니다.
- **디렉터리 나열**: 디렉터리 내 파일과 각 파일의 디렉터리 항목 내용을 나열할 수 있어야 합니다.
- **파일 이름 변경**: 파일의 이름은 사용자에게 내용을 나타내므로 파일의 내용이나 사용이 변경될 때 이름을 변경할 수 있어야 합니다. 파일 이름을 변경하면 디렉터리 구조 내에서 파일의 위치도 변경할 수 있습니다.
- **파일 시스템 탐색**: 디렉터리 구조 내 모든 디렉터리와 파일에 접근하고자 할 수 있습니다. 신뢰성을 위해 전체 파일 시스템의 내용과 구조를 정기적으로 저장하는 것이 좋습니다. 종종 모든 파일을 자기 테이프, 다른 2차 저장소 또는 네트워크를 통해 다른 시스템이나 클라우드로 복사하여 이를 수행합니다. 이 기술은 시스템 고장 시 백업 복사본을 제공합니다. 또한 파일이 더 이상 사용되지 않는 경우 해당 파일을 백업 대상으로 복사하고 디스크 공간을 다른 파일이 재사용할 수 있도록 해제할 수 있습니다.

다음 절에서는 디렉터리의 논리적 구조를 정의하는 가장 일반적인 방식을 설명합니다.

### 13.3.1 단일 레벨 디렉터리

가장 간단한 디렉터리 구조는 단일 레벨 디렉터리입니다. 모든 파일이 동일한 디렉터리에 포함되며, 이는 지원하고 이해하기 쉽습니다 (그림 13.7).

그러나 파일 수가 증가하거나 시스템에 여러 사용자가 있는 경우 단일 레벨 디렉터리는 상당한 제한이 있습니다. 모든 파일이 동일한 디렉터리에 있으므로 고유한 이름을 가져야 합니다. 두 사용자가 데이터 파일을 test.txt로 부르면 고유 이름 규칙이 위반됩니다. 예를 들어, 한 프로그래밍 수업에서 23명의 학생이 두 번째 과제를 prog2.c로 부르고, 다른 11명은 assign2.c로 불렀습니다. 다행히 대부분의 파일 시스템은 최대 255자의 파일 이름을 지원하므로 고유한 파일 이름을 선택하는 것은 비교적 쉽습니다.

단일 레벨 디렉터리의 단일 사용자도 파일 수가 증가하면 모든 파일 이름을 기억하기 어려울 수 있습니다. 한 컴퓨터 시스템에 수백 개의 파일을 가지고 있고 다른 시스템에도 동일한 수의 파일을 가지고 있는 사용자는 드물지 않습니다. 이렇게 많은 파일을 추적하는 것은 벅찬 작업입니다.

### 13.3.2 이중 레벨 디렉터리

단일 레벨 디렉터리는 종종 다른 사용자 간 파일 이름 혼동을 초래합니다. 표준 솔루션은 각 사용자에게 별도의 디렉터리를 만드는 것입니다.

이중 레벨 디렉터리 구조에서 각 사용자는 자신의 사용자 파일 디렉터리(UFD)를 가집니다. UFD는 유사한 구조를 가지지만 각 UFD는 단일 사용자의 파일만 나열합니다. 사용자 작업이 시작되거나 사용자가 로그인하면 시스템의 마스터 파일 디렉터리(MFD)가 검색됩니다. MFD는 사용자 이름 또는 계정 번호로 색인화되어 있으며, 각 항목은 해당 사용자의 UFD를 가리킵니다(그림 13.8).

사용자가 특정 파일을 참조할 때 자신의 UFD만 검색합니다. 따라서 모든 UFD 내의 파일 이름이 고유한 한, 서로 다른 사용자는 동일한 이름의 파일을 가질 수 있습니다. 사용자를 위한 파일을 생성하려면 운영 체제는 해당 사용자의 UFD만 검색하여 동일한 이름의 파일이 있는지 확인합니다. 파일을 삭제하려면 운영 체제는 로컬 UFD로 검색을 제한하여 동일한 이름의 다른 사용자의 파일을 실수로 삭제할 수 없습니다.

사용자 디렉터리는 필요에 따라 생성 및 삭제되어야 합니다. 적절한 사용자 이름 및 계정 정보로 특별 시스템 프로그램이 실행됩니다. 프로그램은 새 UFD를 생성하고 MFD에 대한 항목을 추가합니다. 이 프로그램의 실행은 시스템 관리자에게만 허용될 수 있습니다. 사용자 디렉터리의 디스크 공간 할당은 파일 자체에 대해 14장에서 논의된 기술로 처리할 수 있습니다.

이중 레벨 디렉터리 구조는 이름 충돌 문제를 해결하지만 여전히 단점이 있습니다. 이 구조는 효과적으로 한 사용자를 다른 사용자로부터 격리합니다. 사용자가 완전히 독립적일 때는 장점이지만, 사용자가 특정 작업에서 협력하고 서로의 파일에 접근하고자 할 때는 단점입니다. 일부 시스템은 로컬 사용자 파일에 대한 다른 사용자의 접근을 허용하지 않습니다.

접근이 허용되려면 한 사용자가 다른 사용자의 디렉터리에서 파일 이름을 지정할 수 있어야 합니다. 이중 레벨 디렉터리에서 특정 파일을 고유하게 이름 지정하려면 사용자 이름과 파일 이름을 모두 제공해야 합니다. 이중 레벨 디렉터리는 높이 2의 트리 또는 역트리로 생각할 수 있습니다. 트리의 루트는 MFD입니다. MFD의 직계 자손은 UFD입니다. UFD의 자손은 파일 자체입니다. 파일은 트리의 잎사귀입니다. 사용자 이름과 파일 이름을 지정하면 루트(MFD)에서 잎사귀(지정된 파일)까지의 경로가 정의됩니다. 따라서 사용자 이름과 파일 이름은 경로 이름을 정의합니다. 시스템의 모든 파일은 경로 이름을 가지고 있습니다. 파일을 고유하게 이름 지정하려면 사용자가 원하는 파일의 경로 이름을 알아야 합니다.

예를 들어, 사용자인 A가 자신의 테스트 파일 test.txt에 접근하려면 단순히 test.txt라고 참조할 수 있습니다. 그러나 사용자 B의 test.txt 파일(userb 디렉터리 항목 이름이 있는) 접근하려면 /userb/test.txt라고 참조해야 할 수 있습니다. 각 시스템에는 사용자의 디렉터리 이외의 디렉터리에서 파일을 이름 지정하는 구문이 있습니다.

파일의 볼륨을 지정하려면 추가 구문이 필요합니다. 예를 들어, Windows에서는 볼륨이 문자 뒤에 콜론이 붙습니다. 따라서 파일 지정은 C:\userb\test일 수 있습니다. 일부 시스템은 더 나아가 볼륨, 디렉터리 이름, 파일 이름 부분을 구분합니다. 예를 들어, OpenVMS에서는 파일 login.com을 다음과 같이 지정할 수 있습니다: u:[sst.crissmeyer]login.com;1, 여기서 u는 볼륨 이름, sst는 디렉터리 이름, crissmeyer는 하위 디렉터리 이름, 1은 버전 번호입니다. 다른 시스템, 예를 들어 UNIX 및 Linux에서는 볼륨 이름을 디렉터리 이름의 일부로 간주합니다. 첫 번째 이름이 볼륨의 이름이고 나머지는 디렉터리 및 파일입니다. 예를 들어, /u/pgalvin/test는 볼륨 u, 디렉터리 pgalvin, 파일 test를 지정할 수 있습니다.

이 상황의 특별한 사례는 시스템 파일입니다. 시스템의 일부로 제공되는 프로그램(로더, 어셈블러, 컴파일러, 유틸리티 루틴, 라이브러리 등)은 일반적으로 파일로 정의됩니다. 운영 체제에 적절한 명령이 주어지면 이러한 파일이 로더에 의해 읽히고 실행됩니다. 많은 명령 인터프리터는 이러한 명령을 로드하고 실행할 파일 이름으로 간주합니다. 위에서 정의한 디렉터리 시스템에서는 현재 UFD에서 이 파일 이름을 검색합니다. 한 가지 해결책은 시스템 파일을 각 UFD에 복사하는 것입니다. 그러나 모든 시스템 파일을 복사하면 엄청난 양의 공간이 낭비됩니다. (시스템 파일에 5MB가 필요하면 12명의 사용자를 지원하려면 시스템 파일 사본에만 5 × 12 = 60MB가 필요합니다.)

표준 해결책은 검색 절차를 약

간 복잡하게 만드는 것입니다. 시스템 파일을 포함하는 특별 사용자 디렉터리가 정의됩니다(예: 사용자 0). 파일을 로드할 이름이 주어질 때마다 운영 체제는 먼저 로컬 UFD를 검색합니다. 파일이 발견되면 사용됩니다. 발견되지 않으면 시스템은 자동으로 시스템 파일을 포함하는 특별 사용자 디렉터리를 검색합니다. 파일 이름을 지정할 때 검색되는 디렉터리의 순서를 검색 경로라고 합니다. 검색 경로는 명령 이름이 주어질 때 검색할 디렉터리의 무제한 목록을 포함하도록 확장될 수 있습니다. 이 방법은 UNIX와 Windows에서 가장 많이 사용됩니다. 시스템은 각 사용자가 자신의 검색 경로를 가지도록 설계될 수도 있습니다.

### 13.3.3 트리 구조 디렉터리

이중 레벨 디렉터리를 이중 레벨 트리로 보는 방법을 알게 되면 디렉터리 구조를 임의의 높이의 트리로 확장하는 것이 자연스러운 일반화입니다(그림 13.9). 이 일반화는 사용자가 자신의 하위 디렉터리를 만들고 파일을 그에 따라 조직할 수 있게 합니다. 트리는 가장 일반적인 디렉터리 구조입니다. 트리는 루트 디렉터리를 가지며, 시스템의 모든 파일은 고유한 경로 이름을 가집니다.

디렉터리(또는 하위 디렉터리)는 파일 또는 하위 디렉터리 집합을 포함합니다. 많은 구현에서 디렉터리는 단순히 또 다른 파일이지만 특별한 방식으로 처리됩니다. 모든 디렉터리는 동일한 내부 형식을 가지고 있습니다. 각 디렉터리 항목의 한 비트는 항목을 파일(0) 또는 하위 디렉터리(1)로 정의합니다. 특별 시스템 호출은 디렉터리를 생성하고 삭제하는 데 사용됩니다. 이 경우 운영 체제(또는 파일 시스템 코드)는 디렉터리의 또 다른 파일 형식을 구현합니다.

일반 사용에서는 각 프로세스가 현재 디렉터리를 가집니다. 현재 디렉터리는 프로세스와 현재 관심 있는 대부분의 파일을 포함해야 합니다. 파일이 참조될 때 현재 디렉터리가 검색됩니다. 현재 디렉터리에 없는 파일이 필요하면 사용자는 보통 경로 이름을 지정하거나 파일을 포함하는 디렉터리로 현재 디렉터리를 변경해야 합니다. 디렉터리를 변경하려면 디렉터리 이름을 매개 변수로 받아 현재 디렉터리를 재정의하는 시스템 호출을 제공할 수 있습니다. 따라서 사용자는 원하는 때에 현재 디렉터리를 변경할 수 있습니다. 다른 시스템에서는 각 프로세스가 서로 다른 현재 디렉터리를 가질 수 있으므로 응용 프로그램(예: 셸)이 현재 디렉터리를 추적하고 작동하도록 합니다.

사용자의 로그인 셸의 초기 현재 디렉터리는 사용자 작업이 시작되거나 사용자가 로그인할 때 지정됩니다. 운영 체제는 계정 파일(또는 다른 사전 정의된 위치)을 검색하여 이 사용자의 항목을 찾습니다(계정 목적으로). 계정 파일에는 사용자의 초기 디렉터리를 가리키는 포인터가 있습니다. 이 포인터는 사용자의 초기 현재 디렉터리를 지정하는 로컬 변수로 복사됩니다. 해당 셸에서 다른 프로세스가 생성될 수 있습니다. 생성될 때의 부모의 현재 디렉터리는 보통 하위 프로세스의 현재 디렉터리입니다.

경로 이름은 절대 경로와 상대 경로의 두 가지 유형이 있습니다. UNIX와 Linux에서 절대 경로 이름은 루트(초기 “/”로 지정)에서 시작하여 지정된 파일까지 경로를 따르며, 경로의 디렉터리 이름을 제공합니다. 상대 경로 이름은 현재 디렉터리에서 경로를 정의합니다. 예를 들어, 그림 13.9의 트리 구조 파일 시스템에서 현재 디렉터리가 /spell/mail이면 상대 경로 이름 prt/first는 절대 경로 이름 /spell/mail/prt/first와 동일한 파일을 참조합니다.

사용자가 자신의 하위 디렉터리를 정의할 수 있도록 하면 파일에 구조를 부여할 수 있습니다. 이 구조는 다른 주제와 관련된 파일을 위한 별도의 디렉터리를 생성하거나 다른 형태의 정보를 저장할 수 있습니다. 예를 들어, programs 디렉터리는 소스 프로그램을 포함할 수 있고, bin 디렉터리는 모든 바이너리를 저장할 수 있습니다. (참고로, 실행 파일은 많은 시스템에서 “바이너리”로 알려져 있었으며, 이는 bin 디렉터리에 저장되었습니다.)

트리 구조 디렉터리에서 흥미로운 정책 결정은 디렉터리를 삭제하는 방법입니다. 디렉터리가 비어 있으면 이를 포함하는 디렉터리에서 항목을 단순히 삭제할 수 있습니다. 그러나 삭제할 디렉터리가 비어 있지 않고 여러 파일이나 하위 디렉터리를 포함하는 경우 두 가지 접근 방식 중 하나를 사용할 수 있습니다. 일부 시스템은 디렉터리가 비어 있지 않으면 삭제하지 않습니다. 따라서 디렉터리를 삭제하려면 사용자가 먼저 해당 디렉터리의 모든 파일을 삭제해야 합니다. 하위 디렉터리가 있으면 이 절차를 재귀적으로 적용하여 삭제할 수 있습니다. 이 접근 방식은 상당한 작업을 초래할 수 있습니다. UNIX의 rm 명령이 사용하는 대체 접근 방식은 디렉터리를 삭제할 때 해당 디렉터리의 모든 파일과 하위 디렉터리도 삭제하는 옵션을 제공하는 것입니다. 두 접근 방식 모두 구현하기 쉽습니다. 선택은 정책의 문제입니다. 후자의 정책은 더 편리하지만, 한 명령으로 전체 디렉터리 구조가 제거될 수 있어 더 위험합니다. 명령이 잘못 실행되면 많은 파일과 디렉터리를 복원해야 할 수도 있습니다(백업이 있다고 가정).

트리 구조 디렉터리 시스템에서는 사용자가 자신의 파일 외에도 다른 사용자의 파일에 접근할 수 있도록 할 수 있습니다. 예를 들어, 사용자 B는 경로 이름을 지정하여 사용자 A의 파일에 접근할 수 있습니다. 사용자 B는 절대 경로 이름이나 상대 경로 이름을 지정할 수 있습니다. 또는 사용자 B는 현재 디렉터리를 사용자 A의 디렉터리로 변경하고 파일 이름으로 파일에 접근할 수 있습니다.

### 13.3.4 비순환 그래프 디렉터리

두 프로그래머가 공동 프로젝트에서 작업하고 있다고 가정해 봅시다. 해당 프로젝트와 관련된 파일은 하위 디렉터리에 저장하여 다른 프로젝트와 두 프로그래머의 파일과 구분할 수 있습니다. 그러나 두 프로그래머가 프로젝트에 대해 동등하게 책임이 있으므로 두 사람 모두 하위 디렉터리가 자신의 디렉터리에 있어야 합니다. 이 경우 공통 하위 디렉터리는 공유되어야 합니다. 공유 디렉터리나 파일은 파일 시스템에 두 곳(또는 그 이상)에서 동시에 존재합니다.

트리 구조는 파일이나 디렉터리 공유를 금지합니다. 순환이 없는 그래프, 즉 비순환 그래프는 디렉터리가 하위 디렉터리와 파일을 공유할 수 있게 합니다(그림 13.10). 동일한 파일이나 하위 디렉터리가 두 개의 다른 디렉터리에 있을 수 있습니다. 비순환 그래프는 트리 구조 디렉터리 체계의 자연스러운 일반화입니다.

공유 파일(또는 디렉터리)은 파일의 두 개 사본과 다릅니다. 두 개 사본이 있으면 각 프로그래머는 원본이 아닌 사본을 볼 수 있지만, 한 프로그래머가 파일을 변경하면 변경 사항이 다른 사람의 사본에는 나타나지 않습니다. 공유 파일은 실제 파일이 하나만 있으므로 한 사람이 변경한 사항이 다른 사람에게 즉시 표시됩니다. 하위 디렉터리의 공유는 특히 중요합니다. 한 사람이 생성한 새 파일은 자동으로 모든 공유 하위 디렉터리에 나타납니다.

사람들이 팀으로 작업할 때 공유하려는 모든 파일을 하나의 디렉터리에 넣을 수 있습니다. 각 팀원의 홈 디렉터리는 이 공유 파일 디렉터리를 하위 디렉터리로 포함할 수 있습니다. 심지어 단일 사용자의 경우에도 사용자의 파일 조직은 일부 파일을 다른 하위 디렉터리에 배치해야 할 수 있습니다. 예를 들어, 특정 프로젝트를 위해 작성된 프로그램은 모든 프로그램 디렉터리와 해당 프로젝트 디렉터리에 있어야 합니다.

공유 파일 및 하위 디렉터리는 여러 가지 방식으로 구현할 수 있습니다. UNIX 시스템에서 예를 들어, 새로운 디렉터리 항목을 링크라고 합니다. 링크는 다른 파일이나 하위 디렉터리에 대한 포인터 역할을 합니다. 예를 들어, 링크는 절대 경로 이름이나 상대 경로 이름으로 구현될 수 있습니다. 파일 참조가 이루어질 때 디렉터리를 검색합니다. 디렉터리 항목이 링크로 표시되면 링크 정보에 실제 파일 이름이 포함됩니다. 해당 경로 이름을 사용하여 링크를 해석하고 실제 파일을 찾습니다. 링크는 디렉터리 항목의 형식(또는 유형을 지원하는 시스템에서 특수 유형을 가짐)으로 쉽게 식별할 수 있으며 간접 포인터 역할을 합니다. 운영

 체제는 시스템의 비순환 구조를 유지하기 위해 디렉터리 트리 탐색 시 이러한 링크를 무시합니다.

공유 파일을 구현하는 또 다른 일반적인 접근 방식은 모든 정보를 두 공유 디렉터리에 복제하는 것입니다. 따라서 두 항목은 동일하고 동등합니다. 이 접근 방식과 링크 생성의 차이를 고려하십시오. 링크는 원본 디렉터리 항목과 분명히 다르므로 두 개는 동등하지 않습니다. 그러나 중복 디렉터리 항목은 원본과 복사본을 구별할 수 없게 만듭니다. 중복 디렉터리 항목의 주요 문제는 파일 수정 시 일관성을 유지하는 것입니다.

비순환 그래프 디렉터리 구조는 간단한 트리 구조보다 더 유연하지만 더 복잡합니다. 몇 가지 문제를 신중하게 고려해야 합니다. 이제 파일에는 여러 개의 절대 경로 이름이 있을 수 있습니다. 결과적으로 서로 다른 파일 이름이 동일한 파일을 참조할 수 있습니다. 이 상황은 프로그래밍 언어의 별칭 문제와 유사합니다. 전체 파일 시스템을 탐색하려고 할 때, 파일을 찾고, 모든 파일의 통계를 수집하거나 모든 파일을 백업 저장소로 복사하려고 할 때 이 문제가 중요해집니다. 공유 구조를 두 번 탐색하고 싶지 않기 때문입니다.

삭제와 관련된 또 다른 문제는 공유 파일에 할당된 공간을 언제 해제하여 재사용할 수 있는지입니다. 한 사람이 파일을 삭제할 때마다 파일을 제거하는 한 가지 방법이 있지만, 이 작업은 이제 존재하지 않는 파일에 대한 포인터를 남길 수 있습니다. 더 나쁜 것은 남아 있는 파일 포인터에 실제 디스크 주소가 포함되고 해당 공간이 나중에 다른 파일에 재사용되는 경우 이러한 포인터가 다른 파일의 중간을 가리킬 수 있습니다.

공유가 기호 링크로 구현된 시스템에서는 이 상황을 처리하기가 더 쉽습니다. 링크 삭제는 원본 파일에 영향을 미치지 않으며 링크만 제거됩니다. 파일 항목 자체가 삭제되면 파일 공간이 해제되어 링크가 남습니다. 이러한 링크를 검색하여 제거할 수 있지만, 각 파일과 연결된 링크 목록을 유지하지 않으면 이 검색은 비용이 많이 듭니다. 또는 링크를 그대로 두고 사용 시도가 있을 때까지 기다릴 수 있습니다. 그 시점에서 링크 이름으로 지정된 파일이 존재하지 않는다는 것을 확인하고 링크 이름 해석에 실패할 수 있습니다. 접근은 다른 불법 파일 이름과 동일하게 처리됩니다. (이 경우, 파일 삭제 후 원래 파일에 대한 기호 링크가 사용되기 전에 동일한 이름의 다른 파일이 생성되면 어떻게 할지 신중하게 고려해야 합니다.) UNIX의 경우 파일이 삭제되면 기호 링크가 남아 있으며, 사용자가 원래 파일이 없어졌거나 대체되었음을 인식해야 합니다. Microsoft Windows도 동일한 접근 방식을 사용합니다.

삭제에 대한 또 다른 접근 방식은 모든 참조가 삭제될 때까지 파일을 보존하는 것입니다. 이 접근 방식을 구현하려면 마지막 참조가 삭제된 시점을 결정하는 메커니즘이 있어야 합니다. 파일에 대한 모든 참조(디렉터리 항목 또는 기호 링크)의 목록을 유지할 수 있습니다. 링크 또는 디렉터리 항목이 설정될 때 파일 참조 목록에 새 항목이 추가됩니다. 링크 또는 디렉터리 항목이 삭제될 때 목록에서 해당 항목을 제거합니다. 파일 참조 목록이 비어 있을 때 파일이 삭제됩니다.

이 접근 방식의 문제는 파일 참조 목록의 가변적이고 잠재적으로 큰 크기입니다. 그러나 전체 목록을 유지할 필요는 없습니다. 참조 수만 유지하면 됩니다. 새 링크나 디렉터리 항목이 추가되면 참조 수가 증가합니다. 링크나 항목을 삭제하면 참조 수가 감소합니다. 참조 수가 0이 되면 파일을 삭제할 수 있습니다. 더 이상 파일에 대한 참조가 없습니다. UNIX 운영 체제는 기호 링크(또는 하드 링크)가 아닌 링크에 대해 이 접근 방식을 사용하며, 파일 정보 블록(또는 inode)에 참조 수를 유지합니다. 디렉터리에 대한 다중 참조를 효과적으로 금지함으로써 비순환 그래프 구조를 유지합니다.

논의된 문제를 피하기 위해 일부 시스템은 공유 디렉터리나 링크를 허용하지 않습니다.

### 13.3.5 일반 그래프 디렉터리

비순환 그래프 구조를 사용할 때 심각한 문제는 순환이 없도록 보장하는 것입니다. 이중 레벨 디렉터리로 시작하여 사용자가 하위 디렉터리를 생성할 수 있도록 하면 트리 구조 디렉터리가 생성됩니다. 새로운 파일과 하위 디렉터리를 기존 트리 구조 디렉터리에 추가하면 트리 구조 특성이 유지된다는 것을 쉽게 알 수 있습니다. 그러나 링크를 추가하면 트리 구조가 파괴되어 단순 그래프 구조가 됩니다(그림 13.11).

비순환 그래프의 주요 장점은 그래프를 탐색하고 파일에 더 이상 참조가 없음을 결정하는 알고리즘의 상대적인 단순성입니다. 주로 성능상의 이유로 비순환 그래프의 공유 섹션을 두 번 탐색하지 않기를 원합니다. 특정 파일을 찾기 위해 주요 공유 하위 디렉터리를 한 번 검색한 후 찾지 못하면 다시 검색을 피하고 싶습니다. 두 번째 검색은 시간 낭비가 됩니다.

디렉터리에 순환이 있는 경우 성능뿐만 아니라 정확성 때문에 구성 요소를 두 번 검색하지 않기를 원합니다. 잘못 설계된 알고리즘은 순환을 계속 검색하고 절대 종료되지 않는 무한 루프를 초래할 수 있습니다. 한 가지 해결책은 검색 중에 접근할 디렉터리 수를 임의로 제한하는 것입니다.

파일을 삭제할 수 있는 시점을 결정하려고 할 때도 유사한 문제가 발생합니다. 비순환 그래프 디렉터리 구조에서는 참조 수가 0이면 파일이나 디렉터리에 대한 참조가 더 이상 없음을 의미하므로 파일을 삭제할 수 있습니다. 그러나 순환이 있는 경우 참조 수가 0이 아니어도 디렉터리나 파일을 참조할 수 없는 상황이 발생할 수 있습니다. 이 이상 현상은 디렉터리 구조에서 자기 참조(또는 순환)의 가능성 때문에 발생합니다. 이 경우 마지막 참조가 삭제되고 디스크 공간이 재할당될 수 있는 시점을 결정하기 위해 가비지 컬렉션(Garbage Collection) 방법을 사용해야 합니다. 가비지 컬렉션은 전체 파일 시스템을 탐색하여 접근 가능한 모든 항목에 표시를 합니다. 그런 다음 표시되지 않은 모든 항목을 수집하여 자유 공간 목록에 추가합니다. (유사한 표시 절차를 사용하여 파일 시스템에서 모든 항목을 한 번만 탐색하거나 검색할 수 있도록 할 수 있습니다.) 그러나 디스크 기반 파일 시스템의 가비지 컬렉션은 시간이 많이 걸리므로 거의 시도하지 않습니다.

가비지 컬렉션은 그래프에 순환이 있을 가능성 때문에 필요합니다. 따라서 비순환 그래프 구조가 작업하기 훨씬 쉽습니다. 어려움은 구조에 새 링크를 추가할 때 순환을 피하는 것입니다. 새로운 링크가 순환을 완성할 시점을 어떻게 알 수 있습니까? 그래프에서 순환을 감지하는 알고리즘이 있지만, 특히 그래프가 디스크 저장소에 있을 때 계산 비용이 많이 듭니다. 디렉터리와 링크의 특별한 경우에 더 간단한 알고리즘은 디렉터리 탐색 시 링크를 우회하는 것입니다. 순환이 방지되며 추가 오버헤드가 발생하지 않습니다.

### 13.4 보호

컴퓨터 시스템에 정보가 저장될 때, 우리는 이를 물리적 손상(신뢰성 문제)과 부적절한 접근(보호 문제)으로부터 안전하게 보호하고자 합니다.

신뢰성은 일반적으로 파일의 복제본을 통해 제공됩니다. 많은 컴퓨터는 시스템 프로그램을 통해 자동으로(또는 컴퓨터 운영자의 개입을 통해) 정기적으로 디스크 파일을 테이프에 복사하여(하루, 주, 월 단위) 파일 시스템이 실수로 파괴될 경우를 대비한 복사본을 유지합니다. 파일 시스템은 읽기 또는 쓰기 오류와 같은 하드웨어 문제, 전력 서지 또는 전력 장애, 헤드 충돌, 먼지, 극한 온도, 그리고 파괴 행위로 인해 손상될 수 있습니다. 파일은 실수로 삭제될 수 있습니다. 파일 시스템 소프트웨어의 버그로 인해 파일 내용이 손실될 수도 있습니다. 신뢰성에 대한 자세한 내용은 11장에서 다루었습니다.

보호는 여러 방법으로 제공될 수 있습니다. 현대 운영 체제를 실행하는 노트북 시스템의 경우, 사용자 이름과 비밀번호 인증을 요구하여 접근을 제한하고, 보조 저장 장치를 암호화하여 노트북을 열고 드라이브를 제거하는 경우에도 데이터 접근을 어렵게 하며, 네트워크 접근을 방화벽으로 차단하여 사용 중일 때 네트워크 연결을 통한 침입을 어렵게 할 수 있습니다. 다중 사용자 시스템에서는 유효한 접근조차도 더 발전된 메커니즘이 필요하여 데이터에 대한 유효한 접근만 허용합니다.

#### 13.4.1 접근 유형

파일을 보호해야 할 필요성은 파일에 접근할 수 있는 능력에서 직접적으로 발생합니다. 다른 사용자의 파일에 접근할 수 없도록 허용하지 않는 시스템은 보호가 필요하지 않습니다. 따라서 접근을 금지함으로써 완전한 보호를 제공할 수 있습니다. 반대로, 아무런 보호 없이 자유로운 접근을 허용할 수도 있습니다. 두 접근 방식 모두 일반적인 사용에는 너무 극단적입니다. 필요한 것은 통제된 접근입니다.

보호 메커니즘은 수행할 수 있는 파일 접근 유형을 제한하여 통제된 접근을 제공합니다. 접근은 요청된 접근 유형 중 하나에 따라 허용되거나 거부됩니다. 여러 다른 유형의 작업이 통제될 수 있습니다:

- 읽기: 파일을 읽음.
- 쓰기: 파일을 쓰거나 다시 씀.
- 실행: 파일을 메모리에 로드하고 실행함.
- 덧붙이기: 파일 끝에 새로운 정보를 씀.
- 삭제: 파일을 삭제하고 공간을 재사용 가능하도록 함.
- 목록: 파일의 이름과 속성을 나열함.
- 속성 변경: 파일의 속성을 변경함.

다른 작업, 예를 들어 파일 이름 변경, 복사, 편집도 통제될 수 있습니다. 그러나 많은 시스템에서는 이러한 고급 기능이 낮은 수준의 시스템 호출을 수행하는 시스템 프로그램에 의해 구현될 수 있습니다. 보호는 오직 낮은 수준에서만 제공됩니다. 예를 들어, 파일 복사는 단순히 일련의 읽기 요청으로 구현될 수 있습니다. 이 경우, 읽기 접근 권한이 있는 사용자는 파일을 복사하고, 인쇄할 수 있습니다.

많은 보호 메커니즘이 제안되었습니다. 각각은 장단점이 있으며, 의도된 응용에 적합해야 합니다. 예를 들어, 소수의 연구 그룹 구성원만 사용하는 소형 컴퓨터 시스템은 연구, 재무, 인사 운영에 사용되는 대형 기업 컴퓨터와 동일한 유형의 보호가 필요하지 않을 수 있습니다. 다음 섹션에서는 보호에 대한 몇 가지 접근 방식을 논의하고, 17장에서 더 완전한 내용을 제공합니다.

#### 13.4.2 접근 제어

보호 문제에 대한 가장 일반적인 접근 방식은 사용자의 신원에 따라 접근을 의존하게 만드는 것입니다. 다른 사용자는 파일이나 디렉터리에 대해 서로 다른 유형의 접근이 필요할 수 있습니다. 신원에 의존하는 접근을 구현하는 가장 일반적인 방법은 각 파일과 디렉터리에 접근 제어 목록(ACL)을 연결하여 사용자 이름과 각 사용자가 허용하는 접근 유형을 지정하는 것입니다. 사용자가 특정 파일에 접근을 요청하면 운영 체제는 해당 파일과 관련된 접근 목록을 확인합니다. 해당 사용자가 요청한 접근 유형에 나열되어 있으면 접근이 허용됩니다. 그렇지 않으면 보호 위반이 발생하고 사용자의 작업은 파일 접근이 거부됩니다.

이 접근 방식의 장점은 복잡한 접근 방법을 가능하게 한다는 것입니다. 접근 목록의 주요 문제는 그 길이입니다. 모든 사람이 파일을 읽을 수 있도록 하려면 읽기 접근 권한이 있는 모든 사용자를 나열해야 합니다. 이 기술에는 두 가지 바람직하지 않은 결과가 있습니다:

- 이러한 목록을 작성하는 것은 지루하고 보람 없는 작업일 수 있으며, 특히 시스템에 있는 사용자의 목록을 사전에 알지 못하는 경우 더욱 그렇습니다.
- 고정 크기의 디렉터리 항목이 이제는 가변 크기로 되어 공간 관리가 더 복잡해집니다.

이 문제는 접근 제어 목록의 길이를 축약함으로써 해결할 수 있습니다.

접근 제어 목록의 길이를 축약하기 위해 많은 시스템에서는 각 파일과 관련된 세 가지 사용자 분류를 인식합니다:

- 소유자: 파일을 생성한 사용자가 소유자입니다.
- 그룹: 파일을 공유하며 유사한 접근이 필요한 사용자 그룹입니다.
- 기타: 시스템의 모든 다른 사용자입니다.

가장 일반적인 최근 접근 방식은 접근 제어 목록을 보다 일반적이고 구현하기 쉬운 소유자, 그룹, 전체 접근 제어 체계와 결합하는 것입니다. 예를 들어, Solaris는 기본적으로 세 가지 접근 범주를 사용하지만, 더 세밀한 접근 제어가 필요한 경우 특정 파일과 디렉터리에 접근 제어 목록을 추가할 수 있습니다.

예를 들어, 새 책을 쓰고 있는 사람인 Sara를 생각해 봅시다. 그녀는 프로젝트를 돕기 위해 세 명의 대학원생(Jim, Dawn, Jill)을 고용했습니다. 책의 텍스트는 book.tex라는 파일에 저장됩니다. 이 파일과 관련된 보호는 다음과 같습니다:

- Sara는 파일에 대한 모든 작업을 수행할 수 있어야 합니다.
- Jim, Dawn, Jill은 파일을 읽고 쓸 수만 있어야 하며, 파일을 삭제할 수 없어야 합니다.
- 다른 모든 사용자는 파일을 읽을 수만 있어야 합니다. (Sara는 가능한 많은 사람이 텍스트를 읽고 피드백을 받을 수 있기를 원합니다.)

이러한 보호를 달성하기 위해, 우리는 Jim, Dawn, Jill이 포함된 새로운 그룹, 예를 들어 text라는 그룹을 생성해야 합니다. 그런 다음 그룹 이름 text를 book.tex 파일과 연결하고, 접근 권한을 우리가 설명한 정책에 따라 설정해야 합니다.

이제 Sara가 방문자에게 1장을 임시로 접근할 수 있도록 하고 싶다고 가정해 봅시다. 방문자를 text 그룹에 추가할 수는 없습니다. 왜냐하면 그렇게 하면 그에게 모든 장에 접근할 수 있는 권한을 주기 때문입니다. 파일은 하나의 그룹에만 속할 수 있기 때문에, Sara는 1장에 다른 그룹을 추가할 수 없습니다. 그러나 접근 제어 목록 기능을 추가하면, 방문자를 1장의 접근 제어 목록에 추가할 수 있습니다.

이 체계가 제대로 작동하려면 권한과 접근 목록을 엄격히 통제해야 합니다. 이 통제는 여러 방법으로 달성할 수 있습니다. 예를 들어, UNIX 시스템에서는 그룹을 생성하고 수정할 수 있는 권한이 시설 관리자(또는 슈퍼유저)에게만 주어집니다. 따라서 통제는 인간의 상호작용을 통해 이루어집니다. 접근 목록은 17.6.2절에서 더 자세히 논의됩니다.

보다 제한된 보호 분류에서는 보호를 정의하기 위해 세 개의 필드만 필요합니다. 일반적으로 각 필드는 비트 모음이며, 각 비트는 관련 접근을 허용하거나 금지합니다. 예를 들어, UNIX 시스템에서는 각 필드에 세 비트—rwx가 정의되어 있으며, r은 읽기 접근을, w는 쓰기 접근을, x는 실행을 제어합니다. 파일 소유자, 파일의 그룹 및 다른 모든 사용자를 위한 별도의 필드가 유지됩니다. 이 체계에서는 파일 당 아홉 비트가 보호 정보를 기록하는 데 필요합니다. 따라서 우리의 예에서는 파일 book.tex의 보호 필드는 다음과 같습니다: 소유자 Sara의 경우 모든 비트가 설정되며, 그룹 text의 경우 r과 w 비트가 설정되며, 전체 사용자의 경우 r 비트만 설정됩니다.

접근 방식 결합의 어려움 중 하나는 사용자 인터페이스에 있습니다. 사용자는 파일에 선택적 ACL 권한이 설정되어 있는지 알 수 있어야 합니다. Solaris 예에서, 정규 권한에 “+”가 추가됩니다. 예를 들어:

    19 -rw-r--r--+ 1 jim staff 130 May 25 22:13 file1

별도의 명령어 setfacl과 getfacl이 ACL을 관리하는 데 사용됩니다.

Windows 사용자는 일반적으로 GUI를 통해 접근 제어 목록을 관리합니다. 그림 13.12는 Windows 7 NTFS 파일 시스템에서 파일 권한 창을 보여줍니다. 이 예에서, 사용자 "guest"는 파일 ListPanel.java에 대한 접근이 명시적으로 거부됩니다.

또 다른 어려움은 권한과 ACL이 충돌할 때 우선순위를 지정하는 것입니다. 예를 들어, Walter가 읽기 권한이 있는 파일의 그룹에 속해 있지만, 파일에 Walter에게 읽기 및 쓰기 권한을 부여하는 ACL이 있는 경우, Walter의 쓰기 권한은 허용되어야 할까요? Solaris 및 다른 운영 체제에서는 ACL에 우선순위를 부여합니다(더 세밀하며 기본적으로 할당되지 않기 때문입니다). 이는 구체성이 우선해야 한다는 일반 규칙을 따릅니다.
#### 13.4.3 기타 보호 접근 방식

보호 문제에 대한 또 다른 접근 방식은 각 파일에 비밀번호를 연결하는 것입니다. 컴퓨터 시스템에 대한 접근이 종종 비밀번호로 통제되는 것처럼, 각 파일에 대한 접근도 동일한 방식으로 통제될 수 있습니다. 비밀번호가 무작위로 선택되고 자주 변경된다면, 이 체계는 파일에 대한 접근을 제한하는 데 효과적일 수 있습니다. 그러나 비밀번호 사용에는 몇 가지 단점이 있습니다. 첫째, 사용자가 기억해야 할 비밀번호의 수가 많아져서 체계가 비현실적일 수 있습니다. 둘째, 모든 파일에 하나의 비밀번호만 사용하면, 한 번 발견되면 모든 파일에 접근할 수 있습니다. 보호는 모두 또는 전무의 원칙으로 이루어집니다. 일부 시스템에서는 개별 파일보다는 하위 디렉터리에 비밀번호를 연결하여 이 문제를 해결합니다. 더 일반적으로는 파티션 또는 개별 파일을 암호화하여 강력한 보호를 제공하지만, 비밀번호 관리는 중요합니다.

다중 레벨 디렉터리 구조에서는 개별 파일뿐만 아니라 하위 디렉터리의 파일 모음도 보호해야 합니다. 즉, 디렉터리 보호를 위한 메커니즘을 제공해야 합니다. 보호해야 할 디렉터리 작업은 파일 작업과는 다소 다릅니다. 디렉터리에서 파일 생성 및 삭제를 통제하고 싶습니다. 또한 사용자가 디렉터리 내의 파일 존재 여부를 확인할 수 있는지 통제하고 싶을 것입니다. 때로는 파일의 존재와 이름을 아는 것 자체가 중요합니다. 따라서 디렉터리 내용 목록 작성은 보호된 작업이어야 합니다. 마찬가지로, 경로 이름이 디렉터리의 파일을 참조하는 경우, 사용자는 디렉터리와 파일 모두에 접근할 수 있어야 합니다. 파일에 여러 경로 이름이 있을 수 있는 시스템(예: 비순환 그래프 및 일반 그래프)에서는 경로 이름에 따라 특정 파일에 대한 접근 권한이 달라질 수 있습니다.

### 13.5 메모리 매핑 파일

파일에 접근하는 또 다른 방법이 있으며, 매우 흔히 사용됩니다. 표준 시스템 호출 open(), read(), write()를 사용하여 디스크에서 파일을 순차적으로 읽는 것을 생각해 보세요. 각 파일 접근은 시스템 호출과 디스크 접근을 필요로 합니다. 대안으로, 파일 I/O를 일반 메모리 접근으로 처리하기 위해 10장에서 논의한 가상 메모리 기술을 사용할 수 있습니다. 이 접근 방식은 파일을 메모리 매핑하는 것으로 알려져 있으며, 가상 주소 공간의 일부를 파일과 논리적으로 연결할 수 있게 합니다. 이로 인해 성능이 크게 향상될 수 있습니다.

#### 13.5.1 기본 메커니즘

메모리 매핑 파일은 디스크 블록을 메모리의 페이지(또는 페이지들)와 매핑하여 수행됩니다. 파일에 대한 초기 접근은 일반적인 요구 페이징을 통해 진행되며, 페이지 폴트가 발생합니다. 그러나 파일의 페이지 크기 부분이 파일 시스템에서 물리적 페이지로 읽혀집니다(일부 시스템은 한 번에 페이지 크기보다 더 많은 메모리 청크를 읽기로 선택할 수 있습니다). 이후 파일에 대한 읽기와 쓰기는 일반적인 메모리 접근으로 처리됩니다. 메모리를 통해 파일을 조작하면 read() 및 write() 시스템 호출을 사용하는 오버헤드를 줄여 파일 접근과 사용을 단순화하고 가속화할 수 있습니다.

메모리에 매핑된 파일에 대한 쓰기는 반드시 즉시(동기적)로 보조 저장 장치의 파일에 쓰여지지는 않습니다. 일반적으로 시스템은 파일이 닫힐 때 메모리 이미지의 변경 사항을 기반으로 파일을 업데이트합니다. 메모리 압박이 있을 때 시스템은 다른 용도로 메모리를 해제할 때 중간 변경 사항을 교체 공간에 저장하여 손실되지 않도록 합니다. 파일이 닫히면, 모든 메모리 매핑된 데이터는 보조 저장 장치의 파일에 다시 쓰여지고 프로세스의 가상 메모리에서 제거됩니다.

일부 운영 체제는 특정 시스템 호출을 통해서만 메모리 매핑을 제공하며, 모든 다른 파일 I/O는 표준 시스템 호출을 사용하여 수행합니다. 그러나 일부 시스템은 파일이 메모리 매핑으로 지정되었는지 여부와 관계없이 파일을 메모리 매핑하는 것을 선택합니다. Solaris를 예로 들어 봅시다. 파일이 메모리 매핑으로 지정된 경우(mmap() 시스템 호출 사용) Solaris는 파일을 프로세스의 주소 공간에 매핑합니다. 파일이 open(), read(), write()와 같은 일반적인 시스템 호출을 사용하여 열리고 접근되면 Solaris는 여전히 파일을 메모리 매핑합니다. 그러나 파일은 커널 주소 공간에 매핑됩니다. 파일이 어떻게 열리든 관계없이 Solaris는 모든 파일 I/O를 메모리 매핑으로 처리하여 효율적인 메모리 서브시스템을 통해 파일 접근이 이루어지도록 하고 각 전통적인 read() 및 write() 호출로 인한 시스템 호출 오버헤드를 피합니다.

여러 프로세스가 동일한 파일을 동시에 매핑하도록 허용하여 데이터 공유를 가능하게 할 수 있습니다. 어느 프로세스에서든 쓰기는 가상 메모리의 데이터를 수정하며 동일한 파일 섹션을 매핑하는 다른 모든 프로세스에서 볼 수 있습니다. 가상 메모리의 이전 논의를 고려할 때, 메모리 매핑된 메모리 섹션의 공유가 어떻게 구현되는지 명확할 것입니다: 공유 프로세스 각각의 가상 메모리 맵은 동일한 물리적 메모리 페이지를 가리킵니다—디스크 블록의 사본을 포함한 페이지입니다. 이 메모리 공유는 그림 13.13에 설명되어 있습니다. 메모리 매핑 시스템 호출은 또한 쓰기 시 복사 기능을 지원하여 프로세스가 읽기 전용 모드에서 파일을 공유하되 수정한 데이터의 사본을 갖도록 합니다. 공유 데이터에 대한 접근이 조정되도록 하기 위해 관련된 프로세스는 6장에서 설명한 상호 배제 메커니즘 중 하나를 사용할 수 있습니다.

종종 공유 메모리는 사실 파일을 메모리 매핑함으로써 구현됩니다. 이 시나리오에서 프로세스는 동일한 파일을 가상 주소 공간에 메모리 매핑하여 공유 메모리를 통해 통신할 수 있습니다. 메모리 매핑된 파일은 통신하는 프로세스 간의 공유 메모리 영역으로 작동합니다(그림 13.14). 3.5절에서 이미 POSIX 공유 메모리 객체가 생성되고 각 통신 프로세스가 객체를 주소 공간에 메모리 매핑하는 것을 보았습니다. 다음 섹션에서는 메모리 매핑 파일을 사용한 공유 메모리에 대한 Windows API 지원을 논의합니다.

### 14.1 파일 시스템 구조

디스크는 파일 시스템이 유지되는 대부분의 보조 저장 장치를 제공합니다. 두 가지 특성이 이 목적에 적합하게 만듭니다:

1. 디스크는 제자리에 다시 쓸 수 있습니다. 디스크에서 블록을 읽고, 블록을 수정한 후, 동일한 블록에 다시 쓸 수 있습니다.
2. 디스크는 포함된 어떤 블록의 정보든 직접 접근할 수 있습니다. 따라서, 파일을 순차적으로 또는 임의로 접근하는 것이 간단하며, 한 파일에서 다른 파일로 전환하는 것은 드라이브가 읽기-쓰기 헤드를 이동시키고 미디어가 회전하기를 기다리는 것을 필요로 합니다.

비휘발성 메모리(NVM) 장치는 점점 더 파일 저장 및 파일 시스템의 위치로 사용되고 있습니다. NVM 장치는 하드 디스크와는 달리 제자리에 다시 쓸 수 없고 다른 성능 특성을 가지고 있습니다. 디스크 및 NVM 장치의 구조에 대해서는 11장에서 자세히 논의합니다.

I/O 효율성을 향상시키기 위해, 메모리와 대용량 저장 장치 간의 I/O 전송은 블록 단위로 수행됩니다. 하드 디스크 드라이브의 각 블록은 하나 이상의 섹터를 가지고 있습니다. 디스크 드라이브에 따라 섹터 크기는 일반적으로 512 바이트 또는 4,096 바이트입니다. NVM 장치는 보통 4,096 바이트의 블록을 가지며, 사용되는 전송 방법은 디스크 드라이브에서 사용되는 것과 유사합니다.

파일 시스템은 데이터를 쉽게 저장, 위치 지정 및 검색할 수 있게 하여 저장 장치에 효율적이고 편리하게 접근할 수 있도록 합니다. 파일 시스템은 두 가지 매우 다른 설계 문제를 제기합니다. 첫 번째 문제는 파일 시스템이 사용자에게 어떻게 보여야 하는지를 정의하는 것입니다. 이 작업에는 파일과 그 속성을 정의하고, 파일에 허용되는 작업과 파일을 조직하는 디렉터리 구조를 정의하는 것이 포함됩니다. 두 번째 문제는 논리적 파일 시스템을 물리적 보조 저장 장치에 매핑하기 위한 알고리즘과 데이터 구조를 만드는 것입니다.

파일 시스템 자체는 일반적으로 많은 다른 수준으로 구성됩니다. 그림 14.1에 나타난 구조는 계층적 설계의 예입니다. 설계의 각 수준은 더 높은 수준에서 사용될 새로운 기능을 만들기 위해 더 낮은 수준의 기능을 사용합니다.

I/O 제어 수준은 장치 드라이버와 인터럽트 핸들러로 구성되어 있으며, 메인 메모리와 디스크 시스템 간의 정보를 전송합니다. 장치 드라이버는 번역기라고 생각할 수 있습니다. 그 입력은 "블록 123을 검색"과 같은 고수준 명령어로 구성됩니다. 그 출력은 하드웨어 컨트롤러가 사용하는 하드웨어 특정 명령어로 구성되며, 이는 I/O 장치를 시스템의 나머지 부분과 인터페이스합니다. 장치 드라이버는 일반적으로 I/O 컨트롤러의 메모리의 특정 위치에 특정 비트 패턴을 기록하여 컨트롤러에게 어떤 장치 위치를 작업할지와 어떤 작업을 수행할지를 지시합니다. 장치 드라이버와 I/O 인프라의 세부 사항은 12장에서 다룹니다.

기본 파일 시스템(리눅스에서는 "블록 I/O 서브시스템"이라고 함)은 저장 장치에서 블록을 읽고 쓰기 위해 적절한 장치 드라이버에 일반 명령어만 발행하면 됩니다. 이 레이어는 논리적 블록 주소에 따라 드라이브에 명령을 발행합니다. 또한 I/O 요청 스케줄링과도 관련이 있습니다. 이 레이어는 다양한 파일 시스템, 디렉터리, 데이터 블록을 보유하는 메모리 버퍼와 캐시도 관리합니다. 버퍼가 가득 차면 버퍼 관리자는 더 많은 버퍼 메모리를 찾거나 요청된 I/O가 완료될 수 있도록 버퍼 공간을 해제해야 합니다. 캐시는 성능을 향상시키기 위해 자주 사용되는 파일 시스템 메타데이터를 보유하는 데 사용되므로, 캐시의 내용을 관리하는 것이 최적의 시스템 성능에 중요합니다.

파일 조직 모듈은 파일과 그 논리적 블록에 대해 알고 있습니다. 각 파일의 논리적 블록은 0(또는 1)에서 N까지 번호가 매겨집니다. 파일 조직 모듈에는 미할당 블록을 추적하고 요청 시 파일 조직 모듈에 이 블록을 제공하는 자유 공간 관리자도 포함됩니다.

마지막으로, 논리적 파일 시스템은 메타데이터 정보를 관리합니다. 메타데이터에는 실제 데이터(또는 파일의 내용)를 제외한 모든 파일 시스템 구조가 포함됩니다. 논리적 파일 시스템은 디렉터리 구조를 관리하여 파일 조직 모듈에 상징적 파일 이름을 제공할 때 필요한 정보를 제공합니다. 파일 제어 블록을 통해 파일 구조를 유지합니다. 파일 제어 블록(FCB)(유닉스 파일 시스템의 inode)은 소유권, 권한 및 파일 내용의 위치를 포함하여 파일에 대한 정보를 포함합니다. 논리적 파일 시스템은 13장과 17장에서 논의된 대로 보호도 책임집니다.

파일 시스템 구현에 계층 구조가 사용되면 코드의 중복이 최소화됩니다. I/O 제어와 때로는 기본 파일 시스템 코드는 여러 파일 시스템에서 사용할 수 있습니다. 각 파일 시스템은 자체 논리적 파일 시스템과 파일 조직 모듈을 가질 수 있습니다. 불행히도, 계층화는 운영 체제 오버헤드를 증가시킬 수 있으며, 이는 성능 저하를 초래할 수 있습니다. 계층화의 사용, 사용해야 할 계층의 수, 각 계층이 수행할 작업에 대한 결정은 새로운 시스템을 설계하는 데 있어 주요 과제입니다.

오늘날 많은 파일 시스템이 사용되고 있으며 대부분의 운영 체제는 하나 이상의 파일 시스템을 지원합니다. 예를 들어, 대부분의 CD-ROM은 ISO 9660 형식으로 작성됩니다. 이는 CD-ROM 제조업체들이 합의한 표준 형식입니다. 이동식 미디어 파일 시스템 외에도 각 운영 체제에는 하나 이상의 디스크 기반 파일 시스템이 있습니다. UNIX는 버클리 고속 파일 시스템(FFS)을 기반으로 한 UNIX 파일 시스템(UFS)을 사용합니다. Windows는 FAT, FAT32, NTFS(Windows NT 파일 시스템)의 디스크 파일 시스템 형식을 지원하며, CD-ROM 및 DVD 파일 시스템 형식도 지원합니다. 리눅스는 130개 이상의 파일 시스템을 지원하지만, 표준 리눅스 파일 시스템은 확장 파일 시스템으로 알려져 있으며, 가장 일반적인 버전은 ext3과 ext4입니다. 또한 서버의 파일 시스템을 하나 이상의 클라이언트 컴퓨터가 네트워크를 통해 마운트하는 분산 파일 시스템도 있습니다.

파일 시스템 연구는 운영 체제 설계 및 구현에서 활발한 영역으로 남아 있습니다. Google은 수많은 디스크에서 많은 클라이언트로부터 고성능 접근을 포함한 회사의 특정 저장 및 검색 요구를 충족시키기 위해 자체 파일 시스템을 만들었습니다. 또 다른 흥미로운 프로젝트는 FUSE 파일 시스템으로, 파일 시스템을 사용자 레벨 코드로 구현하고 실행함으로써 파일 시스템 개발과 사용에 유연성을 제공합니다. FUSE를 사용하면 사용자가 다양한 운영 체제에 새 파일 시스템을 추가할 수 있으며, 그 파일 시스템을 사용하여 파일을 관리할 수 있습니다.

### 14.2 파일 시스템 작업

섹션 13.1.2에서 설명한 대로, 운영 체제는 프로세스가 파일 내용에 접근하기 위해 open() 및 close() 시스템 호출을 구현합니다. 이 섹션에서는 파일 시스템 작업을 구현하는 데 사용되는 구조와 작업을 다룹니다.

#### 14.2.1 개요

파일 시스템을 구현하기 위해 여러 저장 및 메모리 내 구조가 사용됩니다. 이러한 구조는 운영 체제와 파일 시스템에 따라 다르지만 몇 가지 일반 원칙이 적용됩니다.

저장소에는, 파일 시스템이 그곳에 저장된 운영 체제를 부팅하는 방법, 총 블록 수, 사용 가능한 블록의 수와 위치, 디렉터리 구조 및 개별 파일에 대한 정보가 포함될 수 있습니다. 이러한 구조의 많은 부분은 이 장의 나머지 부분에서 자세히 설명됩니다. 여기서는 간략히 설명합니다:

- 부팅 제어 블록(볼륨 당)은 시스템이 해당 볼륨에서 운영 체제를 부팅하는 데 필요한 정보를 포함할 수 있습니다. 디스크에 운영 체제가 포함되지 않은 경우, 이 블록은 비어 있을 수 있습니다. 이는 일반적으로 볼륨의 첫 번째 블록입니다. UFS에서는 부트 블록이라고 하며, NTFS에서는 파티션 부트 섹터입니다.
- 볼륨 제어 블록(볼륨 당)은 볼륨의 블록 수, 블록 크기, 사용 가능한 블록 수 및 사용 가능한 블록 포인터, 사용 가능한 FCB 수 및 FCB 포인터와 같은 볼륨 세부 정보를 포함합니다. UFS에서는 이를 슈퍼블록이라고 하며, NTFS에서는 마스터

 파일 테이블에 저장됩니다.
- 파일 시스템 당 디렉터리 구조는 파일을 조직하는 데 사용됩니다. UFS에서는 파일 이름과 관련된 inode 번호가 포함됩니다. NTFS에서는 마스터 파일 테이블에 저장됩니다.
- 파일 당 FCB는 파일에 대한 많은 세부 정보를 포함합니다. 이는 디렉터리 항목과 연결할 수 있는 고유 식별 번호를 가집니다. NTFS에서는 이 정보가 실제로 마스터 파일 테이블 내에 저장되며, 각 파일 당 하나의 행을 가지는 관계형 데이터베이스 구조를 사용합니다.

메모리 내 정보는 파일 시스템 관리와 캐싱을 통한 성능 향상을 위해 사용됩니다. 데이터는 마운트 시 로드되고, 파일 시스템 작업 중에 업데이트되며, 디스마운트 시 삭제됩니다. 여러 유형의 구조가 포함될 수 있습니다:

- 메모리 내 마운트 테이블은 각 마운트된 볼륨에 대한 정보를 포함합니다.
- 메모리 내 디렉터리 구조 캐시는 최근에 접근한 디렉터리의 디렉터리 정보를 보유합니다. (볼륨이 마운트된 디렉터리에 대해서는 볼륨 테이블에 대한 포인터를 포함할 수 있습니다.)
- 시스템 전체의 오픈 파일 테이블은 각 오픈된 파일의 FCB 사본과 기타 정보를 포함합니다.
- 프로세스 별 오픈 파일 테이블은 프로세스가 오픈한 모든 파일에 대해 시스템 전체의 오픈 파일 테이블의 적절한 항목에 대한 포인터와 기타 정보를 포함합니다.
- 버퍼는 파일 시스템 블록이 파일 시스템에서 읽히거나 쓰일 때 보유합니다.

새 파일을 만들기 위해, 프로세스는 논리적 파일 시스템을 호출합니다. 논리적 파일 시스템은 디렉터리 구조의 형식을 알고 있습니다. 새 파일을 만들기 위해, 새로운 FCB를 할당합니다. (또는, 파일 시스템 구현이 파일 시스템 생성 시 모든 FCB를 생성하면, FCB는 사용 가능한 FCB 집합에서 할당됩니다.) 시스템은 적절한 디렉터리를 메모리로 읽고, 새 파일 이름과 FCB로 업데이트한 후 파일 시스템에 다시 씁니다. 일반적인 FCB는 그림 14.2에 나와 있습니다.

일부 운영 체제, 유닉스를 포함하여, 디렉터리를 파일과 동일하게 처리합니다—즉, 디렉터리임을 나타내는 "타입" 필드가 있는 파일로 처리합니다. 다른 운영 체제, 윈도우를 포함하여, 파일과 디렉터리에 대해 별도의 시스템 호출을 구현하고 디렉터리를 파일과 별개의 엔티티로 처리합니다. 더 큰 구조적 문제와 상관없이, 논리적 파일 시스템은 디렉터리 I/O를 저장 블록 위치로 매핑하기 위해 파일 조직 모듈을 호출할 수 있으며, 이는 기본 파일 시스템과 I/O 제어 시스템으로 전달됩니다.

#### 14.2.2 사용

파일이 생성되면, I/O에 사용될 수 있습니다. 먼저, 파일을 열어야 합니다. open() 호출은 파일 이름을 논리적 파일 시스템에 전달합니다. open() 시스템 호출은 먼저 시스템 전체의 오픈 파일 테이블을 검색하여 파일이 이미 다른 프로세스에 의해 사용 중인지 확인합니다. 그렇다면, 프로세스 별 오픈 파일 테이블 항목이 기존의 시스템 전체의 오픈 파일 테이블을 가리키도록 생성됩니다. 이 알고리즘은 상당한 오버헤드를 절약할 수 있습니다. 파일이 아직 열려 있지 않다면, 디렉터리 구조를 검색하여 주어진 파일 이름을 찾습니다. 디렉터리 구조의 일부는 디렉터리 작업 속도를 높이기 위해 메모리에 캐시되어 있습니다. 파일을 찾으면, FCB가 메모리 내의 시스템 전체 오픈 파일 테이블에 복사됩니다. 이 테이블은 FCB를 저장할 뿐만 아니라 파일을 열어 놓은 프로세스의 수를 추적합니다.

그 다음, 프로세스 별 오픈 파일 테이블에 항목이 생성되며, 시스템 전체 오픈 파일 테이블 항목에 대한 포인터와 다른 필드가 포함됩니다. 이러한 다른 필드에는 파일에서 현재 위치(다음 read() 또는 write() 작업을 위한)와 파일을 열 때의 접근 모드가 포함될 수 있습니다. open() 호출은 프로세스 별 파일 시스템 테이블의 적절한 항목에 대한 포인터를 반환합니다. 모든 파일 작업은 이후 이 포인터를 통해 수행됩니다. 파일 이름은 오픈 파일 테이블의 일부가 아닐 수 있으며, 적절한 FCB가 디스크에 위치한 후에는 시스템에서 필요하지 않습니다. 그러나 동일한 파일을 다음에 열 때 시간을 절약하기 위해 캐시될 수 있습니다. 항목에 부여된 이름은 다를 수 있습니다. 유닉스 시스템은 이를 파일 설명자라고 하며, 윈도우는 파일 핸들이라고 합니다.

프로세스가 파일을 닫으면, 프로세스 별 테이블 항목이 제거되고, 시스템 전체 항목의 오픈 수가 감소합니다. 파일을 연 모든 사용자가 파일을 닫으면, 업데이트된 메타데이터가 디스크 기반 디렉터리 구조에 복사되고, 시스템 전체 오픈 파일 테이블 항목이 제거됩니다.

파일 시스템 구조의 캐싱 측면을 간과해서는 안 됩니다. 대부분의 시스템은 실제 데이터 블록을 제외한 오픈 파일에 대한 모든 정보를 메모리에 보유합니다. BSD 유닉스 시스템은 디스크 I/O를 절약할 수 있는 곳 어디에서든 캐시를 사용하는 것이 일반적입니다. 85%의 평균 캐시 히트율을 보여주는 이러한 기술은 구현할 가치가 충분히 있습니다. BSD 유닉스 시스템은 부록 C에서 완전히 설명되어 있습니다.

파일 시스템 구현의 운영 구조는 그림 14.3에 요약되어 있습니다.

### 14.3 디렉터리 구현

디렉터리 할당 및 디렉터리 관리 알고리즘의 선택은 파일 시스템의 효율성, 성능, 신뢰성에 큰 영향을 미칩니다. 이 섹션에서는 이러한 알고리즘 중 하나를 선택할 때의 트레이드오프를 논의합니다.

#### 14.3.1 선형 목록

디렉터리를 구현하는 가장 간단한 방법은 파일 이름과 데이터 블록에 대한 포인터를 가진 선형 목록을 사용하는 것입니다. 이 방법은 프로그래밍하기는 간단하지만 실행하는 데 시간이 많이 걸립니다. 새 파일을 생성하려면 먼저 디렉터리를 검색하여 동일한 이름의 파일이 없는지 확인해야 합니다. 그런 다음 디렉터리 끝에 새 항목을 추가합니다. 파일을 삭제하려면, 디렉터리에서 해당 파일 이름을 검색한 다음 할당된 공간을 해제합니다. 디렉터리 항목을 재사용하기 위해, 몇 가지 방법 중 하나를 사용할 수 있습니다. 항목을 사용되지 않음으로 표시하거나(예: 모든 공백 이름을 할당하거나, 유효하지 않은 inode 번호(예: 0)를 할당하거나, 각 항목에 사용됨-사용되지 않음 비트를 포함하여), 사용 가능한 디렉터리 항목 목록에 연결할 수 있습니다. 세 번째 대안은 디렉터리의 마지막 항목을 해제된 위치로 복사하고 디렉터리 길이를 줄이는 것입니다. 파일을 삭제하는 데 필요한 시간을 줄이기 위해 연결된 목록을 사용할 수도 있습니다.

디렉터리 항목의 선형 목록의 실제 단점은 파일을 찾기 위해 선형 검색이 필요하다는 것입니다. 디렉터리 정보는 자주 사용되며, 접근 속도가 느리면 사용자는 이를 눈치챕니다. 실제로 많은 운영 체제는 가장 최근에 사용된 디렉터리 정보를 저장하기 위해 소프트웨어 캐시를 구현합니다. 캐시 히트는 정보를 보조 저장 장치에서 계속 다시 읽을 필요를 없앱니다. 정렬된 목록은 이진 검색을 가능하게 하여 평균 검색 시간을 줄입니다. 그러나 목록을 정렬된 상태로 유지해야 하는 요구 사항은 파일을 생성하거나 삭제할 때 디렉터리 정보를 대량으로 이동해야 할 수도 있어 복잡성을 증가시킵니다. 여기서 균형 트리와 같은 보다 정교한 트리 데이터 구조가 도움이 될 수 있습니다. 정렬된 목록의 장점은 별도의 정렬 단계 없이 정렬된 디렉터리 목록을 생성할 수 있다는 것입니다.

#### 14.3.2 해시 테이블

파일 디렉터리에 사용되는 또 다른 데이터 구조는 해시 테이블입니다. 여기서 선형 목록은 디렉터리 항목을 저장하지만, 해시 데이터 구조도 사용됩니다. 해시 테이블은 파일 이름에서 계산된 값을 가져와 선형 목록의 파일 이름에 대한 포인터를 반환합니다. 따라서 디렉터리 검색 시간을 크게 줄일 수 있습니다. 삽입 및 삭제도 비교적 간단하지만 충돌—즉, 두 파일 이름이 동일한 위치로 해시되는 상황—에 대한 대비가 필요합니다.

해시 테이블의 주요 문제는 일반적으로 고정된 크기이며 해시 함수가 그 크기에 의존한다는 것입니다. 예를 들어, 64개의 항목을 저장하는 선형 탐색 해시 테이블

을 만든다고 가정해 봅시다. 해시 함수는 파일 이름을 0에서 63까지의 정수로 변환합니다(예: 64로 나눈 나머지를 사용하여). 나중에 65번째 파일을 생성하려고 하면, 디렉터리 해시 테이블을 128개의 항목으로 확장해야 합니다. 결과적으로, 파일 이름을 0에서 127 범위로 매핑하는 새로운 해시 함수가 필요하며, 기존 디렉터리 항목을 새로운 해시 함수 값에 맞게 재구성해야 합니다.

대안으로, 체인 오버플로 해시 테이블을 사용할 수 있습니다. 각 해시 항목은 개별 값 대신 연결된 목록이 될 수 있으며, 충돌을 새 항목을 연결된 목록에 추가하여 해결할 수 있습니다. 이름을 검색하려면 충돌하는 테이블 항목의 연결된 목록을 따라야 하므로 검색 속도가 약간 느려질 수 있습니다. 그래도 전체 디렉터리를 선형 검색하는 것보다 이 방법이 훨씬 빠를 가능성이 큽니다.

### 14.4 할당 방법

보조 저장 장치의 직접 접근 특성은 파일 구현에 유연성을 제공합니다. 거의 모든 경우에, 여러 파일이 동일한 장치에 저장됩니다. 주요 문제는 이러한 파일에 공간을 할당하여 저장 공간을 효과적으로 사용하고 파일에 빠르게 접근할 수 있도록 하는 방법입니다. 보조 저장 공간을 할당하는 세 가지 주요 방법이 널리 사용됩니다: 연속 할당, 연결 할당 및 인덱스 할당. 각 방법에는 장단점이 있습니다. 일부 시스템은 세 가지 모두를 지원하지만, 시스템이 파일 시스템 유형 내의 모든 파일에 대해 하나의 방법을 사용하는 것이 더 일반적입니다.

#### 14.4.1 연속 할당

연속 할당은 각 파일이 장치의 연속된 블록 집합을 차지해야 합니다. 장치 주소는 장치의 선형 순서를 정의합니다. 이 순서에 따르면, 하나의 작업만 장치에 접근하는 경우 블록 b 다음 블록 b+1에 접근하는 데 헤드 이동이 필요하지 않습니다. 헤드 이동이 필요한 경우(한 실린더의 마지막 섹터에서 다음 실린더의 첫 번째 섹터로 이동하는 경우), 헤드는 한 트랙에서 다음 트랙으로만 이동하면 됩니다. 따라서 HDD의 경우, 연속적으로 할당된 파일에 접근하는 데 필요한 디스크 탐색 횟수는 최소화되며(논리적 주소가 가까운 블록이 물리적으로도 가까운 경우), 탐색 시간이 최소화됩니다.

연속 할당된 파일은 첫 번째 블록의 주소와 파일의 길이(블록 단위)로 정의됩니다. 파일이 n 블록 길이이고 위치 b에서 시작되면, b, b+1, b+2, ..., b+n-1 블록을 차지합니다. 각 파일의 디렉터리 항목은 시작 블록의 주소와 이 파일에 할당된 영역의 길이를 나타냅니다(그림 14.4). 연속 할당은 구현하기 쉽지만 한계가 있어 현대 파일 시스템에서는 사용되지 않습니다.

연속 할당된 파일에 접근하는 것은 쉽습니다. 순차 접근의 경우, 파일 시스템은 마지막으로 참조된 블록의 주소를 기억하고 필요할 때 다음 블록을 읽습니다. 블록 b에서 시작하는 파일의 블록 I에 직접 접근하려면, 바로 블록 b+i에 접근할 수 있습니다. 따라서, 연속 할당은 순차 접근과 직접 접근 모두를 지원할 수 있습니다.

그러나 연속 할당에는 몇 가지 문제가 있습니다. 새로운 파일을 위한 공간을 찾는 것이 어려울 수 있습니다. 이 작업이 어떻게 수행되는지는 선택된 자유 공간 관리 시스템에 달려 있습니다. 이러한 관리 시스템은 14.5절에서 논의됩니다. 모든 관리 시스템을 사용할 수 있지만, 일부는 다른 것보다 느립니다.

연속 할당 문제는 9.2절에서 논의된 일반적인 동적 저장 할당 문제의 특정 응용으로 볼 수 있습니다. 이는 자유 공간 목록에서 크기 n의 요청을 어떻게 만족시킬 것인가에 관한 문제입니다. 첫 번째 적합(fit)과 최적 적합(fit)은 사용 가능한 홀 집합에서 자유 홀을 선택하는 데 가장 일반적인 전략입니다. 시뮬레이션에 따르면, 첫 번째 적합과 최적 적합은 시간과 저장 공간 활용 측면에서 최악 적합(worst fit)보다 더 효율적입니다. 저장 공간 활용 측면에서 첫 번째 적합이나 최적 적합이 명확히 더 나은 것은 아니지만, 첫 번째 적합이 일반적으로 더 빠릅니다.

이 알고리즘들은 모두 외부 단편화 문제를 겪습니다. 파일이 할당되고 삭제되면서, 자유 저장 공간이 작은 조각으로 나뉩니다. 외부 단편화는 자유 공간이 조각으로 나뉠 때마다 존재합니다. 요청에 대해 가장 큰 연속 조각이 충분하지 않으면, 저장 공간은 데이터를 저장하기에 충분히 큰 홀로 분할됩니다. 디스크 저장 공간의 총량과 평균 파일 크기에 따라, 외부 단편화는 사소한 문제일 수도 있고, 심각한 문제일 수도 있습니다.

외부 단편화로 인해 상당한 양의 저장 공간을 잃는 것을 방지하는 한 가지 전략은 전체 파일 시스템을 다른 장치로 복사하는 것입니다. 원래 장치는 완전히 비워져 하나의 큰 연속 자유 공간이 생성됩니다. 그런 다음, 파일을 이 큰 홀에서 연속 공간을 할당하여 원래 장치로 다시 복사합니다. 이 방식은 모든 자유 공간을 하나의 연속 공간으로 효과적으로 압축하여 단편화 문제를 해결합니다. 그러나 이 압축의 비용은 시간이며, 특히 큰 저장 장치에서는 비용이 매우 높을 수 있습니다. 이러한 장치를 압축하는 데 몇 시간이 걸릴 수 있으며, 주간 단위로 필요할 수 있습니다. 일부 시스템은 이 기능을 오프라인에서 수행해야 하며, 파일 시스템이 마운트 해제되어야 합니다. 이 다운타임 동안 정상 시스템 운영은 일반적으로 허용되지 않으므로, 생산 기계에서는 이러한 압축을 모든 비용을 피해야 합니다. 대부분의 현대 시스템은 디프래그가 필요한 경우, 정상 시스템 운영 중에 온라인으로 수행할 수 있지만, 성능 페널티가 상당할 수 있습니다.

연속 할당의 또 다른 문제는 파일에 필요한 공간을 결정하는 것입니다. 파일이 생성될 때, 필요한 총 공간을 찾아 할당해야 합니다. 생성자(프로그램 또는 사람)는 생성될 파일의 크기를 어떻게 알 수 있을까요? 일부 경우에는 이 결정이 비교적 간단할 수 있습니다(예: 기존 파일 복사). 그러나 일반적으로 출력 파일의 크기를 추정하기 어려울 수 있습니다.

파일에 너무 적은 공간을 할당하면, 파일을 확장할 수 없을 수 있습니다. 특히 최적 적합 할당 전략을 사용할 때, 파일 양쪽의 공간이 사용 중일 수 있습니다. 따라서 파일을 제자리에 더 크게 만들 수 없습니다. 두 가지 가능성이 있습니다. 첫째, 사용자 프로그램을 종료하고 적절한 오류 메시지를 출력할 수 있습니다. 사용자는 더 많은 공간을 할당하고 프로그램을 다시 실행해야 합니다. 이러한 반복 실행은 비용이 많이 들 수 있습니다. 이를 방지하기 위해 사용자는 보통 필요한 공간을 과대 평가하여 상당한 공간 낭비를 초래합니다. 다른 가능성은 더 큰 홀을 찾아 파일 내용을 새 공간으로 복사하고 이전 공간을 해제하는 것입니다. 공간이 있는 한 이러한 일련의 작업을 반복할 수 있지만, 시간이 많이 걸릴 수 있습니다. 사용자는 문제가 발생했음을 명시적으로 알리지 않아도 되며, 시스템은 점점 더 느려지면서 계속 작동할 수 있습니다.

파일에 필요한 총 공간이 미리 알려진 경우에도 사전 할당은 비효율적일 수 있습니다. 오랜 기간(몇 달 또는 몇 년) 동안 천천히 성장할 파일은 최종 크기에 충분한 공간을 할당해야 하며, 그 공간의 대부분은 오랫동안 사용되지 않을 수 있습니다. 따라서 파일에는 많은 내부 단편화가 발생합니다.

이러한 단점을 최소화하기 위해, 운영 체제는 수정된 연속 할당 체계를 사용할 수 있습니다. 여기서는 처음에 연속 공간 덩어리를 할당합니다. 그런 다음, 그 양이 충분하지 않으면, 또 다른 연속 공간 덩어리인 extents를 추가합니다. 파일 블록의 위치는 위치와 블록 수, 그리고 다음 extent의 첫 번째 블록에 대한 링크로 기록됩니다. 일부 시스템에서는 파일 소유자가 extent 크기를 설정할 수 있지만, 소유자가 잘못 설정하면 비효율이 발생합니다. extents가 너무 크면 내부 단편화가 여전히 문제가 될 수 있으며, 다양한 크기의 extents를 할당하고 해제함에 따라 외부 단편화가 문제가 될 수 있습니다. 상용 Symantec Veritas 파일 시스템은 성능을 최적화하기 위해 extents를 사용합니다. Veritas는 표준 UNIX UFS의 고성능 대체품입니다.

#### 14.4.2 연결 할당

연결 할당은 연속 할당의 모든 문제를 해결합니다. 연결 할당에서는 각 파일이 스토리지

 블록의 연결 목록이며, 블록은 장치 어디에나 흩어져 있을 수 있습니다. 디렉터리에는 파일의 첫 번째 블록과 마지막 블록에 대한 포인터가 포함됩니다. 예를 들어, 5블록의 파일이 블록 9에서 시작하여 블록 16, 블록 1, 블록 10, 마지막으로 블록 25로 계속될 수 있습니다(그림 14.5). 각 블록에는 다음 블록에 대한 포인터가 포함됩니다. 이러한 포인터는 사용자에게 제공되지 않습니다. 따라서 각 블록이 512 바이트 크기이고, 블록 주소(포인터)가 4 바이트를 필요로 한다면, 사용자는 508 바이트 크기의 블록을 보게 됩니다.

새 파일을 생성하기 위해, 디렉터리에 새 항목을 생성합니다. 연결 할당에서는 각 디렉터리 항목에 파일의 첫 번째 블록에 대한 포인터가 있습니다. 이 포인터는 빈 파일을 나타내기 위해 null(리스트의 끝 포인터 값)로 초기화됩니다. 크기 필드도 0으로 설정됩니다. 파일에 쓰기가 발생하면, 자유 공간 관리 시스템이 자유 블록을 찾아 이 새 블록에 쓰고 파일의 끝에 연결합니다. 파일을 읽기 위해, 포인터를 따라 블록에서 블록으로 이동하며 블록을 읽습니다. 연결 할당에는 외부 단편화가 없으며, 자유 공간 목록의 모든 자유 블록을 요청을 만족시키는 데 사용할 수 있습니다. 파일의 크기는 생성 시 선언할 필요가 없습니다. 파일은 자유 블록이 있는 한 계속 성장할 수 있습니다. 따라서 디스크 공간을 압축할 필요가 없습니다.

그러나 연결 할당에는 단점이 있습니다. 주요 문제는 연결 할당이 순차 접근 파일에만 효과적으로 사용될 수 있다는 것입니다. 파일의 i번째 블록을 찾기 위해, 파일의 시작에서 시작하여 포인터를 따라 i번째 블록까지 이동해야 합니다. 각 포인터에 대한 접근은 스토리지 장치 읽기를 필요로 하며, 일부는 HDD 탐색을 필요로 합니다. 따라서 연결 할당 파일에 직접 접근 기능을 지원하는 것은 비효율적입니다.

또 다른 단점은 포인터에 필요한 공간입니다. 포인터가 512 바이트 블록에서 4 바이트를 필요로 한다면, 디스크의 0.78%가 정보 대신 포인터에 사용됩니다. 각 파일은 약간 더 많은 공간이 필요합니다.

이 문제에 대한 일반적인 해결책은 블록을 클러스터라는 다중 값으로 모으고 블록 대신 클러스터를 할당하는 것입니다. 예를 들어, 파일 시스템은 클러스터를 네 개의 블록으로 정의하고 보조 저장 장치에서 클러스터 단위로만 작업할 수 있습니다. 포인터는 파일 공간의 더 작은 비율을 사용합니다. 이 방법은 논리적-물리적 블록 매핑을 단순하게 유지하면서 HDD 처리량을 향상시키고(디스크 헤드 탐색이 적게 필요함) 블록 할당과 자유 목록 관리를 위한 공간을 줄입니다. 이 접근 방식의 비용은 클러스터가 부분적으로 찬 경우 블록이 부분적으로 찬 경우보다 더 많은 공간이 낭비되므로 내부 단편화가 증가한다는 것입니다. 또한 무작위 I/O 성능이 저하됩니다. 왜냐하면 소량의 데이터에 대한 요청이 대량의 데이터를 전송하기 때문입니다. 클러스터는 많은 다른 알고리즘에서도 디스크 접근 시간을 향상시키기 위해 사용될 수 있으므로 대부분의 파일 시스템에서 사용됩니다.

연결 할당의 또 다른 문제는 신뢰성입니다. 파일은 장치 전체에 흩어져 있는 포인터로 연결되어 있으며, 포인터가 손실되거나 손상되었을 때 발생하는 상황을 고려해 보십시오. 운영 체제 소프트웨어의 버그나 하드웨어 고장은 잘못된 포인터를 선택하는 결과를 초래할 수 있습니다. 이 오류는 자유 공간 목록이나 다른 파일로 연결되는 결과를 초래할 수 있습니다. 부분적인 해결책은 이중 연결 목록을 사용하는 것이며, 다른 하나는 각 블록에 파일 이름과 상대 블록 번호를 저장하는 것입니다. 그러나 이러한 체계는 각 파일에 대해 더 많은 오버헤드를 필요로 합니다.

연결 할당의 중요한 변형은 파일 할당 테이블(FAT)을 사용하는 것입니다. 이 간단하지만 효율적인 디스크 공간 할당 방법은 MS-DOS 운영 체제에서 사용되었습니다. 각 볼륨의 시작 부분에 테이블을 저장할 섹션이 예약됩니다. 테이블은 각 블록에 대해 하나의 항목을 가지고 있으며, 블록 번호로 인덱싱됩니다. FAT는 연결 목록과 거의 동일한 방식으로 사용됩니다. 디렉터리 항목에는 파일의 첫 번째 블록 번호가 포함됩니다. 해당 블록 번호로 인덱싱된 테이블 항목에는 파일의 다음 블록 번호가 포함됩니다. 이 체인은 마지막 블록에 도달할 때까지 계속되며, 마지막 블록에는 테이블 항목으로 특별한 파일 끝 값이 있습니다. 사용되지 않은 블록은 테이블 값이 0으로 표시됩니다. 새 블록을 파일에 할당하는 것은 0 값 테이블 항목을 찾고, 이전 파일 끝 값을 새 블록 주소로 교체하는 간단한 문제입니다. 그런 다음 0은 파일 끝 값으로 교체됩니다. FAT 구조의 예는 디스크 블록 217, 618, 339로 구성된 파일에 대해 그림 14.6에 나와 있습니다.

FAT 할당 체계는 FAT가 캐시되지 않는 한 상당한 수의 디스크 헤드 탐색을 초래할 수 있습니다. 디스크 헤드는 볼륨의 시작으로 이동하여 FAT를 읽고 문제의 블록 위치를 찾은 다음, 블록 자체의 위치로 이동해야 합니다. 최악의 경우, 각 블록마다 두 번의 이동이 발생합니다. 그러나 랜덤 접근 시간이 향상되므로 디스크 헤드는 FAT의 정보를 읽어 어떤 블록의 위치든 찾을 수 있습니다.

#### 14.4.3 인덱스 할당

연결 할당은 연속 할당의 외부 단편화와 크기 선언 문제를 해결합니다. 그러나 FAT가 없는 경우, 연결 할당은 효율적인 직접 접근을 지원할 수 없습니다. 왜냐하면 블록에 대한 포인터가 디스크 전체에 흩어져 있고 순서대로 검색해야 하기 때문입니다. 인덱스 할당은 모든 포인터를 한 위치로 모아 이 문제를 해결합니다: 인덱스 블록입니다.

각 파일에는 자체 인덱스 블록이 있으며, 이는 저장 블록 주소의 배열입니다. 인덱스 블록의 i번째 항목은 파일의 i번째 블록을 가리킵니다. 디렉터리는 인덱스 블록의 주소를 포함합니다(그림 14.7). i번째 블록을 찾고 읽으려면 인덱스 블록 항목의 포인터를 사용합니다. 이 체계는 9.3절에서 설명한 페이징 체계와 유사합니다.

파일이 생성되면, 인덱스 블록의 모든 포인터는 null로 설정됩니다. i번째 블록이 처음으로 쓰여질 때, 자유 공간 관리자에서 블록을 가져와 그 주소를 i번째 인덱스 블록 항목에 넣습니다.

인덱스 할당은 외부 단편화를 겪지 않고 직접 접근을 지원합니다. 왜냐하면 저장 장치의 모든 자유 블록이 공간 요청을 만족시킬 수 있기 때문입니다. 그러나 인덱스 할당은 공간 낭비 문제가 있습니다. 인덱스 블록의 포인터 오버헤드는 일반적으로 연결 할당의 포인터 오버헤드보다 큽니다. 파일이 하나 또는 두 블록인 일반적인 경우를 생각해 보십시오. 연결 할당에서는 각 블록당 포인터 하나만의 공간을 잃습니다. 인덱스 할당에서는 하나 또는 두 개의 포인터만 null이 아닌 경우에도 전체 인덱스 블록을 할당해야 합니다.

이 점은 인덱스 블록이 얼마나 커야 하는지에 대한 질문을 제기합니다. 모든 파일은 인덱스 블록을 가져야 하므로, 인덱스 블록을 가능한 작게 유지하고자 합니다. 그러나 인덱스 블록이 너무 작으면 큰 파일에 대해 충분한 포인터를 보유할 수 없으며, 이를 처리할 메커니즘이 필요합니다. 이러한 메커니즘에는 다음이 포함됩니다:

- 연결 체계: 인덱스 블록은 일반적으로 하나의 저장 블록입니다. 따라서 단독으로 직접 읽고 쓸 수 있습니다. 큰 파일을 허용하기 위해, 여러 인덱스 블록을 연결할 수 있습니다. 예를 들어, 인덱스 블록에는 파일 이름과 첫 100개의 디스크 블록 주소 집합을 제공하는 작은 헤더가 포함될 수 있습니다. 다음 주소(인덱스 블록의 마지막 단어)는 null(작은 파일의 경우)이거나 다른 인덱스 블록을 가리키는 포인터(큰 파일의 경우)일 수 있습니다.
- 다중 레벨 인덱스

: 연결 표현의 변형은 첫 번째 레벨 인덱스 블록이 두 번째 레벨 인덱스 블록 집합을 가리키고, 이 블록이 파일 블록을 가리키는 체계입니다. 블록에 접근하기 위해, 운영 체제는 첫 번째 레벨 인덱스를 사용하여 두 번째 레벨 인덱스 블록을 찾고, 그런 다음 해당 블록을 사용하여 원하는 데이터 블록을 찾습니다. 이 접근 방식은 원하는 최대 파일 크기에 따라 세 번째 또는 네 번째 레벨까지 계속될 수 있습니다. 4,096 바이트 블록으로, 인덱스 블록에는 1,024개의 4바이트 포인터를 저장할 수 있습니다. 두 레벨의 인덱스는 1,048,576개의 데이터 블록과 최대 4GB 크기의 파일을 허용합니다.
- 결합 체계: 유닉스 기반 파일 시스템에서 사용되는 또 다른 대안은 인덱스 블록의 첫 번째 15개의 포인터를 파일의 inode에 유지하는 것입니다. 첫 번째 12개의 포인터는 직접 블록을 가리키며, 파일의 데이터를 포함하는 블록의 주소를 포함합니다. 따라서 작은 파일(12 블록 이하)의 데이터는 별도의 인덱스 블록이 필요 없습니다. 블록 크기가 4KB인 경우, 최대 48KB의 데이터를 직접 접근할 수 있습니다. 다음 세 개의 포인터는 간접 블록을 가리킵니다. 첫 번째 포인터는 간접 블록을 가리키며, 이는 데이터를 포함하는 블록의 주소가 아닌 인덱스 블록입니다. 두 번째 포인터는 이중 간접 블록을 가리키며, 이는 실제 데이터 블록을 가리키는 포인터를 포함하는 블록의 주소를 포함합니다. 마지막 포인터는 삼중 간접 블록의 주소를 포함합니다. (유닉스 inode는 그림 14.8에 나와 있습니다.) 이 방법을 사용하면, 파일에 할당할 수 있는 블록 수는 많은 운영 체제가 사용하는 4바이트 파일 포인터가 주소할 수 있는 공간을 초과합니다. 32비트 파일 포인터는 2^32 바이트 또는 4GB만 주소할 수 있습니다. 많은 유닉스 및 리눅스 구현은 이제 64비트 파일 포인터를 지원하여 파일과 파일 시스템이 여러 엑시바이트 크기가 될 수 있습니다. ZFS 파일 시스템은 128비트 파일 포인터를 지원합니다.

인덱스 할당 체계는 연결 할당과 동일한 성능 문제 중 일부를 겪습니다. 특히, 인덱스 블록은 메모리에 캐시할 수 있지만, 데이터 블록은 볼륨 전체에 퍼져 있을 수 있습니다.

#### 14.4.4 성능

논의한 할당 방법은 저장 효율성과 데이터 블록 접근 시간에 따라 다릅니다. 두 가지 모두 운영 체제가 구현할 적절한 방법을 선택하는 중요한 기준입니다.

할당 방법을 선택하기 전에, 시스템이 어떻게 사용될 것인지 결정해야 합니다. 대부분 순차 접근이 있는 시스템은 대부분 랜덤 접근이 있는 시스템과 동일한 방법을 사용해서는 안 됩니다.

어떤 유형의 접근이든, 연속 할당은 블록을 얻기 위해 한 번의 접근만 필요합니다. 파일의 초기 주소를 메모리에 쉽게 유지할 수 있기 때문에, i번째 블록(또는 다음 블록)의 주소를 즉시 계산하고 직접 읽을 수 있습니다.

연결 할당의 경우, 다음 블록의 주소를 메모리에 유지하고 직접 읽을 수 있습니다. 이 방법은 순차 접근에 적합하지만, 직접 접근의 경우, i번째 블록에 대한 접근은 I 블록 읽기를 필요로 할 수 있습니다. 이 문제는 왜 연결 할당이 직접 접근을 요구하는 응용 프로그램에 사용되어서는 안 되는지를 설명합니다.

결과적으로, 일부 시스템은 연속 할당을 사용하여 직접 접근 파일을 지원하고, 연결 할당을 사용하여 순차 접근 파일을 지원합니다. 이러한 시스템에서는 파일이 생성될 때 접근 유형을 선언해야 합니다. 순차 접근을 위해 생성된 파일은 연결되어 직접 접근에 사용할 수 없습니다. 직접 접근을 위해 생성된 파일은 연속적이며, 직접 접근과 순차 접근 모두를 지원할 수 있지만, 생성 시 최대 길이를 선언해야 합니다. 이 경우, 운영 체제는 두 가지 할당 방법을 지원하기 위한 적절한 데이터 구조와 알고리즘을 가져야 합니다. 파일은 원하는 유형의 새 파일을 생성하고, 해당 파일의 내용을 복사하여 변환할 수 있습니다. 그런 다음, 이전 파일을 삭제하고 새 파일의 이름을 변경할 수 있습니다.

인덱스 할당은 더 복잡합니다. 인덱스 블록이 이미 메모리에 있는 경우, 접근은 직접 수행할 수 있습니다. 그러나 인덱스 블록을 메모리에 유지하는 데 상당한 공간이 필요합니다. 이 메모리 공간이 사용 가능하지 않으면, 먼저 인덱스 블록을 읽은 다음 원하는 데이터 블록을 읽어야 할 수 있습니다. 두 레벨 인덱스의 경우, 두 번의 인덱스 블록 읽기가 필요할 수 있습니다. 매우 큰 파일의 경우, 파일 끝 부분 근처의 블록에 접근하려면 필요한 데이터 블록을 읽기 전에 모든 인덱스 블록을 읽어야 할 수 있습니다. 따라서 인덱스 할당의 성능은 인덱스 구조, 파일 크기 및 원하는 블록의 위치에 따라 달라집니다.

일부 시스템은 작은 파일(최대 3~4 블록)에 대해 연속 할당을 사용하고 파일이 커지면 자동으로 인덱스 할당으로 전환하여 연속 할당과 인덱스 할당을 결합합니다. 대부분의 파일이 작고, 작은 파일에 대해 연속 할당이 효율적이기 때문에 평균 성능은 상당히 좋을 수 있습니다.

많은 다른 최적화가 사용됩니다. CPU 속도와 디스크 속도 사이의 차이를 감안할 때, 몇 개의 디스크 헤드 이동을 절약하기 위해 운영 체제에 수천 개의 추가 명령어를 추가하는 것은 비합리적이지 않습니다. 더 나아가, 이 격차는 시간이 지남에 따라 증가하고 있어 수십만 개의 명령어를 사용하여 헤드 이동을 최적화하는 것이 합리적일 수 있습니다.

NVM 장치의 경우, 디스크 헤드 탐색이 없으므로 다른 알고리즘과 최적화가 필요합니다. 존재하지 않는 헤드 이동을 피하기 위해 많은 CPU 사이클을 소비하는 오래된 알고리즘을 사용하는 것은 매우 비효율적일 것입니다. 기존 파일 시스템은 수정 중이며, 새로운 파일 시스템이 NVM 저장 장치에서 최대 성능을 달성하기 위해 만들어지고 있습니다. 이러한 개발은 저장 장치와 응용 프로그램의 데이터 접근 사이의 전체 경로와 명령어 수를 줄이는 것을 목표로 하고 있습니다.

### 14.5 자유 공간 관리

저장 공간이 제한되어 있으므로, 삭제된 파일의 공간을 새로운 파일을 위해 재사용해야 합니다. (한 번 쓰기만 가능한 광디스크는 특정 섹터에 한 번만 쓸 수 있으므로, 재사용이 물리적으로 불가능합니다.) 자유 디스크 공간을 추적하기 위해 시스템은 자유 공간 목록을 유지합니다. 자유 공간 목록은 파일이나 디렉터리에 할당되지 않은 모든 장치 블록을 기록합니다. 새 파일을 생성하기 위해, 자유 공간 목록에서 필요한 공간을 검색하여 새 파일에 할당합니다. 그런 다음, 이 공간은 자유 공간 목록에서 제거됩니다. 파일이 삭제되면, 그 공간이 자유 공간 목록에 추가됩니다. 자유 공간 목록이라는 이름에도 불구하고, 이는 반드시 목록으로 구현되지는 않습니다.

#### 14.5.1 비트 벡터

자유 공간 목록은 자주 비트맵 또는 비트 벡터로 구현됩니다. 각 블록은 1비트로 표현됩니다. 블록이 비어 있으면 비트는 1이고, 블록이 할당되면 비트는 0입니다.

예를 들어, 블록 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17, 18, 25, 26, 27이 비어 있고 나머지 블록은 할당된 디스크를 고려해 보십시오. 자유 공간 비트맵은 다음과 같습니다:

001111001111110001100000011100000 ...

이 접근 방식의 주요 장점은 상대적인 단순성과 디스크에서 첫 번째 자유 블록 또는 n개의 연속 자유 블록을 찾는 효율성입니다. 실제로, 많은 컴퓨터는 이 목적을 효과적으로 사용하기 위한 비트 조작 명령어를 제공합니다. 공간 할당에 비트 벡터를 사용하는 시스템에서 첫 번째 자유 블록을 찾는 한 가지 기술은 각 단어의 값을 순차적으로 확인하여 해당 값이 0이 아닌지 확인하는 것입니다. 0 값의 단어는 0 비트만 포함하며 할당된 블록 집합을 나타냅니다. 첫 번째 0이 아닌 단어는 첫 번째 1 비트의 위치를 나타내며,

 이는 첫 번째 자유 블록의 위치입니다. 블록 번호의 계산은 다음과 같습니다:

(단어당 비트 수) × (0 값 단어 수) + 첫 번째 1 비트의 오프셋.

다시 한 번, 하드웨어 기능이 소프트웨어 기능을 주도하는 것을 볼 수 있습니다. 불행히도, 비트 벡터는 전체 벡터를 주 메모리에 유지하지 않으면 비효율적입니다(복구 요구를 위해 파일 시스템을 포함한 장치에 가끔 쓰여집니다). 주 메모리에 유지하는 것은 작은 장치에서는 가능하지만, 반드시 큰 장치에서는 그렇지 않습니다. 512바이트 블록을 가진 1.3GB 디스크는 자유 블록을 추적하기 위해 332KB 이상의 비트맵이 필요하며, 클러스터링된 블록을 네 개로 그룹화하면 이 수가 디스크당 약 83KB로 줄어듭니다. 4KB 블록을 가진 1TB 디스크는 비트맵을 저장하기 위해 32MB(2^40 / 2^12 = 2^28 비트 = 2^25 바이트 = 32MB)가 필요합니다. 디스크 크기는 계속 증가하므로, 비트 벡터의 문제는 계속 증가할 것입니다.

#### 14.5.2 연결 목록

자유 공간 관리의 또 다른 접근 방식은 모든 자유 블록을 연결하여 파일 시스템의 특별한 위치에 첫 번째 자유 블록에 대한 포인터를 유지하고 메모리에 캐시하는 것입니다. 첫 번째 블록은 다음 자유 블록에 대한 포인터를 포함하며, 이 과정을 반복합니다. 섹션 14.5.1의 예를 다시 생각해 보십시오. 이 경우, 우리는 첫 번째 자유 블록으로 블록 2에 대한 포인터를 유지합니다. 블록 2는 블록 3을 가리키며, 블록 3은 블록 4를 가리키고, 이 과정을 반복합니다(그림 14.9). 이 체계는 효율적이지 않으며, 리스트를 순회하려면 각 블록을 읽어야 하므로 HDD에서 상당한 I/O 시간이 필요합니다. 다행히도, 자유 리스트를 순회하는 것은 자주 발생하지 않습니다. 일반적으로, 운영 체제는 자유 블록이 필요할 때, 리스트의 첫 번째 블록을 사용합니다. FAT 방법은 할당 데이터 구조에 자유 블록 회계를 통합하여 별도의 방법이 필요하지 않습니다.

#### 14.5.3 그룹화

자유 목록 접근 방식의 수정된 방법은 첫 번째 자유 블록에 n개의 자유 블록 주소를 저장하는 것입니다. 첫 n-1개의 블록은 실제로 자유입니다. 마지막 블록은 또 다른 n개의 자유 블록 주소를 포함합니다. 이제 많은 수의 자유 블록 주소를 빠르게 찾을 수 있습니다.

#### 14.5.4 카운팅

또 다른 접근 방식은 일반적으로 여러 연속 블록이 동시에 할당되거나 해제된다는 사실을 이용하는 것입니다. 특히, 연속 할당 알고리즘이나 클러스터링을 통해 공간이 할당될 때 그렇습니다. 따라서, n개의 자유 블록 주소 목록을 유지하는 대신, 첫 번째 자유 블록의 주소와 첫 번째 블록을 따르는 n개의 연속 자유 블록 수를 유지할 수 있습니다. 자유 공간 목록의 각 항목은 장치 주소와 카운트로 구성됩니다. 각 항목은 간단한 디스크 주소보다 더 많은 공간을 필요로 하지만, 전체 목록은 카운트가 일반적으로 1보다 큰 한 더 짧습니다. 이 방법은 블록을 할당하는 extent 방법과 유사합니다. 이러한 항목은 효율적인 조회, 삽입 및 삭제를 위해 균형 트리에 저장될 수 있습니다.

### 14.6 효율성 및 성능

이제 다양한 블록 할당 및 디렉터리 관리 옵션을 논의했으므로, 성능 및 효율적 저장 공간 사용에 대한 영향을 더 고려할 수 있습니다. 디스크는 시스템 성능에서 주요 병목 현상을 나타내는 경향이 있습니다. 디스크가 시스템의 주요 구성 요소 중 가장 느리기 때문입니다. NVM 장치도 CPU와 주 메모리에 비해 느리므로, 성능을 최적화해야 합니다. 이 섹션에서는 보조 저장 장치의 효율성과 성능을 향상시키는 데 사용되는 다양한 기술을 논의합니다.

#### 14.6.1 효율성

저장 장치 공간의 효율적인 사용은 사용 중인 할당 및 디렉터리 알고리즘에 크게 좌우됩니다. 예를 들어, 유닉스 inode는 볼륨에 미리 할당됩니다. 빈 디스크에도 inode로 인해 일부 공간이 손실됩니다. 그러나 inode를 미리 할당하고 볼륨 전체에 분산시킴으로써 파일 시스템의 성능을 향상시킬 수 있습니다. 이 향상된 성능은 파일 데이터 블록을 해당 파일의 inode 블록 근처에 유지하려는 유닉스 할당 및 자유 공간 알고리즘에서 비롯됩니다.

또 다른 예로, 섹션 14.4에서 논의된 클러스터링 체계를 다시 생각해 보겠습니다. 클러스터링은 파일 탐색 및 파일 전송 성능을 향상시키지만 내부 단편화 비용이 발생합니다. 이 단편화를 줄이기 위해, BSD 유닉스는 파일이 커질수록 클러스터 크기를 변경합니다. 클러스터가 채워질 수 있는 경우 큰 클러스터를 사용하고, 작은 파일과 파일의 마지막 클러스터에 대해 작은 클러스터를 사용합니다. 이 시스템은 부록 C에 설명되어 있습니다.

파일의 디렉터리(또는 inode) 항목에 보관할 데이터 유형도 고려해야 합니다. 일반적으로 "마지막 쓰기 날짜"를 기록하여 사용자에게 정보를 제공하고 파일이 백업이 필요한지 여부를 결정합니다. 일부 시스템은 "마지막 접근 날짜"도 기록하여 사용자가 파일이 마지막으로 읽힌 시기를 결정할 수 있습니다. 이 정보를 유지하는 결과는 파일이 읽힐 때마다 디렉터리 구조의 필드를 써야 한다는 것입니다. 이는 블록을 메모리로 읽고, 일부를 변경하고, 블록을 장치에 다시 써야 한다는 의미입니다. 보조 저장 장치 작업은 블록(또는 클러스터) 단위로만 발생하기 때문입니다. 따라서 파일을 읽기 위해 열 때마다 FCB도 읽고 써야 합니다. 이 요구 사항은 자주 접근하는 파일에 비효율적일 수 있으므로, 파일 시스템 설계 시 이득과 성능 비용을 고려해야 합니다. 일반적으로, 파일과 관련된 모든 데이터 항목은 효율성과 성능에 미치는 영향을 고려해야 합니다.

예를 들어, 데이터에 접근하는 데 사용되는 포인터의 크기가 효율성에 미치는 영향을 고려해 보십시오. 대부분의 시스템은 운영 체제 전체에서 32비트 또는 64비트 포인터를 사용합니다. 32비트 포인터를 사용하면 파일 크기는 2^32 바이트 또는 4GB로 제한됩니다. 64비트 포인터를 사용하면 매우 큰 파일 크기를 허용하지만, 64비트 포인터는 더 많은 저장 공간을 필요로 합니다. 따라서 할당 및 자유 공간 관리 방법(연결 목록, 인덱스 등)은 더 많은 저장 공간을 사용합니다.

포인터 크기—또는 운영 체제 내의 고정 할당 크기—를 선택하는 어려움 중 하나는 기술 변화의 영향을 계획하는 것입니다. IBM PC XT에는 10MB 하드 드라이브와 32MB만 지원할 수 있는 MS-DOS FAT 파일 시스템이 있었습니다. (각 FAT 항목은 12비트로, 8KB 클러스터를 가리킴). 디스크 용량이 증가함에 따라 더 큰 디스크를 32MB 파티션으로 나눠야 했습니다. 왜냐하면 파일 시스템이 32MB 이상의 블록을 추적할 수 없었기 때문입니다. 100MB 이상의 용량을 가진 하드 디스크가 보편화되면서, MS-DOS의 디스크 데이터 구조와 알고리즘은 더 큰 파일 시스템을 허용하도록 수정되어야 했습니다. (각 FAT 항목은 16비트로 확장되었고 나중에는 32비트로 확장되었습니다). 초기 파일 시스템 결정은 효율성 이유로 이루어졌습니다. 그러나 MS-DOS 버전 4가 등장하면서, 수백만 명의 컴퓨터 사용자가 더 큰 파일 시스템으로 전환해야 했을 때 불편을 겪었습니다. Solaris의 ZFS 파일 시스템은 128비트 포인터를 사용하며, 이론적으로는 확장할 필요가 없을 것입니다. (원자 수준 저장을 사용하여 2^128 바이트를 저장할 수 있는 장치의 최소 질량은 약 272조 킬로그램입니다.)

또 다른 예로, Solaris 운영 체제의 진화를 고려해 보십시오. 원래, 많은 데이터 구조는 고정 길이였으며 시스템 시작 시 할당되었습니다. 이러한 구조에는 프로세스 테이블과 오픈 파일 테이블이 포함되었습니다. 프로세스 테이블이 가득 차면 더 이상 프로세

스를 생성할 수 없었습니다. 파일 테이블이 가득 차면 더 이상 파일을 열 수 없었습니다. 시스템은 사용자에게 서비스를 제공하지 못하게 되었습니다. 테이블 크기는 커널을 다시 컴파일하고 시스템을 재부팅하여만 증가할 수 있었습니다. Solaris의 이후 릴리스에서는(현대 리눅스 커널과 마찬가지로) 거의 모든 커널 구조가 동적으로 할당되어, 시스템 성능에 대한 인위적인 제한을 제거했습니다. 물론, 이러한 테이블을 조작하는 알고리즘은 더 복잡하며, 시스템은 테이블 항목을 동적으로 할당하고 해제해야 하므로 약간 느립니다. 그러나 그 대가는 더 일반적인 기능성을 위한 일반적인 가격입니다.
### 14.6.2 성능

기본 파일 시스템 알고리즘을 선택한 후에도 여러 가지 방법으로 성능을 향상시킬 수 있습니다. 12장에서 논의한 바와 같이, 저장 장치 컨트롤러에는 온보드 캐시를 형성하기 위한 로컬 메모리가 포함되어 있으며, 이는 전체 트랙이나 블록을 한 번에 저장할 수 있을 만큼 큽니다. HDD에서는 탐색이 수행된 후 디스크 헤드 아래의 섹터에서 시작하여 트랙이 디스크 캐시로 읽혀집니다(지연 시간을 줄임). 그런 다음 디스크 컨트롤러는 운영 체제로 섹터 요청을 전달합니다. 블록이 디스크 컨트롤러에서 메인 메모리로 이동하면, 운영 체제는 해당 블록을 캐시에 저장할 수 있습니다.

일부 시스템은 메인 메모리의 별도 섹션을 버퍼 캐시로 유지하여 블록이 곧 다시 사용될 것이라는 가정 하에 보관합니다. 다른 시스템은 페이지 캐시를 사용하여 파일 데이터를 캐시합니다. 페이지 캐시는 파일 시스템 지향 블록이 아닌 페이지로 파일 데이터를 캐시하기 위해 가상 메모리 기술을 사용합니다. 가상 주소를 사용하여 파일 데이터를 캐시하는 것은 물리적 디스크 블록을 통해 캐시하는 것보다 훨씬 효율적입니다. 이는 접근이 파일 시스템이 아닌 가상 메모리와 인터페이스하기 때문입니다. Solaris, Linux, Windows를 포함한 여러 시스템은 프로세스 페이지와 파일 데이터를 모두 캐시하기 위해 페이지 캐시를 사용합니다. 이를 통합 가상 메모리라고 합니다.

일부 UNIX 및 Linux 버전은 통합 버퍼 캐시를 제공합니다. 통합 버퍼 캐시의 장점을 설명하기 위해 파일을 열고 액세스하는 두 가지 대안을 고려해 봅시다. 한 가지 방법은 메모리 매핑(13.5절)을 사용하는 것이고, 다른 방법은 표준 시스템 호출 read()와 write()를 사용하는 것입니다. 통합 버퍼 캐시가 없는 경우, 그림 14.10과 유사한 상황이 발생합니다. 여기서 read()와 write() 시스템 호출은 버퍼 캐시를 통해 진행됩니다. 그러나 메모리 매핑 호출은 페이지 캐시와 버퍼 캐시의 두 가지 캐시를 사용해야 합니다. 메모리 매핑은 파일 시스템에서 디스크 블록을 읽어 버퍼 캐시에 저장하는 것으로 시작됩니다. 가상 메모리 시스템은 버퍼 캐시와 인터페이스하지 않기 때문에 버퍼 캐시의 파일 내용을 페이지 캐시로 복사해야 합니다. 이러한 상황을 이중 캐싱이라고 하며, 파일 시스템 데이터를 두 번 캐시해야 합니다. 이는 메모리를 낭비할 뿐만 아니라 시스템 메모리 내에서 추가 데이터 이동으로 인해 상당한 CPU와 I/O 사이클을 낭비합니다. 또한 두 캐시 간의 불일치로 인해 파일이 손상될 수 있습니다. 반면 통합 버퍼 캐시가 제공되면 메모리 매핑과 read() 및 write() 시스템 호출 모두 동일한 페이지 캐시를 사용합니다. 이는 이중 캐싱을 방지하고 가상 메모리 시스템이 파일 시스템 데이터를 관리할 수 있도록 합니다. 통합 버퍼 캐시는 그림 14.11에 나와 있습니다.

스토리지 블록이나 페이지(또는 둘 다)를 캐시하든 상관없이, 가장 최근에 사용하지 않은(LRU) (10.4.4절) 알고리즘이 블록 또는 페이지 교체를 위한 일반적인 알고리즘으로 적합해 보입니다. 그러나 Solaris 페이지 캐싱 알고리즘의 진화는 알고리즘 선택의 어려움을 보여줍니다. Solaris는 프로세스와 페이지 캐시가 사용되지 않은 메모리를 공유할 수 있도록 합니다. Solaris 2.5.1 이전 버전에서는 프로세스에 페이지를 할당하는 것과 페이지 캐시에 할당하는 것 사이에 차이가 없었습니다. 결과적으로 많은 I/O 작업을 수행하는 시스템은 대부분의 사용 가능한 메모리를 페이지 캐시로 사용했습니다. 높은 I/O 비율로 인해 페이지 스캐너(10.10.3절)는 메모리가 부족할 때 페이지 캐시가 아닌 프로세스에서 페이지를 회수했습니다. Solaris 2.6 및 Solaris 7은 우선 순위 페이징을 선택적으로 구현하여 페이지 스캐너가 페이지 캐시보다 프로세스 페이지에 우선 순위를 부여했습니다. Solaris 8은 프로세스 페이지와 파일 시스템 페이지 캐시에 고정 한도를 적용하여 서로가 메모리에서 밀려나지 않도록 했습니다. Solaris 9 및 10은 메모리 사용을 극대화하고 스래싱을 최소화하기 위해 알고리즘을 다시 변경했습니다.

I/O 성능에 영향을 미칠 수 있는 또 다른 문제는 파일 시스템에 대한 쓰기가 동기적으로 발생하는지 비동기적으로 발생하는지입니다. 동기적 쓰기는 저장 서브시스템이 이를 수신한 순서대로 발생하며 쓰기는 버퍼링되지 않습니다. 따라서 호출 루틴은 데이터가 드라이브에 도달할 때까지 기다려야 합니다. 비동기적 쓰기에서는 데이터가 캐시에 저장되고 제어가 호출자에게 반환됩니다. 대부분의 쓰기는 비동기적입니다. 그러나 메타데이터 쓰기 등은 동기적일 수 있습니다. 운영 체제는 종종 open 시스템 호출에 플래그를 포함하여 프로세스가 쓰기를 동기적으로 수행하도록 요청할 수 있습니다. 예를 들어 데이터베이스는 원자 트랜잭션을 위해 이 기능을 사용하여 데이터가 필요한 순서로 안정된 저장소에 도달하도록 합니다.

일부 시스템은 파일의 액세스 유형에 따라 다양한 교체 알고리즘을 사용하여 페이지 캐시를 최적화합니다. 파일이 순차적으로 읽거나 쓰일 경우, 페이지를 LRU 순서로 교체해서는 안 됩니다. 가장 최근에 사용된 페이지가 가장 마지막에 사용되거나, 아마도 다시는 사용되지 않을 수 있기 때문입니다. 대신 순차적 접근은 프리 비하인드(free-behind) 및 리드 어헤드(read-ahead)라는 기술로 최적화될 수 있습니다. 프리 비하인드는 다음 페이지가 요청되면 페이지를 버퍼에서 제거합니다. 이전 페이지는 다시 사용될 가능성이 낮아 버퍼 공간을 낭비합니다. 리드 어헤드는 요청된 페이지와 이후 여러 페이지를 읽어 캐시에 저장합니다. 이러한 페이지는 현재 페이지가 처리된 후 요청될 가능성이 큽니다. 이러한 데이터를 한 번에 디스크에서 가져와 캐시에 저장하면 상당한 시간을 절약할 수 있습니다. 트랙 캐시가 컨트롤러에 있다고 해서 다중 프로그래밍 시스템에서 리드 어헤드의 필요성이 없어지지는 않습니다. 트랙 캐시에서 메인 메모리로 여러 작은 전송을 수행하는 데 높은 지연 시간과 오버헤드가 발생하기 때문에 리드 어헤드를 수행하는 것이 여전히 유익합니다.

페이지 캐시, 파일 시스템 및 장치 드라이버는 몇 가지 흥미로운 상호 작용을 합니다. 소량의 데이터가 파일에 쓰여질 때, 페이지는 캐시에 버퍼링되고 저장 장치 드라이버는 장치 주소에 따라 출력 대기열을 정렬합니다. 이러한 두 가지 작업을 통해 디스크 드라이버는 디스크 헤드 탐색을 최소화할 수 있습니다. 동기적 쓰기가 필요한 경우를 제외하고, 디스크에 쓰는 프로세스는 단순히 캐시에 쓰며, 시스템은 데이터를 적절할 때 비동기적으로 디스크에 씁니다. 사용자 프로세스는 매우 빠른 쓰기를 경험합니다. 디스크 파일에서 데이터를 읽을 때 블록 I/O 시스템은 일부 리드 어헤드를 수행합니다. 그러나 쓰기는 읽기보다 훨씬 비동기적입니다. 따라서 파일 시스템을 통한 디스크 출력은 작은 전송에 대해서는 종종 입력보다 빠릅니다. 아무리 많은 버퍼링과 캐싱이 있더라도 대용량 연속 I/O는 용량을 초과하여 장치의 성능에서 병목현상이 발생할 수 있습니다. 예를 들어 대용량 동영상 파일을 HDD에 쓰는 경우, 파일이 페이지 캐시(또는 프로세스에 사용 가능한 페이지 캐시 부분)보다 크면 페이지 캐시가 가득 차고 모든 I/O는 드라이브 속도로 발생합니다. 현재 HDD는 읽기 속도가 쓰기 속도보다 빠르기 때문에 이 경우 성능 측면이 작은 I/O 성능과는 반대로 나타납니다.

### 18.3 혜택과 특징

가상화는 여러 가지 이점 덕분에 매력적인 선택이 됩니다. 대부분의 이점은 동일한 하드웨어를 공유하면서도 여러 다른 실행 환경(즉, 다양한 운영 체제)을 동시에 실행할 수 있는 능력에 근본적으로 관련이 있습니다.

가상화의 중요한 장점 중 하나는 호스트 시스템이 가상 머신으로부터 보호받는다는 점입니다. 이는 가상 머신이 서로 보호받는 것과 같습니다. 게스트 운영 체제 내부의 바이러스는 해당 운영 체제에 손상을 입힐 수 있지만, 호스트나 다른 게스트에 영향을 미칠 가능성은 거의 없습니다. 각 가상 머신이 거의 완전히 다른 가상 머신으로부터 격리되어 있기 때문에 보호 문제는 거의 발생하지 않습니다.

격리의 잠재적 단점은 리소스 공유를 방해할 수 있다는 점입니다. 리소스를 공유하는 두 가지 접근 방식이 구현되었습니다. 첫째, 파일 시스템 볼륨을 공유하여 파일을 공유할 수 있습니다. 둘째, 각 가상 머신이 가상 통신 네트워크를 통해 정보를 보낼 수 있는 가상 머신 네트워크를 정의할 수 있습니다. 이 네트워크는 물리적 통신 네트워크를 모델로 하지만 소프트웨어로 구현됩니다. 물론 VMM은 게스트 수에 상관없이 물리적 리소스를 사용하도록 허용할 수 있습니다. 예를 들어 물리적 네트워크 연결을 공유하도록 허용된 게스트는 물리적 네트워크를 통해 서로 통신할 수 있습니다.

대부분의 가상화 구현에서 공통적으로 제공하는 기능 중 하나는 실행 중인 가상 머신을 정지하거나 일시 중지할 수 있는 능력입니다. 많은 운영 체제는 프로세스에 대해 이러한 기본 기능을 제공하지만, VMM은 한 단계 더 나아가 게스트의 복사본과 스냅샷을 만들 수 있게 합니다. 복사본은 새 VM을 만들거나 현재 상태를 유지한 채 다른 머신으로 VM을 이동하는 데 사용할 수 있습니다. 게스트는 원래 머신에 있었던 것처럼 그 위치에서 다시 시작할 수 있으며, 클론을 생성합니다. 스냅샷은 특정 시점을 기록하며, 변경된 사항을 원하지 않으면 게스트를 해당 시점으로 재설정할 수 있습니다. 종종 VMM은 여러 스냅샷을 허용합니다. 예를 들어, 스냅샷은 한 달 동안 매일 게스트의 상태를 기록하여 그 스냅샷 상태로 복구할 수 있게 합니다. 이러한 능력은 가상 환경에서 유용하게 사용됩니다.

가상 머신 시스템은 운영 체제 연구 및 개발에 완벽한 도구입니다. 일반적으로 운영 체제를 변경하는 것은 어려운 작업입니다. 운영 체제는 크고 복잡한 프로그램이기 때문에 한 부분을 변경하면 다른 부분에서 예기치 않은 버그가 발생할 수 있습니다. 운영 체제는 커널 모드에서 실행되기 때문에 잘못된 포인터 변경은 전체 파일 시스템을 파괴할 수 있는 오류를 일으킬 수 있습니다. 따라서 운영 체제의 모든 변경 사항을 신중하게 테스트해야 합니다.

물론 운영 체제는 전체 머신에서 실행되고 이를 제어하기 때문에 시스템 개발 시간이 필요합니다. 이 기간 동안 시스템은 사용자에게 사용 불가능하며, 시스템 개발 시간은 시스템 부하가 적은 늦은 밤이나 주말에 자주 예약됩니다.

가상 머신 시스템은 이러한 문제를 상당 부분 해결할 수 있습니다. 시스템 프로그래머는 자신의 가상 머신을 받고, 시스템 개발은 물리적 머신 대신 가상 머신에서 수행됩니다. 정상적인 시스템 운영은 완료되고 테스트된 변경 사항이 프로덕션에 적용될 준비가 되었을 때만 방해받습니다.

개발자에게 가상 머신의 또 다른 장점은 개발자의 워크스테이션에서 여러 운영 체제를 동시에 실행할 수 있다는 점입니다. 이 가상화된 워크스테이션은 다양한 환경에서 프로그램의 빠른 포팅과 테스트를 가능하게 합니다. 또한 여러 버전의 프로그램을 각각 자체 운영 체제에서 실행할 수 있습니다. 품질 보증 엔지니어도 여러 환경에서 애플리케이션을 테스트할 수 있으며, 각 환경을 위해 별도의 컴퓨터를 구입, 전원 공급 및 유지 관리할 필요가 없습니다.

생산 데이터 센터 사용에서 가상 머신의 주요 이점은 시스템 통합입니다. 이는 두 개 이상의 별도 시스템을 가상 머신에서 하나의 시스템으로 실행하는 것입니다. 이러한 물리적-가상 변환은 리소스 최적화를 가져오며, 여러 적게 사용되는 시스템을 결합하여 하나의 더 많이 사용되는 시스템을 만들 수 있습니다.

또한, VMM의 관리 도구를 통해 시스템 관리자는 훨씬 더 많은 시스템을 관리할 수 있습니다. 가상 환경은 100개의 물리적 서버가 각각 20개의 가상 서버를 실행할 수 있습니다. 가상화 없이 2000개의 서버는 여러 시스템 관리자가 필요합니다. 가상화와 그 도구를 사용하면 동일한 작업을 한두 명의 관리자가 관리할 수 있습니다. 이러한 도구 중 하나는 템플릿화입니다. 이는 설치 및 구성된 게스트 운영 체제와 애플리케이션이 포함된 표준 가상 머신 이미지를 저장하고 여러 실행 VM의 소스로 사용하는 것입니다. 다른 기능에는 모든 게스트의 패치 관리, 게스트 백업 및 복원, 리소스 사용 모니터링이 포함됩니다.

가상화는 리소스 활용도를 높일 뿐만 아니라 리소스 관리도 개선할 수 있습니다. 일부 VMM은 실행 중인 게스트를 중단 없이 한 물리적 서버에서 다른 서버로 이동시키는 라이브 마이그레이션 기능을 포함합니다. 서버가 과부하 상태일 경우, 라이브 마이그레이션은 게스트를 중단 없이 소스 호스트의 리소스를 확보할 수 있습니다. 마찬가지로 호스트 하드웨어를 수리하거나 업그레이드해야 할 때, 게스트를 다른 서버로 마이그레이션하고, 비운 호스트를 유지 관리한 후 다시 게스트를 마이그레이션할 수 있습니다. 이 작업은 다운타임 없이 사용자의 작업을 중단하지 않고 수행됩니다.

애플리케이션 배포 방식에 대한 가상화의 가능한 영향을 생각해 보십시오. 시스템이 가상 머신을 쉽게 추가, 제거 및 이동할 수 있다면, 왜 애플리케이션을 시스템에 직접 설치해야 할까요? 대신, 애플리케이션은 조정되고 맞춤화된 운영 체제에 가상 머신으로 미리 설치될 수 있습니다. 이 방법은 애플리케이션 개발자에게 여러 가지 이점을 제공합니다. 애플리케이션 관리가 더 쉬워지고, 조정이 적게 필요하며, 애플리케이션 기술 지원이 더 간단해집니다. 시스템 관리자는 환경을 더 쉽게 관리할 수 있습니다. 설치가 간단하며, 애플리케이션을 다른 시스템으로 재배포하는 것이 일반적인 설치 및 재설치 절차보다 훨씬 쉽습니다. 이러한 방법론이 널리 채택되려면, 모든 가상 머신이 모든 가상화 플랫폼에서 실행될 수 있도록 가상 머신 형식이 표준화되어야 합니다. "Open Virtual Machine Format"은 이러한 표준화를 제공하려는 시도로, 가상 머신 형식 통일에 성공할 수 있습니다.

가상화는 컴퓨터 시설 구현, 관리 및 모니터링의 여러 다른 발전의 토대를 마련했습니다. 예를 들어, 클라우드 컴퓨팅은 인터넷 기술을 사용하는 고객에게 CPU, 메모리 및 I/O와 같은 리소스를 서비스로 제공하는 가상화에 의해 가능해졌습니다. API를 사용하여 프로그램이 클라우드 컴퓨팅 시설에 특정 게스트 운영 체제 및 애플리케이션을 실행하는 수천 개의 VM을 생성하도록 지시할 수 있으며, 다른 사람들은 이를 인터넷을 통해 액세스할 수 있습니다. 많은 다중 사용자 게임, 사진 공유 사이트 및 기타 웹 서비스가 이 기능을 사용합니다.

데스크탑 컴퓨팅 분야에서 가상화는 데스크탑 및 노트북 컴퓨터 사용자가 원격 데이터 센터에 위치한 가상 머신에 원격으로 연결하고 로컬처럼 애플리케이션에 액세스할 수 있도록 합니다. 이 방식은 사용자의 사이트에 로컬 디스크에 데이터를 저장하지 않기 때문에 보안을 강화할 수 있습니다. 사용자의 컴퓨팅 리소스 비용도 감소할 수 있습니다. 사용자는 네트워킹, CPU 및 일부 메모리가 필요하지만, 이러한 시스템 구성 요소는 원격으로 실행되는 게스트의 이미지를 표시하는 것만 하면 됩니다(RDP와 같은 프로토콜을 통해). 따라서 비싸고 고성능의 구성 요소가 필요하지 않습니다. 가상화가 더욱 보편화되고 하드웨어 지원이 계속 개선됨에 따라 다른 사용 사례도 따라올 것입니다.

### 18.4 구성 요소

가상 머신 개념은 유용하지만 구현하기 어렵습니다. 기본 머신의 정확한 복제본을 제공하기 위해 많은 작업이 필요합니다. 특히 듀얼 모드 시스템에서는 사용자 모드와 커널 모드만 있는 기본 머신에서 이러한 작업이 어려워집니다. 이 섹션에서는 효율적인 가상화를 위해 필요한 구성 요소를 살펴보겠습니다. 18.5.2절에서 논의된 유형 0 하이퍼바이저에는 이러한 구성 요소가 필요하지 않습니다.

가상화는 CPU에서 제공하는 기능에 따라 달라집니다. 기능이 충분하면 게스트 환경을 제공하는 VMM을 작성할 수 있습니다. 그렇지 않으면 가상화는 불가능합니다. VMM은 트랩 앤드 에뮬레이트 및 이진 번역을 포함한 여러 기술을 사용하여 가상화를 구현합니다. 이 섹션에서는 가상화를 지원하기 위해 필요한 하드웨어 지원과 함께 이러한 기술 각각을 논의합니다.

가상화 옵션 대부분에서 중요한 개념은 가상 CPU(VCPU)의 구현입니다. VCPU는 코드를 실행하지 않습니다. 대신 게스트 머신이 믿는 CPU 상태를 나타냅니다. 각 게스트에 대해 VMM은 해당 게스트의 현재 CPU 상태를 나타내는 VCPU를 유지 관리합니다. 게스트가 VMM에 의해 CPU에 컨텍스트 스위칭될 때, VCPU의 정보는 올바른 컨텍스트를 로드하는 데 사용됩니다. 이는 범용 운영 체제가 PCB를 사용하는 방식과 유사합니다.

#### 18.4.1 트랩 앤드 에뮬레이트

일반적인 듀얼 모드 시스템에서 가상 머신 게스트는 사용자 모드에서만 실행될 수 있습니다(추가 하드웨어 지원이 제공되지 않는 한). 커널은 커널 모드에서 실행되며, 사용자 수준 코드가 커널 모드에서 실행되는 것은 안전하지 않습니다. 물리적 머신이 두 가지 모드를 가지고 있는 것처럼 가상 머신도 두 가지 모드를 가져야 합니다. 따라서 가상 사용자 모드와 가상 커널 모드가 모두 물리적 사용자 모드에서 실행되어야 합니다. 시스템 호출, 인터럽트 또는 특권 명령어 실행 시도와 같은 사용자 모드에서 커널 모드로 전환되는 작업은 가상 머신에서도 동일하게 가상 사용자 모드에서 가상 커널 모드로 전환되어야 합니다.

이러한 전환을 어떻게 달성할 수 있을까요? 절차는 다음과 같습니다: 게스트의 커널이 특권 명령어를 실행하려고 할 때, 이는 사용자 모드에서 오류를 발생시키며 실제 머신의 VMM으로 트랩을 발생시킵니다. VMM은 제어를 얻어 게스트 커널이 시도한 작업을 게스트를 대신하여 실행(또는 "에뮬레이트")합니다. 그런 다음 제어를 가상 머신으로 반환합니다. 이를 트랩 앤드 에뮬레이트 방법이라고 하며 그림 18.2에 나와 있습니다.

특권 명령어와 함께 시간은 중요한 문제입니다. 모든 비특권 명령어는 하드웨어에서 네이티브로 실행되며, 게스트는 네이티브 애플리케이션과 동일한 성능을 제공합니다. 그러나 특권 명령어는 추가 오버헤드를 발생시켜 게스트가 네이티브로 실행될 때보다 더 느리게 실행됩니다. 또한, CPU는 많은 가상 머신 사이에서 멀티프로그래밍되고 있어 가상 머신을 예측할 수 없는 방식으로 더 느리게 만들 수 있습니다.

이 문제는 다양한 방식으로 접근되었습니다. 예를 들어, IBM VM은 가상 머신의 일반 명령어가 하드웨어에서 직접 실행되도록 허용합니다. 특권 명령어(주로 I/O에 필요)는 에뮬레이트되어 더 느리게 실행됩니다. 일반적으로 하드웨어의 발전과 함께 트랩 앤드 에뮬레이트 기능의 성능이 개선되었으며, 필요한 경우가 줄어들었습니다. 예를 들어, 많은 CPU는 이제 표준 듀얼 모드 작업에 추가 모드를 추가했습니다. VCPU는 게스트 운영 체제가 어떤 모드에 있는지 추적할 필요가 없으며, 물리적 CPU가 해당 기능을 수행합니다. 실제로 일부 CPU는 하드웨어에서 게스트 CPU 상태 관리를 제공하여 VMM이 해당 기능을 제공할 필요가 없어 추가 오버헤드를 제거합니다.

#### 18.4.2 이진 번역

일부 CPU는 특권 명령어와 비특권 명령어를 명확하게 구분하지 않습니다. 가상화 구현자에게 불행히도 Intel x86 CPU 라인이 그 중 하나입니다. x86이 설계될 때 가상화를 실행하는 것을 고려하지 않았습니다. 이 문제는 이진 번역 기술의 구현으로 해결되었습니다. 이진 번역은 개념상 간단하지만 구현은 복잡합니다. 기본 단계는 다음과 같습니다:
1. 게스트 VCPU가 사용자 모드에 있는 경우, 게스트는 물리적 CPU에서 네이티브로 명령어를 실행할 수 있습니다.
2. 게스트 VCPU가 커널 모드에 있는 경우, 게스트는 커널 모드에서 실행되고 있다고 생각합니다. VMM은 게스트가 실행하려는 모든 명령어를 게스트의 프로그램 카운터에 기반하여 읽어들여 가상 커널 모드에서 실행되는 명령어를 검사합니다. 특수 명령어가 아닌 경우 네이티브로 실행됩니다. 특수 명령어는 VCPU의 플래그를 변경하는 것과 같은 동등한 작업을 수행하는 새로운 명령어 세트로 번역됩니다.

이진 번역은 그림 18.3에 나와 있습니다. 이진 번역의 기본 방법은 정확하게 실행되지만 성능이 떨어질 것입니다. 다행히도 대부분의 명령어는 네이티브로 실행됩니다. 성능을 향상시키기 위해 VMware 방법을 사용하여 성능을 개선할 수 있습니다. 여기서 캐싱이 해결책을 제공합니다. 번역이 필요한 각 명령어에 대한 대체 코드는 캐시에 저장됩니다. 나중에 해당 명령어가 실행될 때 번역 캐시에서 실행되므로 다시 번역할 필요가 없습니다. 캐시가 충분히 크면 이 방법은 성능을 크게 향상시킬 수 있습니다.

가상화에서 또 다른 문제는 메모리 관리, 특히 페이지 테이블입니다. VMM이 게스트가 페이지 테이블을 관리한다고 믿는 상태와 VMM 자체를 어떻게 유지할 수 있을까요? 일반적인 방법은 중첩 페이지 테이블(NPT)을 사용하는 것입니다. 각 게스트 운영 체제는 가상 메모리에서 물리 메모리로 변환하기 위해 하나 이상의 페이지 테이블을 유지 관리합니다. VMM은 게스트의 CPU 상태를 나타내는 VCPU를 생성하는 것처럼 게스트의 페이지 테이블 상태를 나타내기 위해 NPT를 유지 관리합니다. 게스트가 페이지 테이블을 변경하려고 할 때 VMM은 해당 페이지 테이블 포인터를 적절한 CPU 레지스터에 넣어 해당 테이블을 활성 페이지 테이블로 만듭니다. 페이지 테이블을 수정해야 할 경우(VMM이 페이지 폴트를 처리하는 경우), VMM은 이를 가로채고 중첩 페이지 테이블과 시스템 페이지 테이블을 적절히 수정해야 합니다. NPT의 사용은 TLB 미스를 증가시킬 수 있으며, 성능을 유지하기 위해 많은 복잡한 문제를 해결해야 합니다.

이진 번역 방법은 상당한 오버헤드를 발생시키는 것처럼 보이지만, 충분한 성능을 제공하여 Intel x86 기반 시스템 가상화를 가능하게 했습니다. VMware는 이진 번역 방법의 성능 영향을 테스트하기 위해 Windows XP를 부팅하고 즉시 종료하면서 경과 시간과 번역 횟수를 모니터링했습니다. 그 결과 95만 번의 번역이 발생했으며, 각각 3마이크로초가 소요되어 전체적으로 Windows XP의 네이티브 실행 시간보다 3초(약 5%)가 증가했습니다. 이 결과를 얻기 위해 개발자는 여기서 논의되지 않은 많은 성능 개선을 사용했습니다.

#### 18.4.3 하드웨어 지원

어떤 수준의 하드웨어 지원 없이는 가상화가 불가능합니다. 시스템 내에서 더 많은 하드웨어 지원이 제공될수록 가상 머신은 더 많은 기능을 제공하고 안정적으로 실행되며 더 나은 성능을 제공합니다. Intel x86 CPU 계열에서 Intel은 2005년부터 새로운 가상화 지원(VT-x 명령어)을 추가했습니다. 이제 이진 번역이 더 이상 필요하지 않습니다.

실제로 모든 주요 범용 CPU는 가상화를 위한 확장된 하드웨어 지원을 제공합니다. 예를 들어, AMD 가상화 기술(AMD-V)은 2006년부터 여러 AMD 프로세서에 등장했습니다. 이 기술은 호스트와 게스트 두 가지 새로운 모드를 정의하여 듀얼 모드 프로세서에서 멀티모드 프로세서로 이동합니다. VMM은 호스트 모드를 활성화하고 각 게스트 가상 머신의 특성을 정의한 다음, 시스템을 게스트 모드로 전환하여 가상 머신에서 실행되는 게스트 운영 체제에 시스템 제어를 전달합니다. 게스트 모드에서는 가상화된 운영 체제가 네이티브 하드웨어에서 실행되고 있다고 생각하며, 호스트의 정의에 포함된 장치를 볼 수 있습니다. 게스트가 가상화된 리소스에 접근하려고 하면 VMM에 제어가 전달되어 해당 상호 작용을 관리합니다. Intel VT-x의 기능도 유사하며, 호스트와 게스트 모드에 해당하는 루트 및 비루트 모드를 제공합니다. 두 기능 모두 게스트 컨텍스트 스위치 동안 게스트 CPU 상태를 자동으로 로드하고 저장하기 위해 게스트 VCPU 상태 데이터 구조를 제공합니다.

AMD와 Intel은 또한 가상 환경에서 메모리 관리를 해결했습니다. AMD의 RVI와 Intel의 EPT 메모리 관리 향상 기능을 사용하면 VMM이 소프트웨어 NPT를 구현할 필요가 없습니다. 본질적으로 이 CPU는 VMM이 페이징을 완전히 제어할 수 있도록 하드웨어에서 중첩 페이지 테이블을 구현하여 가상 주소에서 물리 주소로의 변환을 가속화합니다. NPT는 게스트의 논리 주소-물리 주소 변환을 나타내는 새 레이어를 추가합니다. CPU 페이지 테이블 워킹 기능(데이터 구조를 통해 원하는 데이터를 찾는 기능)은 필요한 경우 이 새 레이어를 포함하여 게스트 테이블에서 VMM 테이블을 통해 원하는 물리 주소를 찾습니다. TLB 미스는 성능 페널티를 발생시키는데, 이는 조회를 완료하기 위해 게스트와 호스트 페이지 테이블을 통해 더 많은 테이블을 탐색해야 하기 때문입니다.

I/O는 하드웨어 지원으로 개선된 또 다른 영역입니다. 표준 직접 메모리 접근(DMA) 컨트롤러는 대상 메모리 주소와 소스 I/O 장치를 수락하고 운영 체제의 작업 없이 두 장치 간에 데이터를 전송합니다. 하드웨어 지원 없이 게스트가 VMM이나 다른 게스트의 메모리에 영향을 미치는 DMA 전송을 설정하려고 할 수 있습니다. 하드웨어 지원 DMA를 제공하는 CPU(Intel CPU의 VT-d와 같은)를 사용하면 DMA에도 간접 수준이 추가됩니다. 먼저 VMM은 각 게스트의 물리적 메모리를 CPU에 알려주는 보호 도메인을 설정합니다. 그런 다음, I/O 장치를 보호 도메인에 할당하여 해당 메모리 영역에만 직접 액세스할 수 있도록 합니다. 하드웨어는 I/O 장치에서 발행된 DMA 요청의 주소를 호스트 물리적 메모리 주소로 변환합니다. 이 방식으로 DMA 전송은 VMM의 간섭 없이 게스트와 장치 간에 전달됩니다.

마찬가지로 인터럽트는 적절한 게스트에게 전달되어야 하며 다른 게스트에게는 보이지 않아야 합니다. 가상화 하드웨어 지원이 있는 CPU는 인터럽트 리매핑 기능을 제공하여 게스트에게 도착한 인터럽트를 해당 게스트의 스레드를 현재 실행 중인 코어에 자동으로 전달합니다. 이 방식으로 게스트는 VMM의 간섭 없이 인터럽트를 수신합니다. 인터럽트 리매핑 없이 악성 게스트는 호스트 시스템의 제어를 획득하기 위해 인터럽트를 생성할 수 있습니다.

ARM v8(64비트) 아키텍처는 가상화 하드웨어 지원에 대해 약간 다른 접근 방식을 취합니다. 이 아키텍처는 커널보다 더 특권이 있는 전체 예외 수준(EL2)을 제공합니다. 이를 통해 격리된 하이퍼바이저를 실행할 수 있으며, 자체 MMU 접근과 인터럽트 트래핑 기능을 갖추고 있습니다. 패러버추얼라이제이션을 허용하기 위해 특수 명령어(HVC)가 추가되었습니다. 이를 통해 하이퍼바이저는 게스트 커널에서 호출할 수 있으며, 이 명령어는 커널 모드(EL1) 내에서만 호출할 수 있습니다.

하드웨어 지원 가상화의 흥미로운 부작용은 얇은 하이퍼바이저를 생성할 수 있다는 점입니다. 좋은 예는 macOS의 하이퍼바이저 프레임워크(“HyperVisor.framework”)입니다. 이는 몇 줄의 코드만으로 가상 머신을 생성할 수 있는 운영 체제 제공 라이브러리입니다. 실제 작업은 시스템 호출을 통해 수행되며, 이는 커널이 하이퍼바이저 프로세스를 대신하여 특권 가상화 CPU 명령어를 호출하도록 합니다. 이를 통해 하이퍼바이저가 이러한 호출을 실행하기 위해 자체 커널 모듈을 로드할 필요 없이 가상 머신을 관리할 수 있습니다.